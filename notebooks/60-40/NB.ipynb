{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12c75068-da67-4680-bf92-c9f86a8e9e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU (CuPy) not available. Using CPU (NumPy).\n",
      "\n",
      "======================================================================\n",
      "HYBRID RADIOMIC FEATURE FUSION FOR LUNG DISEASE CLASSIFICATION (Naive Bayes)\n",
      "======================================================================\n",
      "======================================================================\n",
      "DATASET LOADING AND QUALITY CHECK\n",
      "======================================================================\n",
      "\n",
      "Processing Normal...\n",
      "\n",
      "Processing Pneumonia_bacterial...\n",
      "\n",
      "Processing Pneumonia_viral...\n",
      "\n",
      "======================================================================\n",
      "DATASET STATISTICS\n",
      "======================================================================\n",
      "Normal:\n",
      "  Total: 1583\n",
      "  Loaded: 1583\n",
      "  Rejected: 0\n",
      "Pneumonia_bacterial:\n",
      "  Total: 2780\n",
      "  Loaded: 2780\n",
      "  Rejected: 0\n",
      "Pneumonia_viral:\n",
      "  Total: 1493\n",
      "  Loaded: 1493\n",
      "  Rejected: 0\n",
      "\n",
      "Final Dataset Shape: (5856, 256, 256)\n",
      "Labels Shape: (5856,)\n",
      "\n",
      "======================================================================\n",
      "DATA AUGMENTATION\n",
      "======================================================================\n",
      "Augmenting image 0/5856...\n",
      "Augmenting image 100/5856...\n",
      "Augmenting image 200/5856...\n",
      "Augmenting image 300/5856...\n",
      "Augmenting image 400/5856...\n",
      "Augmenting image 500/5856...\n",
      "Augmenting image 600/5856...\n",
      "Augmenting image 700/5856...\n",
      "Augmenting image 800/5856...\n",
      "Augmenting image 900/5856...\n",
      "Augmenting image 1000/5856...\n",
      "Augmenting image 1100/5856...\n",
      "Augmenting image 1200/5856...\n",
      "Augmenting image 1300/5856...\n",
      "Augmenting image 1400/5856...\n",
      "Augmenting image 1500/5856...\n",
      "Augmenting image 1600/5856...\n",
      "Augmenting image 1700/5856...\n",
      "Augmenting image 1800/5856...\n",
      "Augmenting image 1900/5856...\n",
      "Augmenting image 2000/5856...\n",
      "Augmenting image 2100/5856...\n",
      "Augmenting image 2200/5856...\n",
      "Augmenting image 2300/5856...\n",
      "Augmenting image 2400/5856...\n",
      "Augmenting image 2500/5856...\n",
      "Augmenting image 2600/5856...\n",
      "Augmenting image 2700/5856...\n",
      "Augmenting image 2800/5856...\n",
      "Augmenting image 2900/5856...\n",
      "Augmenting image 3000/5856...\n",
      "Augmenting image 3100/5856...\n",
      "Augmenting image 3200/5856...\n",
      "Augmenting image 3300/5856...\n",
      "Augmenting image 3400/5856...\n",
      "Augmenting image 3500/5856...\n",
      "Augmenting image 3600/5856...\n",
      "Augmenting image 3700/5856...\n",
      "Augmenting image 3800/5856...\n",
      "Augmenting image 3900/5856...\n",
      "Augmenting image 4000/5856...\n",
      "Augmenting image 4100/5856...\n",
      "Augmenting image 4200/5856...\n",
      "Augmenting image 4300/5856...\n",
      "Augmenting image 4400/5856...\n",
      "Augmenting image 4500/5856...\n",
      "Augmenting image 4600/5856...\n",
      "Augmenting image 4700/5856...\n",
      "Augmenting image 4800/5856...\n",
      "Augmenting image 4900/5856...\n",
      "Augmenting image 5000/5856...\n",
      "Augmenting image 5100/5856...\n",
      "Augmenting image 5200/5856...\n",
      "Augmenting image 5300/5856...\n",
      "Augmenting image 5400/5856...\n",
      "Augmenting image 5500/5856...\n",
      "Augmenting image 5600/5856...\n",
      "Augmenting image 5700/5856...\n",
      "Augmenting image 5800/5856...\n",
      "\n",
      "Original dataset size: 5856\n",
      "Augmented dataset size: 17568\n",
      "\n",
      "======================================================================\n",
      "OUTLIER REMOVAL (IQR Method)\n",
      "======================================================================\n",
      "Original samples: 17568\n",
      "Outliers removed: 317\n",
      "Remaining samples: 17251\n",
      "\n",
      "======================================================================\n",
      "IMAGE NORMALIZATION (Z-Score)\n",
      "======================================================================\n",
      "Global Mean: 123.19\n",
      "Global Std: 63.41\n",
      "\n",
      "======================================================================\n",
      "RADIOMIC FEATURE EXTRACTION\n",
      "======================================================================\n",
      "Extracting features from image 0/17251...\n",
      "Extracting features from image 100/17251...\n",
      "Extracting features from image 200/17251...\n",
      "Extracting features from image 300/17251...\n",
      "Extracting features from image 400/17251...\n",
      "Extracting features from image 500/17251...\n",
      "Extracting features from image 600/17251...\n",
      "Extracting features from image 700/17251...\n",
      "Extracting features from image 800/17251...\n",
      "Extracting features from image 900/17251...\n",
      "Extracting features from image 1000/17251...\n",
      "Extracting features from image 1100/17251...\n",
      "Extracting features from image 1200/17251...\n",
      "Extracting features from image 1300/17251...\n",
      "Extracting features from image 1400/17251...\n",
      "Extracting features from image 1500/17251...\n",
      "Extracting features from image 1600/17251...\n",
      "Extracting features from image 1700/17251...\n",
      "Extracting features from image 1800/17251...\n",
      "Extracting features from image 1900/17251...\n",
      "Extracting features from image 2000/17251...\n",
      "Extracting features from image 2100/17251...\n",
      "Extracting features from image 2200/17251...\n",
      "Extracting features from image 2300/17251...\n",
      "Extracting features from image 2400/17251...\n",
      "Extracting features from image 2500/17251...\n",
      "Extracting features from image 2600/17251...\n",
      "Extracting features from image 2700/17251...\n",
      "Extracting features from image 2800/17251...\n",
      "Extracting features from image 2900/17251...\n",
      "Extracting features from image 3000/17251...\n",
      "Extracting features from image 3100/17251...\n",
      "Extracting features from image 3200/17251...\n",
      "Extracting features from image 3300/17251...\n",
      "Extracting features from image 3400/17251...\n",
      "Extracting features from image 3500/17251...\n",
      "Extracting features from image 3600/17251...\n",
      "Extracting features from image 3700/17251...\n",
      "Extracting features from image 3800/17251...\n",
      "Extracting features from image 3900/17251...\n",
      "Extracting features from image 4000/17251...\n",
      "Extracting features from image 4100/17251...\n",
      "Extracting features from image 4200/17251...\n",
      "Extracting features from image 4300/17251...\n",
      "Extracting features from image 4400/17251...\n",
      "Extracting features from image 4500/17251...\n",
      "Extracting features from image 4600/17251...\n",
      "Extracting features from image 4700/17251...\n",
      "Extracting features from image 4800/17251...\n",
      "Extracting features from image 4900/17251...\n",
      "Extracting features from image 5000/17251...\n",
      "Extracting features from image 5100/17251...\n",
      "Extracting features from image 5200/17251...\n",
      "Extracting features from image 5300/17251...\n",
      "Extracting features from image 5400/17251...\n",
      "Extracting features from image 5500/17251...\n",
      "Extracting features from image 5600/17251...\n",
      "Extracting features from image 5700/17251...\n",
      "Extracting features from image 5800/17251...\n",
      "Extracting features from image 5900/17251...\n",
      "Extracting features from image 6000/17251...\n",
      "Extracting features from image 6100/17251...\n",
      "Extracting features from image 6200/17251...\n",
      "Extracting features from image 6300/17251...\n",
      "Extracting features from image 6400/17251...\n",
      "Extracting features from image 6500/17251...\n",
      "Extracting features from image 6600/17251...\n",
      "Extracting features from image 6700/17251...\n",
      "Extracting features from image 6800/17251...\n",
      "Extracting features from image 6900/17251...\n",
      "Extracting features from image 7000/17251...\n",
      "Extracting features from image 7100/17251...\n",
      "Extracting features from image 7200/17251...\n",
      "Extracting features from image 7300/17251...\n",
      "Extracting features from image 7400/17251...\n",
      "Extracting features from image 7500/17251...\n",
      "Extracting features from image 7600/17251...\n",
      "Extracting features from image 7700/17251...\n",
      "Extracting features from image 7800/17251...\n",
      "Extracting features from image 7900/17251...\n",
      "Extracting features from image 8000/17251...\n",
      "Extracting features from image 8100/17251...\n",
      "Extracting features from image 8200/17251...\n",
      "Extracting features from image 8300/17251...\n",
      "Extracting features from image 8400/17251...\n",
      "Extracting features from image 8500/17251...\n",
      "Extracting features from image 8600/17251...\n",
      "Extracting features from image 8700/17251...\n",
      "Extracting features from image 8800/17251...\n",
      "Extracting features from image 8900/17251...\n",
      "Extracting features from image 9000/17251...\n",
      "Extracting features from image 9100/17251...\n",
      "Extracting features from image 9200/17251...\n",
      "Extracting features from image 9300/17251...\n",
      "Extracting features from image 9400/17251...\n",
      "Extracting features from image 9500/17251...\n",
      "Extracting features from image 9600/17251...\n",
      "Extracting features from image 9700/17251...\n",
      "Extracting features from image 9800/17251...\n",
      "Extracting features from image 9900/17251...\n",
      "Extracting features from image 10000/17251...\n",
      "Extracting features from image 10100/17251...\n",
      "Extracting features from image 10200/17251...\n",
      "Extracting features from image 10300/17251...\n",
      "Extracting features from image 10400/17251...\n",
      "Extracting features from image 10500/17251...\n",
      "Extracting features from image 10600/17251...\n",
      "Extracting features from image 10700/17251...\n",
      "Extracting features from image 10800/17251...\n",
      "Extracting features from image 10900/17251...\n",
      "Extracting features from image 11000/17251...\n",
      "Extracting features from image 11100/17251...\n",
      "Extracting features from image 11200/17251...\n",
      "Extracting features from image 11300/17251...\n",
      "Extracting features from image 11400/17251...\n",
      "Extracting features from image 11500/17251...\n",
      "Extracting features from image 11600/17251...\n",
      "Extracting features from image 11700/17251...\n",
      "Extracting features from image 11800/17251...\n",
      "Extracting features from image 11900/17251...\n",
      "Extracting features from image 12000/17251...\n",
      "Extracting features from image 12100/17251...\n",
      "Extracting features from image 12200/17251...\n",
      "Extracting features from image 12300/17251...\n",
      "Extracting features from image 12400/17251...\n",
      "Extracting features from image 12500/17251...\n",
      "Extracting features from image 12600/17251...\n",
      "Extracting features from image 12700/17251...\n",
      "Extracting features from image 12800/17251...\n",
      "Extracting features from image 12900/17251...\n",
      "Extracting features from image 13000/17251...\n",
      "Extracting features from image 13100/17251...\n",
      "Extracting features from image 13200/17251...\n",
      "Extracting features from image 13300/17251...\n",
      "Extracting features from image 13400/17251...\n",
      "Extracting features from image 13500/17251...\n",
      "Extracting features from image 13600/17251...\n",
      "Extracting features from image 13700/17251...\n",
      "Extracting features from image 13800/17251...\n",
      "Extracting features from image 13900/17251...\n",
      "Extracting features from image 14000/17251...\n",
      "Extracting features from image 14100/17251...\n",
      "Extracting features from image 14200/17251...\n",
      "Extracting features from image 14300/17251...\n",
      "Extracting features from image 14400/17251...\n",
      "Extracting features from image 14500/17251...\n",
      "Extracting features from image 14600/17251...\n",
      "Extracting features from image 14700/17251...\n",
      "Extracting features from image 14800/17251...\n",
      "Extracting features from image 14900/17251...\n",
      "Extracting features from image 15000/17251...\n",
      "Extracting features from image 15100/17251...\n",
      "Extracting features from image 15200/17251...\n",
      "Extracting features from image 15300/17251...\n",
      "Extracting features from image 15400/17251...\n",
      "Extracting features from image 15500/17251...\n",
      "Extracting features from image 15600/17251...\n",
      "Extracting features from image 15700/17251...\n",
      "Extracting features from image 15800/17251...\n",
      "Extracting features from image 15900/17251...\n",
      "Extracting features from image 16000/17251...\n",
      "Extracting features from image 16100/17251...\n",
      "Extracting features from image 16200/17251...\n",
      "Extracting features from image 16300/17251...\n",
      "Extracting features from image 16400/17251...\n",
      "Extracting features from image 16500/17251...\n",
      "Extracting features from image 16600/17251...\n",
      "Extracting features from image 16700/17251...\n",
      "Extracting features from image 16800/17251...\n",
      "Extracting features from image 16900/17251...\n",
      "Extracting features from image 17000/17251...\n",
      "Extracting features from image 17100/17251...\n",
      "Extracting features from image 17200/17251...\n",
      "\n",
      "Total features extracted per image: 156\n",
      "Feature breakdown:\n",
      "  - Statistical: 8\n",
      "  - Texture (GLCM): 20\n",
      "  - Gabor: 12\n",
      "  - HOG: 100\n",
      "  - Wavelet: 16\n",
      "\n",
      "======================================================================\n",
      "FEATURE SCALING (Z-Score Normalization)\n",
      "======================================================================\n",
      "Fitted scaling parameters\n",
      "Scaled features shape: (17251, 156)\n",
      "Mean of scaled features: 0.0000\n",
      "Std of scaled features: 1.0000\n",
      "\n",
      "======================================================================\n",
      "DIMENSIONALITY REDUCTION (PCA - 50 components)\n",
      "======================================================================\n",
      "Original feature dimension: 156\n",
      "Reduced feature dimension: 50\n",
      "Explained variance ratio: [0.25051415 0.10353698 0.05734164 0.03766788 0.03299413]\n",
      "Cumulative variance (first 5 components): [0.25051415 0.35405114 0.41139277 0.44906065 0.48205478]\n",
      "Total variance explained: 0.8638\n",
      "\n",
      "======================================================================\n",
      "TRAINING WITH 60% TRAIN / 40% TEST SPLIT\n",
      "======================================================================\n",
      "\n",
      "Train set: 10350 samples\n",
      "Test set: 6901 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TRAINING: Gaussian Naive Bayes\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Results:\n",
      "Accuracy: 0.5017\n",
      "Training Time: 0.00s\n",
      "\n",
      "Normal:\n",
      "  Precision: 0.5173\n",
      "  Recall: 0.4792\n",
      "  F1-Score: 0.4975\n",
      "\n",
      "Bacterial Pneumonia:\n",
      "  Precision: 0.6963\n",
      "  Recall: 0.4446\n",
      "  F1-Score: 0.5427\n",
      "\n",
      "Viral Pneumonia:\n",
      "  Precision: 0.3591\n",
      "  Recall: 0.6344\n",
      "  F1-Score: 0.4586\n",
      "\n",
      "Results saved to: output_run2_NB\\results_summary.json\n",
      "Visualizations saved to: output_run2_NB/\n",
      "\n",
      "======================================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU support\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"GPU (CuPy) detected and will be used for training!\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"GPU (CuPy) not available. Using CPU (NumPy).\")\n",
    "    cp = np  # Fallback to numpy\n",
    "\n",
    "# Select computation library\n",
    "xp = cp if GPU_AVAILABLE else np\n",
    "\n",
    "# ============================================================================\n",
    "# 1. DATASET PREPARATION AND LOADING\n",
    "# ============================================================================\n",
    "\n",
    "class DatasetLoader:\n",
    "    \"\"\"Handles dataset loading, quality checking, and initial preprocessing\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.categories = ['Normal', 'Pneumonia_bacterial', 'Pneumonia_viral']\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.label_map = {'Normal': 0, 'Pneumonia_bacterial': 1, 'Pneumonia_viral': 2}\n",
    "        \n",
    "    def check_image_quality(self, img_path):\n",
    "        \"\"\"Check if image is corrupted or low quality\"\"\"\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                return False, \"Corrupted\"\n",
    "            \n",
    "            # Check resolution (minimum 64x64)\n",
    "            if img.shape[0] < 64 or img.shape[1] < 64:\n",
    "                return False, \"Low resolution\"\n",
    "            \n",
    "            # Check if image is too dark or too bright\n",
    "            mean_intensity = np.mean(img)\n",
    "            if mean_intensity < 10 or mean_intensity > 245:\n",
    "                return False, \"Poor contrast\"\n",
    "            \n",
    "            return True, \"OK\"\n",
    "        except Exception as e:\n",
    "            return False, str(e)\n",
    "    \n",
    "    def load_dataset(self, target_size=(256, 256)):\n",
    "        \"\"\"Load and preprocess dataset\"\"\"\n",
    "        print(\"=\" * 70)\n",
    "        print(\"DATASET LOADING AND QUALITY CHECK\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        stats = {cat: {'total': 0, 'loaded': 0, 'rejected': 0} for cat in self.categories}\n",
    "        \n",
    "        for category in self.categories:\n",
    "            cat_path = os.path.join(self.dataset_path, category)\n",
    "            if not os.path.exists(cat_path):\n",
    "                print(f\"Warning: {category} folder not found!\")\n",
    "                continue\n",
    "            \n",
    "            files = [f for f in os.listdir(cat_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            stats[category]['total'] = len(files)\n",
    "            \n",
    "            print(f\"\\nProcessing {category}...\")\n",
    "            for filename in files:\n",
    "                img_path = os.path.join(cat_path, filename)\n",
    "                is_valid, reason = self.check_image_quality(img_path)\n",
    "                \n",
    "                if is_valid:\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img_resized = cv2.resize(img, target_size)\n",
    "                    self.images.append(img_resized)\n",
    "                    self.labels.append(self.label_map[category])\n",
    "                    stats[category]['loaded'] += 1\n",
    "                else:\n",
    "                    stats[category]['rejected'] += 1\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"DATASET STATISTICS\")\n",
    "        print(\"=\" * 70)\n",
    "        for cat in self.categories:\n",
    "            print(f\"{cat}:\")\n",
    "            print(f\"  Total: {stats[cat]['total']}\")\n",
    "            print(f\"  Loaded: {stats[cat]['loaded']}\")\n",
    "            print(f\"  Rejected: {stats[cat]['rejected']}\")\n",
    "        \n",
    "        self.images = np.array(self.images)\n",
    "        self.labels = np.array(self.labels)\n",
    "        \n",
    "        print(f\"\\nFinal Dataset Shape: {self.images.shape}\")\n",
    "        print(f\"Labels Shape: {self.labels.shape}\")\n",
    "        \n",
    "        return self.images, self.labels\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def apply_clahe(self, image):\n",
    "        \"\"\"Apply Contrast Limited Adaptive Histogram Equalization\"\"\"\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        return clahe.apply(image)\n",
    "    \n",
    "    def add_gaussian_noise(self, image, mean=0, sigma=10):\n",
    "        \"\"\"Add Gaussian noise for augmentation\"\"\"\n",
    "        noise = np.random.normal(mean, sigma, image.shape)\n",
    "        noisy_img = image + noise\n",
    "        return np.clip(noisy_img, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    def rotate_image(self, image, angle):\n",
    "        \"\"\"Rotate image by specified angle\"\"\"\n",
    "        h, w = image.shape\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(image, M, (w, h))\n",
    "        return rotated\n",
    "    \n",
    "    def flip_image(self, image, direction='horizontal'):\n",
    "        \"\"\"Flip image horizontally or vertically\"\"\"\n",
    "        if direction == 'horizontal':\n",
    "            return cv2.flip(image, 1)\n",
    "        else:\n",
    "            return cv2.flip(image, 0)\n",
    "    \n",
    "    def augment_data(self, images, labels, augmentation_factor=2):\n",
    "        \"\"\"Apply data augmentation techniques\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"DATA AUGMENTATION\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        augmented_images = list(images)\n",
    "        augmented_labels = list(labels)\n",
    "        \n",
    "        n_original = len(images)\n",
    "        \n",
    "        for i, (img, label) in enumerate(zip(images, labels)):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Augmenting image {i}/{n_original}...\")\n",
    "            \n",
    "            # Apply CLAHE\n",
    "            img_clahe = self.apply_clahe(img)\n",
    "            augmented_images.append(img_clahe)\n",
    "            augmented_labels.append(label)\n",
    "            \n",
    "            # Rotation\n",
    "            if augmentation_factor >= 2:\n",
    "                img_rot = self.rotate_image(img, 15)\n",
    "                augmented_images.append(img_rot)\n",
    "                augmented_labels.append(label)\n",
    "            \n",
    "            # Flipping\n",
    "            if augmentation_factor >= 3:\n",
    "                img_flip = self.flip_image(img, 'horizontal')\n",
    "                augmented_images.append(img_flip)\n",
    "                augmented_labels.append(label)\n",
    "            \n",
    "            # Noise addition\n",
    "            if augmentation_factor >= 4:\n",
    "                img_noise = self.add_gaussian_noise(img, sigma=5)\n",
    "                augmented_images.append(img_noise)\n",
    "                augmented_labels.append(label)\n",
    "        \n",
    "        print(f\"\\nOriginal dataset size: {n_original}\")\n",
    "        print(f\"Augmented dataset size: {len(augmented_images)}\")\n",
    "        \n",
    "        return np.array(augmented_images), np.array(augmented_labels)\n",
    "    \n",
    "    def remove_outliers_iqr(self, images, labels):\n",
    "        \"\"\"Remove outliers using IQR method based on image statistics\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"OUTLIER REMOVAL (IQR Method)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Calculate mean intensity for each image\n",
    "        mean_intensities = np.array([np.mean(img) for img in images])\n",
    "        \n",
    "        Q1 = np.percentile(mean_intensities, 25)\n",
    "        Q3 = np.percentile(mean_intensities, 75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Keep only non-outliers\n",
    "        mask = (mean_intensities >= lower_bound) & (mean_intensities <= upper_bound)\n",
    "        \n",
    "        print(f\"Original samples: {len(images)}\")\n",
    "        print(f\"Outliers removed: {np.sum(~mask)}\")\n",
    "        print(f\"Remaining samples: {np.sum(mask)}\")\n",
    "        \n",
    "        return images[mask], labels[mask]\n",
    "    \n",
    "    def normalize_images(self, images):\n",
    "        \"\"\"Z-score normalization\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"IMAGE NORMALIZATION (Z-Score)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Flatten all images for global statistics\n",
    "        all_pixels = images.reshape(-1)\n",
    "        self.mean = np.mean(all_pixels)\n",
    "        self.std = np.std(all_pixels)\n",
    "        \n",
    "        print(f\"Global Mean: {self.mean:.2f}\")\n",
    "        print(f\"Global Std: {self.std:.2f}\")\n",
    "        \n",
    "        # Normalize\n",
    "        normalized = (images - self.mean) / (self.std + 1e-8)\n",
    "        \n",
    "        return normalized\n",
    "\n",
    "# ============================================================================\n",
    "# 3. RADIOMIC FEATURE EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "class RadiomicFeatureExtractor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # Statistical Features\n",
    "    def extract_statistical_features(self, image):\n",
    "        \"\"\"Extract first-order statistical features\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Mean\n",
    "        features.append(np.mean(image))\n",
    "        \n",
    "        # Variance\n",
    "        features.append(np.var(image))\n",
    "        \n",
    "        # Standard Deviation\n",
    "        features.append(np.std(image))\n",
    "        \n",
    "        # Entropy\n",
    "        hist, _ = np.histogram(image, bins=256, range=(0, 256), density=True)\n",
    "        hist = hist[hist > 0]  # Remove zero probabilities\n",
    "        entropy = -np.sum(hist * np.log2(hist))\n",
    "        features.append(entropy)\n",
    "        \n",
    "        # Skewness\n",
    "        mean = np.mean(image)\n",
    "        std = np.std(image)\n",
    "        skewness = np.mean(((image - mean) / std) ** 3)\n",
    "        features.append(skewness)\n",
    "        \n",
    "        # Kurtosis\n",
    "        kurtosis = np.mean(((image - mean) / std) ** 4) - 3\n",
    "        features.append(kurtosis)\n",
    "        \n",
    "        # Energy\n",
    "        features.append(np.sum(image ** 2))\n",
    "        \n",
    "        # RMS (Root Mean Square)\n",
    "        features.append(np.sqrt(np.mean(image ** 2)))\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    # GLCM Texture Features\n",
    "    def compute_glcm(self, image, distance=1, angle=0):\n",
    "        \"\"\"Compute Gray Level Co-occurrence Matrix\"\"\"\n",
    "        # Quantize image to reduce levels (0-31)\n",
    "        levels = 32\n",
    "        image_quantized = (image / (256 / levels)).astype(np.int32)\n",
    "        image_quantized = np.clip(image_quantized, 0, levels - 1)\n",
    "        \n",
    "        # Initialize GLCM\n",
    "        glcm = np.zeros((levels, levels), dtype=np.float64)\n",
    "        \n",
    "        rows, cols = image_quantized.shape\n",
    "        \n",
    "        # Compute offset based on angle\n",
    "        if angle == 0:\n",
    "            dx, dy = 0, distance\n",
    "        elif angle == 45:\n",
    "            dx, dy = distance, distance\n",
    "        elif angle == 90:\n",
    "            dx, dy = distance, 0\n",
    "        else:  # 135\n",
    "            dx, dy = distance, -distance\n",
    "        \n",
    "        # Build GLCM\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                ni, nj = i + dx, j + dy\n",
    "                if 0 <= ni < rows and 0 <= nj < cols:\n",
    "                    glcm[image_quantized[i, j], image_quantized[ni, nj]] += 1\n",
    "        \n",
    "        # Normalize\n",
    "        glcm = glcm / (np.sum(glcm) + 1e-10)\n",
    "        \n",
    "        return glcm\n",
    "    \n",
    "    def extract_glcm_features(self, glcm):\n",
    "        \"\"\"Extract Haralick texture features from GLCM\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Contrast\n",
    "        contrast = 0\n",
    "        for i in range(glcm.shape[0]):\n",
    "            for j in range(glcm.shape[1]):\n",
    "                contrast += glcm[i, j] * (i - j) ** 2\n",
    "        features.append(contrast)\n",
    "        \n",
    "        # Dissimilarity\n",
    "        dissimilarity = 0\n",
    "        for i in range(glcm.shape[0]):\n",
    "            for j in range(glcm.shape[1]):\n",
    "                dissimilarity += glcm[i, j] * abs(i - j)\n",
    "        features.append(dissimilarity)\n",
    "        \n",
    "        # Homogeneity\n",
    "        homogeneity = 0\n",
    "        for i in range(glcm.shape[0]):\n",
    "            for j in range(glcm.shape[1]):\n",
    "                homogeneity += glcm[i, j] / (1 + (i - j) ** 2)\n",
    "        features.append(homogeneity)\n",
    "        \n",
    "        # Energy (Angular Second Moment)\n",
    "        energy = np.sum(glcm ** 2)\n",
    "        features.append(energy)\n",
    "        \n",
    "        # Correlation\n",
    "        mu_i = np.sum(np.arange(glcm.shape[0]).reshape(-1, 1) * glcm)\n",
    "        mu_j = np.sum(np.arange(glcm.shape[1]).reshape(1, -1) * glcm)\n",
    "        sigma_i = np.sqrt(np.sum(((np.arange(glcm.shape[0]).reshape(-1, 1) - mu_i) ** 2) * glcm))\n",
    "        sigma_j = np.sqrt(np.sum(((np.arange(glcm.shape[1]).reshape(1, -1) - mu_j) ** 2) * glcm))\n",
    "        \n",
    "        correlation = 0\n",
    "        for i in range(glcm.shape[0]):\n",
    "            for j in range(glcm.shape[1]):\n",
    "                correlation += ((i - mu_i) * (j - mu_j) * glcm[i, j]) / (sigma_i * sigma_j + 1e-10)\n",
    "        features.append(correlation)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def extract_texture_features(self, image):\n",
    "        \"\"\"Extract GLCM features for multiple angles\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Compute GLCM for 4 angles (0, 45, 90, 135 degrees)\n",
    "        for angle in [0, 45, 90, 135]:\n",
    "            glcm = self.compute_glcm(image, distance=1, angle=angle)\n",
    "            glcm_features = self.extract_glcm_features(glcm)\n",
    "            features.extend(glcm_features)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    # Gabor Filter Features\n",
    "    def gabor_kernel(self, ksize, sigma, theta, lambd, gamma, psi):\n",
    "        \"\"\"Create Gabor kernel\"\"\"\n",
    "        sigma_x = sigma\n",
    "        sigma_y = sigma / gamma\n",
    "        \n",
    "        xmax = ksize // 2\n",
    "        ymax = ksize // 2\n",
    "        xmin = -xmax\n",
    "        ymin = -ymax\n",
    "        \n",
    "        kernel = np.zeros((ksize, ksize))\n",
    "        \n",
    "        for y in range(ymin, ymax + 1):\n",
    "            for x in range(xmin, xmax + 1):\n",
    "                x_theta = x * np.cos(theta) + y * np.sin(theta)\n",
    "                y_theta = -x * np.sin(theta) + y * np.cos(theta)\n",
    "                \n",
    "                exp_part = np.exp(-0.5 * (x_theta**2 / sigma_x**2 + y_theta**2 / sigma_y**2))\n",
    "                cos_part = np.cos(2 * np.pi * x_theta / lambd + psi)\n",
    "                \n",
    "                kernel[y + ymax, x + xmax] = exp_part * cos_part\n",
    "        \n",
    "        return kernel\n",
    "    \n",
    "    def extract_gabor_features(self, image):\n",
    "        \"\"\"Extract Gabor filter features\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Gabor parameters\n",
    "        ksize = 21\n",
    "        sigma = 3\n",
    "        lambd = 10\n",
    "        gamma = 0.5\n",
    "        psi = 0\n",
    "        \n",
    "        # Multiple orientations\n",
    "        for theta in [0, np.pi/4, np.pi/2, 3*np.pi/4]:\n",
    "            kernel = self.gabor_kernel(ksize, sigma, theta, lambd, gamma, psi)\n",
    "            filtered = cv2.filter2D(image.astype(np.float64), -1, kernel)\n",
    "            \n",
    "            # Extract statistics from filtered image\n",
    "            features.append(np.mean(filtered))\n",
    "            features.append(np.std(filtered))\n",
    "            features.append(np.max(filtered))\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    # HOG Features\n",
    "    def extract_hog_features(self, image, cell_size=16, bin_count=9):\n",
    "        \"\"\"Extract Histogram of Oriented Gradients features\"\"\"\n",
    "        # Compute gradients\n",
    "        gx = cv2.Sobel(image.astype(np.float64), cv2.CV_64F, 1, 0, ksize=3)\n",
    "        gy = cv2.Sobel(image.astype(np.float64), cv2.CV_64F, 0, 1, ksize=3)\n",
    "        \n",
    "        # Compute magnitude and angle\n",
    "        magnitude = np.sqrt(gx**2 + gy**2)\n",
    "        angle = np.arctan2(gy, gx) * (180 / np.pi) % 180\n",
    "        \n",
    "        # Divide image into cells\n",
    "        h, w = image.shape\n",
    "        cell_h = h // cell_size\n",
    "        cell_w = w // cell_size\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        for i in range(cell_h):\n",
    "            for j in range(cell_w):\n",
    "                cell_mag = magnitude[i*cell_size:(i+1)*cell_size, j*cell_size:(j+1)*cell_size]\n",
    "                cell_ang = angle[i*cell_size:(i+1)*cell_size, j*cell_size:(j+1)*cell_size]\n",
    "                \n",
    "                # Create histogram\n",
    "                hist, _ = np.histogram(cell_ang, bins=bin_count, range=(0, 180), weights=cell_mag)\n",
    "                features.extend(hist)\n",
    "        \n",
    "        return np.array(features[:100])  # Limit to 100 features\n",
    "    \n",
    "    # Wavelet Features\n",
    "    def dwt_2d(self, image):\n",
    "        \"\"\"Simple 2D Discrete Wavelet Transform (Haar)\"\"\"\n",
    "        h, w = image.shape\n",
    "        \n",
    "        # Ensure even dimensions\n",
    "        if h % 2 != 0:\n",
    "            image = image[:-1, :]\n",
    "            h -= 1\n",
    "        if w % 2 != 0:\n",
    "            image = image[:, :-1]\n",
    "            w -= 1\n",
    "        \n",
    "        # Low-pass and high-pass filters\n",
    "        low = np.array([1, 1]) / np.sqrt(2)\n",
    "        high = np.array([1, -1]) / np.sqrt(2)\n",
    "        \n",
    "        # Convolve rows\n",
    "        rows_low = np.zeros((h, w // 2))\n",
    "        rows_high = np.zeros((h, w // 2))\n",
    "        \n",
    "        for i in range(h):\n",
    "            for j in range(w // 2):\n",
    "                rows_low[i, j] = np.sum(image[i, 2*j:2*j+2] * low)\n",
    "                rows_high[i, j] = np.sum(image[i, 2*j:2*j+2] * high)\n",
    "        \n",
    "        # Convolve columns\n",
    "        LL = np.zeros((h // 2, w // 2))\n",
    "        LH = np.zeros((h // 2, w // 2))\n",
    "        HL = np.zeros((h // 2, w // 2))\n",
    "        HH = np.zeros((h // 2, w // 2))\n",
    "        \n",
    "        for j in range(w // 2):\n",
    "            for i in range(h // 2):\n",
    "                LL[i, j] = np.sum(rows_low[2*i:2*i+2, j] * low)\n",
    "                LH[i, j] = np.sum(rows_low[2*i:2*i+2, j] * high)\n",
    "                HL[i, j] = np.sum(rows_high[2*i:2*i+2, j] * low)\n",
    "                HH[i, j] = np.sum(rows_high[2*i:2*i+2, j] * high)\n",
    "        \n",
    "        return LL, LH, HL, HH\n",
    "    \n",
    "    def extract_wavelet_features(self, image):\n",
    "        \"\"\"Extract wavelet-based features\"\"\"\n",
    "        # Convert to uint8 if normalized\n",
    "        if image.dtype != np.uint8:\n",
    "            img_min = np.min(image)\n",
    "            img_max = np.max(image)\n",
    "            image = ((image - img_min) / (img_max - img_min + 1e-8) * 255).astype(np.uint8)\n",
    "        \n",
    "        LL, LH, HL, HH = self.dwt_2d(image.astype(np.float64))\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        # Extract statistics from each subband\n",
    "        for subband in [LL, LH, HL, HH]:\n",
    "            features.append(np.mean(subband))\n",
    "            features.append(np.std(subband))\n",
    "            features.append(np.max(subband))\n",
    "            features.append(np.min(subband))\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def extract_all_features(self, images):\n",
    "        \"\"\"Extract all radiomic features from images\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"RADIOMIC FEATURE EXTRACTION\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_features = []\n",
    "        n_images = len(images)\n",
    "        \n",
    "        for idx, img in enumerate(images):\n",
    "            if idx % 100 == 0:\n",
    "                print(f\"Extracting features from image {idx}/{n_images}...\")\n",
    "            \n",
    "            # Convert to uint8 for some operations\n",
    "            if img.dtype != np.uint8:\n",
    "                img_min = np.min(img)\n",
    "                img_max = np.max(img)\n",
    "                img_uint8 = ((img - img_min) / (img_max - img_min + 1e-8) * 255).astype(np.uint8)\n",
    "            else:\n",
    "                img_uint8 = img\n",
    "            \n",
    "            # Extract different feature types\n",
    "            stat_features = self.extract_statistical_features(img_uint8)\n",
    "            texture_features = self.extract_texture_features(img_uint8)\n",
    "            gabor_features = self.extract_gabor_features(img_uint8)\n",
    "            hog_features = self.extract_hog_features(img_uint8)\n",
    "            wavelet_features = self.extract_wavelet_features(img)\n",
    "            \n",
    "            # Concatenate all features\n",
    "            combined = np.concatenate([\n",
    "                stat_features,\n",
    "                texture_features,\n",
    "                gabor_features,\n",
    "                hog_features,\n",
    "                wavelet_features\n",
    "            ])\n",
    "            \n",
    "            all_features.append(combined)\n",
    "        \n",
    "        all_features = np.array(all_features)\n",
    "        \n",
    "        print(f\"\\nTotal features extracted per image: {all_features.shape[1]}\")\n",
    "        print(f\"Feature breakdown:\")\n",
    "        print(f\"  - Statistical: {len(stat_features)}\")\n",
    "        print(f\"  - Texture (GLCM): {len(texture_features)}\")\n",
    "        print(f\"  - Gabor: {len(gabor_features)}\")\n",
    "        print(f\"  - HOG: {len(hog_features)}\")\n",
    "        print(f\"  - Wavelet: {len(wavelet_features)}\")\n",
    "        \n",
    "        return all_features\n",
    "\n",
    "# ============================================================================\n",
    "# 4. FEATURE FUSION AND SCALING\n",
    "# ============================================================================\n",
    "\n",
    "class FeatureFusion:\n",
    "    \"\"\"\n",
    "    Perform feature fusion and scaling\n",
    "    \n",
    "    Preferred Method: Z-score normalization after concatenation\n",
    "    \n",
    "    Justification:\n",
    "    - Combines complementary information from different feature types\n",
    "    - Z-score ensures all features contribute equally regardless of scale\n",
    "    - Prevents dominance by features with larger magnitudes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def scale_features(self, features, fit=True):\n",
    "        \"\"\"Apply Z-score normalization to features\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"FEATURE SCALING (Z-Score Normalization)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if fit:\n",
    "            self.mean = np.mean(features, axis=0)\n",
    "            self.std = np.std(features, axis=0)\n",
    "            print(\"Fitted scaling parameters\")\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        self.std[self.std == 0] = 1\n",
    "        \n",
    "        scaled = (features - self.mean) / self.std\n",
    "        \n",
    "        print(f\"Scaled features shape: {scaled.shape}\")\n",
    "        print(f\"Mean of scaled features: {np.mean(scaled):.4f}\")\n",
    "        print(f\"Std of scaled features: {np.std(scaled):.4f}\")\n",
    "        \n",
    "        return scaled\n",
    "\n",
    "# ============================================================================\n",
    "# 5. DIMENSIONALITY REDUCTION (PCA)\n",
    "# ============================================================================\n",
    "\n",
    "class PCA:\n",
    "    \"\"\"\n",
    "    Principal Component Analysis for dimensionality reduction\n",
    "    \n",
    "    Preferred Method: Manual PCA implementation\n",
    "    \n",
    "    Justification:\n",
    "    - Reduces computational complexity\n",
    "    - Removes redundant/correlated features\n",
    "    - Retains maximum variance in data\n",
    "    - Improves training time and prevents overfitting\n",
    "    \n",
    "    Reference: Jolliffe & Cadima, 2016\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=50):\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "        self.explained_variance = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit PCA on training data\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"DIMENSIONALITY REDUCTION (PCA - {self.n_components} components)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Center the data\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        X_centered = X - self.mean\n",
    "        \n",
    "        # Compute covariance matrix\n",
    "        cov_matrix = np.cov(X_centered.T)\n",
    "        \n",
    "        # Compute eigenvalues and eigenvectors\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "        \n",
    "        # Sort by eigenvalues\n",
    "        idx = eigenvalues.argsort()[::-1]\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        \n",
    "        # Select top n_components\n",
    "        self.components = eigenvectors[:, :self.n_components]\n",
    "        self.explained_variance = eigenvalues[:self.n_components]\n",
    "        \n",
    "        # Calculate explained variance ratio\n",
    "        total_var = np.sum(eigenvalues)\n",
    "        explained_var_ratio = self.explained_variance / total_var\n",
    "        cumulative_var = np.cumsum(explained_var_ratio)\n",
    "        \n",
    "        print(f\"Original feature dimension: {X.shape[1]}\")\n",
    "        print(f\"Reduced feature dimension: {self.n_components}\")\n",
    "        print(f\"Explained variance ratio: {explained_var_ratio[:5]}\")\n",
    "        print(f\"Cumulative variance (first 5 components): {cumulative_var[:5]}\")\n",
    "        print(f\"Total variance explained: {cumulative_var[-1]:.4f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data to PCA space\"\"\"\n",
    "        X_centered = X - self.mean\n",
    "        return np.dot(X_centered, self.components)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit and transform in one step\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "# ============================================================================\n",
    "# 6. DATA SPLITTING\n",
    "# ============================================================================\n",
    "\n",
    "class DataSplitter:\n",
    "    \"\"\"Manual train-test split implementation\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle_data(X, y, seed=42):\n",
    "        \"\"\"Shuffle data with a given seed\"\"\"\n",
    "        np.random.seed(seed)\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "        return X[indices], y[indices]\n",
    "    \n",
    "    @staticmethod\n",
    "    def train_test_split(X, y, train_ratio=0.6, seed=42):\n",
    "        \"\"\"Split data into train and test sets\"\"\"\n",
    "        X_shuffled, y_shuffled = DataSplitter.shuffle_data(X, y, seed)\n",
    "        \n",
    "        n_samples = len(X)\n",
    "        n_train = int(n_samples * train_ratio)\n",
    "        \n",
    "        X_train = X_shuffled[:n_train]\n",
    "        y_train = y_shuffled[:n_train]\n",
    "        X_test = X_shuffled[n_train:]\n",
    "        y_test = y_shuffled[n_train:]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    @staticmethod\n",
    "    def k_fold_split(X, y, k=5):\n",
    "        \"\"\"Generate k-fold cross-validation splits\"\"\"\n",
    "        n_samples = len(X)\n",
    "        fold_size = n_samples // k\n",
    "        indices = np.arange(n_samples)\n",
    "        \n",
    "        folds = []\n",
    "        for i in range(k):\n",
    "            test_start = i * fold_size\n",
    "            test_end = (i + 1) * fold_size if i < k - 1 else n_samples\n",
    "            \n",
    "            test_indices = indices[test_start:test_end]\n",
    "            train_indices = np.concatenate([indices[:test_start], indices[test_end:]])\n",
    "            \n",
    "            folds.append((train_indices, test_indices))\n",
    "        \n",
    "        return folds\n",
    "\n",
    "# ============================================================================\n",
    "# 7. MACHINE LEARNING CLASSIFIERS\n",
    "# ============================================================================\n",
    "\n",
    "class GaussianNaiveBayes:\n",
    "    \"\"\"\n",
    "    Manual Gaussian Naive Bayes implementation for multiclass classification\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.mean = None\n",
    "        self.var = None\n",
    "        self.prior = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        if GPU_AVAILABLE:\n",
    "            X = cp.asarray(X)\n",
    "            y = cp.asarray(y)\n",
    "        \n",
    "        self.classes = xp.unique(y)\n",
    "        n_features = X.shape[1]\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        self.mean = xp.zeros((n_classes, n_features))\n",
    "        self.var = xp.zeros((n_classes, n_features))\n",
    "        self.prior = xp.zeros(n_classes)\n",
    "        \n",
    "        for idx, c in enumerate(self.classes):\n",
    "            X_c = X[y == c]\n",
    "            self.mean[idx, :] = xp.mean(X_c, axis=0)\n",
    "            self.var[idx, :] = xp.var(X_c, axis=0) + 1e-9  # prevent division by zero\n",
    "            self.prior[idx] = X_c.shape[0] / X.shape[0]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if GPU_AVAILABLE:\n",
    "            X = cp.asarray(X)\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        n_classes = len(self.classes)\n",
    "        probs = xp.zeros((n_samples, n_classes))\n",
    "        \n",
    "        for idx, c in enumerate(self.classes):\n",
    "            mean = self.mean[idx]\n",
    "            var = self.var[idx]\n",
    "            # Gaussian likelihood\n",
    "            likelihood = xp.exp(-0.5 * ((X - mean) ** 2) / var) / xp.sqrt(2 * xp.pi * var)\n",
    "            probs[:, idx] = xp.prod(likelihood, axis=1) * self.prior[idx]\n",
    "        \n",
    "        # Normalize to get probabilities\n",
    "        probs /= xp.sum(probs, axis=1, keepdims=True)\n",
    "        if GPU_AVAILABLE:\n",
    "            probs = cp.asnumpy(probs)\n",
    "        return probs\n",
    "    \n",
    "    def predict(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return np.argmax(probs, axis=1)\n",
    "\n",
    "# ============================================================================\n",
    "# 8. MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Comprehensive model evaluation with multiple metrics\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def confusion_matrix(y_true, y_pred, n_classes=3):\n",
    "        \"\"\"Compute confusion matrix\"\"\"\n",
    "        cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "        for true, pred in zip(y_true, y_pred):\n",
    "            cm[true, pred] += 1\n",
    "        return cm\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(y_true, y_pred):\n",
    "        \"\"\"Calculate accuracy\"\"\"\n",
    "        return np.mean(y_true == y_pred)\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall_f1(y_true, y_pred, n_classes=3):\n",
    "        \"\"\"Calculate precision, recall, and F1-score for each class\"\"\"\n",
    "        cm = ModelEvaluator.confusion_matrix(y_true, y_pred, n_classes)\n",
    "        \n",
    "        precision = np.zeros(n_classes)\n",
    "        recall = np.zeros(n_classes)\n",
    "        f1 = np.zeros(n_classes)\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            tp = cm[i, i]\n",
    "            fp = np.sum(cm[:, i]) - tp\n",
    "            fn = np.sum(cm[i, :]) - tp\n",
    "            \n",
    "            precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
    "        \n",
    "        return precision, recall, f1\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_confusion_matrix(cm, class_names, filename):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_roc_curve(y_true, y_proba, n_classes, class_names, filename):\n",
    "        \"\"\"Plot ROC curves for multiclass classification\"\"\"\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            # Binary classification for each class\n",
    "            y_true_binary = (y_true == i).astype(int)\n",
    "            y_scores = y_proba[:, i]\n",
    "            \n",
    "            # Compute ROC curve points\n",
    "            thresholds = np.linspace(0, 1, 100)\n",
    "            tpr_list = []\n",
    "            fpr_list = []\n",
    "            \n",
    "            for thresh in thresholds:\n",
    "                y_pred_binary = (y_scores >= thresh).astype(int)\n",
    "                \n",
    "                tp = np.sum((y_true_binary == 1) & (y_pred_binary == 1))\n",
    "                fp = np.sum((y_true_binary == 0) & (y_pred_binary == 1))\n",
    "                tn = np.sum((y_true_binary == 0) & (y_pred_binary == 0))\n",
    "                fn = np.sum((y_true_binary == 1) & (y_pred_binary == 0))\n",
    "                \n",
    "                tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "                \n",
    "                tpr_list.append(tpr)\n",
    "                fpr_list.append(fpr)\n",
    "            \n",
    "            # Compute AUC using trapezoidal rule\n",
    "            fpr_array = np.array(fpr_list)\n",
    "            tpr_array = np.array(tpr_list)\n",
    "            \n",
    "            sorted_idx = np.argsort(fpr_array)\n",
    "            fpr_sorted = fpr_array[sorted_idx]\n",
    "            tpr_sorted = tpr_array[sorted_idx]\n",
    "            \n",
    "            auc = np.trapz(tpr_sorted, fpr_sorted)\n",
    "            \n",
    "            plt.plot(fpr_sorted, tpr_sorted, label=f'{class_names[i]} (AUC = {auc:.3f})', linewidth=2)\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves - Multiclass Classification')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_training_curves(loss_history, accuracy_history, filename):\n",
    "        \"\"\"Plot training loss and accuracy curves\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Loss curve\n",
    "        ax1.plot(loss_history, linewidth=2, color='red')\n",
    "        ax1.set_xlabel('Iteration')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title('Training Loss over Iterations')\n",
    "        ax1.grid(alpha=0.3)\n",
    "        \n",
    "        # Accuracy curve (sampled every 10 iterations)\n",
    "        iterations = np.arange(0, len(loss_history), 10)[:len(accuracy_history)]\n",
    "        ax2.plot(iterations, accuracy_history, linewidth=2, color='blue')\n",
    "        ax2.set_xlabel('Iteration')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_title('Training Accuracy over Iterations')\n",
    "        ax2.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# 9. MAIN PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution pipeline\"\"\"\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"output_run2_NB\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"HYBRID RADIOMIC FEATURE FUSION FOR LUNG DISEASE CLASSIFICATION (Naive Bayes)\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: Load Dataset\n",
    "    # ========================================================================\n",
    "    dataset_path = \"chest_xray\"\n",
    "    loader = DatasetLoader(dataset_path)\n",
    "    images, labels = loader.load_dataset(target_size=(256, 256))\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2: Preprocessing\n",
    "    # ========================================================================\n",
    "    preprocessor = DataPreprocessor()\n",
    "    images_aug, labels_aug = preprocessor.augment_data(images, labels, augmentation_factor=2)\n",
    "    images_clean, labels_clean = preprocessor.remove_outliers_iqr(images_aug, labels_aug)\n",
    "    images_norm = preprocessor.normalize_images(images_clean)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 3: Feature Extraction\n",
    "    # ========================================================================\n",
    "    feature_extractor = RadiomicFeatureExtractor()\n",
    "    features = feature_extractor.extract_all_features(images_norm)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 4: Feature Fusion and Scaling\n",
    "    # ========================================================================\n",
    "    fusion = FeatureFusion()\n",
    "    features_scaled = fusion.scale_features(features, fit=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 5: Dimensionality Reduction\n",
    "    # ========================================================================\n",
    "    pca = PCA(n_components=50)\n",
    "    features_pca = pca.fit_transform(features_scaled)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 6: Data Splitting and Model Training\n",
    "    # ========================================================================\n",
    "    class_names = ['Normal', 'Bacterial Pneumonia', 'Viral Pneumonia']\n",
    "    train_ratios = [0.6]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for train_ratio in train_ratios:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"TRAINING WITH {int(train_ratio*100)}% TRAIN / {int((1-train_ratio)*100)}% TEST SPLIT\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = DataSplitter.train_test_split(\n",
    "            features_pca, labels_clean, train_ratio=train_ratio\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTrain set: {len(X_train)} samples\")\n",
    "        print(f\"Test set: {len(X_test)} samples\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # Train Naive Bayes\n",
    "        # ====================================================================\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"TRAINING: Gaussian Naive Bayes\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        nb_model = GaussianNaiveBayes()\n",
    "        nb_model.fit(X_train, y_train)\n",
    "        \n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = nb_model.predict(X_test)\n",
    "        y_proba = nb_model.predict_proba(X_test)\n",
    "        \n",
    "        # Evaluation\n",
    "        cm = ModelEvaluator.confusion_matrix(y_test, y_pred)\n",
    "        accuracy = ModelEvaluator.accuracy(y_test, y_pred)\n",
    "        precision, recall, f1 = ModelEvaluator.precision_recall_f1(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Training Time: {train_time:.2f}s\")\n",
    "        \n",
    "        for i, class_name in enumerate(class_names):\n",
    "            print(f\"\\n{class_name}:\")\n",
    "            print(f\"  Precision: {precision[i]:.4f}\")\n",
    "            print(f\"  Recall: {recall[i]:.4f}\")\n",
    "            print(f\"  F1-Score: {f1[i]:.4f}\")\n",
    "        \n",
    "        # Save confusion matrix\n",
    "        cm_filename = os.path.join(output_dir, f'confusion_matrix_NB_{int(train_ratio*100)}.png')\n",
    "        ModelEvaluator.plot_confusion_matrix(cm, class_names, cm_filename)\n",
    "        \n",
    "        # Save ROC curve\n",
    "        roc_filename = os.path.join(output_dir, f'roc_curve_NB_{int(train_ratio*100)}.png')\n",
    "        ModelEvaluator.plot_roc_curve(y_test, y_proba, 3, class_names, roc_filename)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'model': 'Gaussian Naive Bayes',\n",
    "            'train_ratio': train_ratio,\n",
    "            'accuracy': float(accuracy),\n",
    "            'precision': precision.tolist(),\n",
    "            'recall': recall.tolist(),\n",
    "            'f1_score': f1.tolist(),\n",
    "            'training_time': float(train_time),\n",
    "            'confusion_matrix': cm.tolist()\n",
    "        })\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 7: Save Results Summary\n",
    "    # ========================================================================\n",
    "    results_file = os.path.join(output_dir, 'results_summary.json')\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nResults saved to: {results_file}\")\n",
    "    print(f\"Visualizations saved to: {output_dir}/\")\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    models = [r['model'] for r in results]\n",
    "    accuracies = [r['accuracy'] for r in results]\n",
    "    plt.bar(range(len(models)), accuracies, color='steelblue')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Comparison - Accuracy')\n",
    "    plt.xticks(range(len(models)), models, rotation=45, ha='right')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'model_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256fb65b-87b5-4b71-a1c6-b622dcbab589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GPU INITIALIZATION\n",
      "======================================================================\n",
      "GPU Device: NVIDIA GeForce RTX 3060\n",
      "GPU Memory: 12.88 GB\n",
      "CUDA Version: 12.1\n",
      "CUDA enabled - All processing will run on GPU!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "CUDA-ACCELERATED LUNG DISEASE CLASSIFICATION\n",
      "PyTorch CUDA - All Processing on GPU\n",
      "======================================================================\n",
      "\n",
      "Initial GPU Memory: 0.00 GB allocated\n",
      "Initial GPU Memory: 0.00 GB reserved\n",
      "======================================================================\n",
      "DATASET LOADING AND QUALITY CHECK\n",
      "======================================================================\n",
      "\n",
      "Processing Normal...\n",
      "\n",
      "Processing Pneumonia_bacterial...\n",
      "\n",
      "Processing Pneumonia_viral...\n",
      "\n",
      "======================================================================\n",
      "DATASET STATISTICS\n",
      "======================================================================\n",
      "Normal:\n",
      "  Total: 1583\n",
      "  Loaded: 1583\n",
      "  Rejected: 0\n",
      "Pneumonia_bacterial:\n",
      "  Total: 2780\n",
      "  Loaded: 2780\n",
      "  Rejected: 0\n",
      "Pneumonia_viral:\n",
      "  Total: 1493\n",
      "  Loaded: 1493\n",
      "  Rejected: 0\n",
      "\n",
      "Transferring data to GPU...\n",
      "Final Dataset Shape: torch.Size([5856, 256, 256])\n",
      "Labels Shape: torch.Size([5856])\n",
      "Data location: cuda:0\n",
      "GPU Memory after loading: 1.54 GB allocated\n",
      "\n",
      "======================================================================\n",
      "DATA AUGMENTATION (GPU-Accelerated)\n",
      "======================================================================\n",
      "Applying CLAHE enhancement...\n",
      "  Processing 0/5856...\n",
      "  Processing 500/5856...\n",
      "  Processing 1000/5856...\n",
      "  Processing 1500/5856...\n",
      "  Processing 2000/5856...\n",
      "  Processing 2500/5856...\n",
      "  Processing 3000/5856...\n",
      "  Processing 3500/5856...\n",
      "  Processing 4000/5856...\n",
      "  Processing 4500/5856...\n",
      "  Processing 5000/5856...\n",
      "  Processing 5500/5856...\n",
      "Applying rotation augmentation...\n",
      "  Processing 0/5856...\n",
      "  Processing 500/5856...\n",
      "  Processing 1000/5856...\n",
      "  Processing 1500/5856...\n",
      "  Processing 2000/5856...\n",
      "  Processing 2500/5856...\n",
      "  Processing 3000/5856...\n",
      "  Processing 3500/5856...\n",
      "  Processing 4000/5856...\n",
      "  Processing 4500/5856...\n",
      "  Processing 5000/5856...\n",
      "  Processing 5500/5856...\n",
      "\n",
      "Original dataset size: 5856\n",
      "Augmented dataset size: 17568\n",
      "Data stored on: cuda:0\n",
      "GPU Memory after augmentation: 6.14 GB allocated\n",
      "\n",
      "======================================================================\n",
      "OUTLIER REMOVAL (IQR Method - GPU)\n",
      "======================================================================\n",
      "Original samples: 17568\n",
      "Outliers removed: 317\n",
      "Remaining samples: 17251\n",
      "\n",
      "======================================================================\n",
      "IMAGE NORMALIZATION (Z-Score - GPU)\n",
      "======================================================================\n",
      "Global Mean: 123.19\n",
      "Global Std: 63.41\n",
      "GPU Memory after preprocessing: 15.19 GB allocated\n",
      "\n",
      "======================================================================\n",
      "RADIOMIC FEATURE EXTRACTION (GPU-Accelerated)\n",
      "======================================================================\n",
      "Feature Categories:\n",
      "  1. Statistical: Mean, Variance, Std\n",
      "  2. Texture: GLCM Contrast, Homogeneity\n",
      "  3. Filter-based: Gabor Mean Response, Gabor Std Response\n",
      "======================================================================\n",
      "Extracting features from image 0/17251...\n",
      "Extracting features from image 100/17251...\n",
      "Extracting features from image 200/17251...\n",
      "Extracting features from image 300/17251...\n",
      "Extracting features from image 400/17251...\n",
      "Extracting features from image 500/17251...\n",
      "Extracting features from image 600/17251...\n",
      "Extracting features from image 700/17251...\n",
      "Extracting features from image 800/17251...\n",
      "Extracting features from image 900/17251...\n",
      "Extracting features from image 1000/17251...\n",
      "Extracting features from image 1100/17251...\n",
      "Extracting features from image 1200/17251...\n",
      "Extracting features from image 1300/17251...\n",
      "Extracting features from image 1400/17251...\n",
      "Extracting features from image 1500/17251...\n",
      "Extracting features from image 1600/17251...\n",
      "Extracting features from image 1700/17251...\n",
      "Extracting features from image 1800/17251...\n",
      "Extracting features from image 1900/17251...\n",
      "Extracting features from image 2000/17251...\n",
      "Extracting features from image 2100/17251...\n",
      "Extracting features from image 2200/17251...\n",
      "Extracting features from image 2300/17251...\n",
      "Extracting features from image 2400/17251...\n",
      "Extracting features from image 2500/17251...\n",
      "Extracting features from image 2600/17251...\n",
      "Extracting features from image 2700/17251...\n",
      "Extracting features from image 2800/17251...\n",
      "Extracting features from image 2900/17251...\n",
      "Extracting features from image 3000/17251...\n",
      "Extracting features from image 3100/17251...\n",
      "Extracting features from image 3200/17251...\n",
      "Extracting features from image 3300/17251...\n",
      "Extracting features from image 3400/17251...\n",
      "Extracting features from image 3500/17251...\n",
      "Extracting features from image 3600/17251...\n",
      "Extracting features from image 3700/17251...\n",
      "Extracting features from image 3800/17251...\n",
      "Extracting features from image 3900/17251...\n",
      "Extracting features from image 4000/17251...\n",
      "Extracting features from image 4100/17251...\n",
      "Extracting features from image 4200/17251...\n",
      "Extracting features from image 4300/17251...\n",
      "Extracting features from image 4400/17251...\n",
      "Extracting features from image 4500/17251...\n",
      "Extracting features from image 4600/17251...\n",
      "Extracting features from image 4700/17251...\n",
      "Extracting features from image 4800/17251...\n",
      "Extracting features from image 4900/17251...\n",
      "Extracting features from image 5000/17251...\n",
      "Extracting features from image 5100/17251...\n",
      "Extracting features from image 5200/17251...\n",
      "Extracting features from image 5300/17251...\n",
      "Extracting features from image 5400/17251...\n",
      "Extracting features from image 5500/17251...\n",
      "Extracting features from image 5600/17251...\n",
      "Extracting features from image 5700/17251...\n",
      "Extracting features from image 5800/17251...\n",
      "Extracting features from image 5900/17251...\n",
      "Extracting features from image 6000/17251...\n",
      "Extracting features from image 6100/17251...\n",
      "Extracting features from image 6200/17251...\n",
      "Extracting features from image 6300/17251...\n",
      "Extracting features from image 6400/17251...\n",
      "Extracting features from image 6500/17251...\n",
      "Extracting features from image 6600/17251...\n",
      "Extracting features from image 6700/17251...\n",
      "Extracting features from image 6800/17251...\n",
      "Extracting features from image 6900/17251...\n",
      "Extracting features from image 7000/17251...\n",
      "Extracting features from image 7100/17251...\n",
      "Extracting features from image 7200/17251...\n",
      "Extracting features from image 7300/17251...\n",
      "Extracting features from image 7400/17251...\n",
      "Extracting features from image 7500/17251...\n",
      "Extracting features from image 7600/17251...\n",
      "Extracting features from image 7700/17251...\n",
      "Extracting features from image 7800/17251...\n",
      "Extracting features from image 7900/17251...\n",
      "Extracting features from image 8000/17251...\n",
      "Extracting features from image 8100/17251...\n",
      "Extracting features from image 8200/17251...\n",
      "Extracting features from image 8300/17251...\n",
      "Extracting features from image 8400/17251...\n",
      "Extracting features from image 8500/17251...\n",
      "Extracting features from image 8600/17251...\n",
      "Extracting features from image 8700/17251...\n",
      "Extracting features from image 8800/17251...\n",
      "Extracting features from image 8900/17251...\n",
      "Extracting features from image 9000/17251...\n",
      "Extracting features from image 9100/17251...\n",
      "Extracting features from image 9200/17251...\n",
      "Extracting features from image 9300/17251...\n",
      "Extracting features from image 9400/17251...\n",
      "Extracting features from image 9500/17251...\n",
      "Extracting features from image 9600/17251...\n",
      "Extracting features from image 9700/17251...\n",
      "Extracting features from image 9800/17251...\n",
      "Extracting features from image 9900/17251...\n",
      "Extracting features from image 10000/17251...\n",
      "Extracting features from image 10100/17251...\n",
      "Extracting features from image 10200/17251...\n",
      "Extracting features from image 10300/17251...\n",
      "Extracting features from image 10400/17251...\n",
      "Extracting features from image 10500/17251...\n",
      "Extracting features from image 10600/17251...\n",
      "Extracting features from image 10700/17251...\n",
      "Extracting features from image 10800/17251...\n",
      "Extracting features from image 10900/17251...\n",
      "Extracting features from image 11000/17251...\n",
      "Extracting features from image 11100/17251...\n",
      "Extracting features from image 11200/17251...\n",
      "Extracting features from image 11300/17251...\n",
      "Extracting features from image 11400/17251...\n",
      "Extracting features from image 11500/17251...\n",
      "Extracting features from image 11600/17251...\n",
      "Extracting features from image 11700/17251...\n",
      "Extracting features from image 11800/17251...\n",
      "Extracting features from image 11900/17251...\n",
      "Extracting features from image 12000/17251...\n",
      "Extracting features from image 12100/17251...\n",
      "Extracting features from image 12200/17251...\n",
      "Extracting features from image 12300/17251...\n",
      "Extracting features from image 12400/17251...\n",
      "Extracting features from image 12500/17251...\n",
      "Extracting features from image 12600/17251...\n",
      "Extracting features from image 12700/17251...\n",
      "Extracting features from image 12800/17251...\n",
      "Extracting features from image 12900/17251...\n",
      "Extracting features from image 13000/17251...\n",
      "Extracting features from image 13100/17251...\n",
      "Extracting features from image 13200/17251...\n",
      "Extracting features from image 13300/17251...\n",
      "Extracting features from image 13400/17251...\n",
      "Extracting features from image 13500/17251...\n",
      "Extracting features from image 13600/17251...\n",
      "Extracting features from image 13700/17251...\n",
      "Extracting features from image 13800/17251...\n",
      "Extracting features from image 13900/17251...\n",
      "Extracting features from image 14000/17251...\n",
      "Extracting features from image 14100/17251...\n",
      "Extracting features from image 14200/17251...\n",
      "Extracting features from image 14300/17251...\n",
      "Extracting features from image 14400/17251...\n",
      "Extracting features from image 14500/17251...\n",
      "Extracting features from image 14600/17251...\n",
      "Extracting features from image 14700/17251...\n",
      "Extracting features from image 14800/17251...\n",
      "Extracting features from image 14900/17251...\n",
      "Extracting features from image 15000/17251...\n",
      "Extracting features from image 15100/17251...\n",
      "Extracting features from image 15200/17251...\n",
      "Extracting features from image 15300/17251...\n",
      "Extracting features from image 15400/17251...\n",
      "Extracting features from image 15500/17251...\n",
      "Extracting features from image 15600/17251...\n",
      "Extracting features from image 15700/17251...\n",
      "Extracting features from image 15800/17251...\n",
      "Extracting features from image 15900/17251...\n",
      "Extracting features from image 16000/17251...\n",
      "Extracting features from image 16100/17251...\n",
      "Extracting features from image 16200/17251...\n",
      "Extracting features from image 16300/17251...\n",
      "Extracting features from image 16400/17251...\n",
      "Extracting features from image 16500/17251...\n",
      "Extracting features from image 16600/17251...\n",
      "Extracting features from image 16700/17251...\n",
      "Extracting features from image 16800/17251...\n",
      "Extracting features from image 16900/17251...\n",
      "Extracting features from image 17000/17251...\n",
      "Extracting features from image 17100/17251...\n",
      "Extracting features from image 17200/17251...\n",
      "\n",
      "Total features extracted per image: 7\n",
      "All features stored on: cuda:0\n",
      "GPU Memory after feature extraction: 15.19 GB allocated\n",
      "\n",
      "======================================================================\n",
      "FEATURE SCALING (GPU - Z-Score)\n",
      "======================================================================\n",
      "Fitted scaling parameters on GPU\n",
      "Scaled features shape: torch.Size([17251, 7])\n",
      "Mean: 0.0000\n",
      "Std: 1.0000\n",
      "\n",
      "======================================================================\n",
      "DIMENSIONALITY REDUCTION (PCA on GPU - 7 components)\n",
      "======================================================================\n",
      "Original dimension: 7\n",
      "Reduced dimension: 7\n",
      "Total variance explained: 1.0000\n",
      "Computation done on: GPU\n",
      "GPU Memory after PCA: 15.20 GB allocated\n",
      "\n",
      "======================================================================\n",
      "TRAINING WITH 60% TRAIN / 40% TEST SPLIT\n",
      "======================================================================\n",
      "\n",
      "Train set: 10350 samples (GPU)\n",
      "Test set: 6901 samples (GPU)\n",
      "GPU Memory before training: 15.20 GB allocated\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TRAINING: Nave Bayes on GPU (Gaussian)\n",
      "----------------------------------------------------------------------\n",
      "Number of classes: 3\n",
      "Number of features: 7\n",
      "\n",
      "Processing class 0...\n",
      "  Samples: 2823\n",
      "  Prior probability: 0.2728\n",
      "\n",
      "Processing class 1...\n",
      "  Samples: 4872\n",
      "  Prior probability: 0.4707\n",
      "\n",
      "Processing class 2...\n",
      "  Samples: 2655\n",
      "  Prior probability: 0.2565\n",
      "\n",
      "Training completed on GPU!\n",
      "\n",
      "GPU Memory after training: 15.20 GB allocated\n",
      "\n",
      "======================================================================\n",
      "RESULTS (CUDA-Accelerated with PyTorch)\n",
      "======================================================================\n",
      "Accuracy: 0.6366\n",
      "Training Time: 0.08s\n",
      "Processing: 100% on NVIDIA GeForce RTX 3060\n",
      "\n",
      "Normal:\n",
      "  Precision: 0.5548\n",
      "  Recall: 0.8542\n",
      "  F1-Score: 0.6727\n",
      "\n",
      "Bacterial Pneumonia:\n",
      "  Precision: 0.7137\n",
      "  Recall: 0.6519\n",
      "  F1-Score: 0.6814\n",
      "\n",
      "Viral Pneumonia:\n",
      "  Precision: 0.6508\n",
      "  Recall: 0.3680\n",
      "  F1-Score: 0.4701\n",
      "\n",
      "Results saved to: output_nb_cuda\\results_summary_nb_cuda.json\n",
      "Visualizations saved to: output_nb_cuda/\n",
      "\n",
      "Final GPU Memory: 15.20 GB allocated\n",
      "Peak GPU Memory: 19.71 GB\n",
      "\n",
      "======================================================================\n",
      "CUDA-ACCELERATED PIPELINE COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# PyTorch CUDA support\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        GPU_AVAILABLE = True\n",
    "        device = torch.device('cuda:0')\n",
    "        print(\"=\" * 70)\n",
    "        print(\"GPU INITIALIZATION\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "        print(\"CUDA enabled - All processing will run on GPU!\")\n",
    "        print(\"=\" * 70)\n",
    "    else:\n",
    "        GPU_AVAILABLE = False\n",
    "        device = torch.device('cpu')\n",
    "        print(\"WARNING: CUDA not available. Using CPU.\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    device = torch.device('cpu')\n",
    "    print(\"ERROR: PyTorch not available. Please install with: pip install torch torchvision\")\n",
    "    exit(1)\n",
    "# ============================================================================\n",
    "# 1. DATASET PREPARATION AND LOADING\n",
    "# ============================================================================\n",
    "class DatasetLoader:\n",
    "    \"\"\"Handles dataset loading with GPU transfer\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.categories = ['Normal', 'Pneumonia_bacterial', 'Pneumonia_viral']\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.label_map = {'Normal': 0, 'Pneumonia_bacterial': 1, 'Pneumonia_viral': 2}\n",
    "        \n",
    "    def check_image_quality(self, img_path):\n",
    "        \"\"\"Check if image is corrupted or low quality\"\"\"\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                return False, \"Corrupted\"\n",
    "            \n",
    "            if img.shape[0] < 64 or img.shape[1] < 64:\n",
    "                return False, \"Low resolution\"\n",
    "            \n",
    "            mean_intensity = np.mean(img)\n",
    "            if mean_intensity < 10 or mean_intensity > 245:\n",
    "                return False, \"Poor contrast\"\n",
    "            \n",
    "            return True, \"OK\"\n",
    "        except Exception as e:\n",
    "            return False, str(e)\n",
    "    \n",
    "    def load_dataset(self, target_size=(256, 256)):\n",
    "        \"\"\"Load and preprocess dataset, then transfer to GPU\"\"\"\n",
    "        print(\"=\" * 70)\n",
    "        print(\"DATASET LOADING AND QUALITY CHECK\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        stats = {cat: {'total': 0, 'loaded': 0, 'rejected': 0} for cat in self.categories}\n",
    "        \n",
    "        for category in self.categories:\n",
    "            cat_path = os.path.join(self.dataset_path, category)\n",
    "            if not os.path.exists(cat_path):\n",
    "                print(f\"Warning: {category} folder not found!\")\n",
    "                continue\n",
    "            \n",
    "            files = [f for f in os.listdir(cat_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            stats[category]['total'] = len(files)\n",
    "            \n",
    "            print(f\"\\nProcessing {category}...\")\n",
    "            for filename in files:\n",
    "                img_path = os.path.join(cat_path, filename)\n",
    "                is_valid, reason = self.check_image_quality(img_path)\n",
    "                \n",
    "                if is_valid:\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img_resized = cv2.resize(img, target_size)\n",
    "                    self.images.append(img_resized)\n",
    "                    self.labels.append(self.label_map[category])\n",
    "                    stats[category]['loaded'] += 1\n",
    "                else:\n",
    "                    stats[category]['rejected'] += 1\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"DATASET STATISTICS\")\n",
    "        print(\"=\" * 70)\n",
    "        for cat in self.categories:\n",
    "            print(f\"{cat}:\")\n",
    "            print(f\"  Total: {stats[cat]['total']}\")\n",
    "            print(f\"  Loaded: {stats[cat]['loaded']}\")\n",
    "            print(f\"  Rejected: {stats[cat]['rejected']}\")\n",
    "        \n",
    "        # Convert to numpy first, then transfer to GPU\n",
    "        images_np = np.array(self.images, dtype=np.float32)\n",
    "        labels_np = np.array(self.labels, dtype=np.int64)\n",
    "        \n",
    "        print(f\"\\nTransferring data to GPU...\")\n",
    "        self.images = torch.from_numpy(images_np).to(device)\n",
    "        self.labels = torch.from_numpy(labels_np).to(device)\n",
    "        \n",
    "        print(f\"Final Dataset Shape: {self.images.shape}\")\n",
    "        print(f\"Labels Shape: {self.labels.shape}\")\n",
    "        print(f\"Data location: {self.images.device}\")\n",
    "        \n",
    "        return self.images, self.labels\n",
    "# ============================================================================\n",
    "# 2. DATA PREPROCESSING (GPU-Optimized)\n",
    "# ============================================================================\n",
    "class DataPreprocessor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def apply_clahe_batch(self, images):\n",
    "        \"\"\"Apply CLAHE to batch of images\"\"\"\n",
    "        results = []\n",
    "        for i in range(len(images)):\n",
    "            img_cpu = images[i].cpu().numpy().astype(np.uint8)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            result = clahe.apply(img_cpu)\n",
    "            results.append(result)\n",
    "        return torch.from_numpy(np.stack(results)).to(device)\n",
    "    \n",
    "    def add_gaussian_noise_gpu(self, images, mean=0, sigma=10):\n",
    "        \"\"\"Add Gaussian noise using GPU\"\"\"\n",
    "        noise = torch.randn_like(images) * sigma + mean\n",
    "        noisy_img = images + noise\n",
    "        return torch.clamp(noisy_img, 0, 255)\n",
    "    \n",
    "    def rotate_image_batch(self, images, angle):\n",
    "        \"\"\"Rotate batch of images\"\"\"\n",
    "        results = []\n",
    "        for i in range(len(images)):\n",
    "            img_cpu = images[i].cpu().numpy().astype(np.uint8)\n",
    "            h, w = img_cpu.shape\n",
    "            center = (w // 2, h // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            rotated = cv2.warpAffine(img_cpu, M, (w, h))\n",
    "            results.append(rotated)\n",
    "        return torch.from_numpy(np.stack(results)).to(device)\n",
    "    \n",
    "    def flip_image_gpu(self, images, direction='horizontal'):\n",
    "        \"\"\"Flip images on GPU\"\"\"\n",
    "        if direction == 'horizontal':\n",
    "            return torch.flip(images, dims=[2])\n",
    "        else:\n",
    "            return torch.flip(images, dims=[1])\n",
    "    \n",
    "    def augment_data(self, images, labels, augmentation_factor=2):\n",
    "        \"\"\"Apply data augmentation on GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"DATA AUGMENTATION (GPU-Accelerated)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        augmented_images = [images]\n",
    "        augmented_labels = [labels]\n",
    "        \n",
    "        n_original = len(images)\n",
    "        \n",
    "        # CLAHE enhancement\n",
    "        print(\"Applying CLAHE enhancement...\")\n",
    "        batch_size = 100\n",
    "        clahe_results = []\n",
    "        for i in range(0, n_original, batch_size):\n",
    "            if i % 500 == 0:\n",
    "                print(f\"  Processing {i}/{n_original}...\")\n",
    "            batch = images[i:i+batch_size]\n",
    "            clahe_batch = self.apply_clahe_batch(batch)\n",
    "            clahe_results.append(clahe_batch)\n",
    "        augmented_images.append(torch.cat(clahe_results, dim=0))\n",
    "        augmented_labels.append(labels)\n",
    "        \n",
    "        if augmentation_factor >= 2:\n",
    "            print(\"Applying rotation augmentation...\")\n",
    "            rotation_results = []\n",
    "            for i in range(0, n_original, batch_size):\n",
    "                if i % 500 == 0:\n",
    "                    print(f\"  Processing {i}/{n_original}...\")\n",
    "                batch = images[i:i+batch_size]\n",
    "                rot_batch = self.rotate_image_batch(batch, 15)\n",
    "                rotation_results.append(rot_batch)\n",
    "            augmented_images.append(torch.cat(rotation_results, dim=0))\n",
    "            augmented_labels.append(labels)\n",
    "        \n",
    "        if augmentation_factor >= 3:\n",
    "            print(\"Applying flip augmentation...\")\n",
    "            # Reshape for flip operation\n",
    "            images_3d = images.unsqueeze(1)  # Add channel dimension\n",
    "            flipped = torch.flip(images_3d, dims=[3]).squeeze(1)\n",
    "            augmented_images.append(flipped)\n",
    "            augmented_labels.append(labels)\n",
    "        \n",
    "        if augmentation_factor >= 4:\n",
    "            print(\"Applying noise augmentation...\")\n",
    "            noisy = self.add_gaussian_noise_gpu(images, sigma=5)\n",
    "            augmented_images.append(noisy)\n",
    "            augmented_labels.append(labels)\n",
    "        \n",
    "        # Concatenate all augmented data on GPU\n",
    "        final_images = torch.cat(augmented_images, dim=0)\n",
    "        final_labels = torch.cat(augmented_labels, dim=0)\n",
    "        \n",
    "        print(f\"\\nOriginal dataset size: {n_original}\")\n",
    "        print(f\"Augmented dataset size: {len(final_images)}\")\n",
    "        print(f\"Data stored on: {final_images.device}\")\n",
    "        \n",
    "        return final_images, final_labels\n",
    "    \n",
    "    def remove_outliers_iqr(self, images, labels):\n",
    "        \"\"\"Remove outliers using IQR method on GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"OUTLIER REMOVAL (IQR Method - GPU)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Calculate mean intensity for each image on GPU\n",
    "        mean_intensities = torch.mean(images.view(len(images), -1), dim=1)\n",
    "        \n",
    "        Q1 = torch.quantile(mean_intensities, 0.25)\n",
    "        Q3 = torch.quantile(mean_intensities, 0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        mask = (mean_intensities >= lower_bound) & (mean_intensities <= upper_bound)\n",
    "        \n",
    "        print(f\"Original samples: {len(images)}\")\n",
    "        print(f\"Outliers removed: {(~mask).sum().item()}\")\n",
    "        print(f\"Remaining samples: {mask.sum().item()}\")\n",
    "        \n",
    "        return images[mask], labels[mask]\n",
    "    \n",
    "    def normalize_images(self, images):\n",
    "        \"\"\"Z-score normalization on GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"IMAGE NORMALIZATION (Z-Score - GPU)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Global statistics on GPU\n",
    "        self.mean = torch.mean(images)\n",
    "        self.std = torch.std(images)\n",
    "        \n",
    "        print(f\"Global Mean: {self.mean.item():.2f}\")\n",
    "        print(f\"Global Std: {self.std.item():.2f}\")\n",
    "        \n",
    "        # Normalize on GPU\n",
    "        normalized = (images - self.mean) / (self.std + 1e-8)\n",
    "        \n",
    "        return normalized\n",
    "# ============================================================================\n",
    "# 3. RADIOMIC FEATURE EXTRACTION (GPU-Optimized)\n",
    "# ============================================================================\n",
    "class RadiomicFeatureExtractor:\n",
    "    \"\"\"GPU-accelerated radiomic feature extraction\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def extract_statistical_features_gpu(self, image):\n",
    "        \"\"\"Extract statistical features on GPU\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        features.append(torch.mean(image).item())\n",
    "        features.append(torch.var(image).item())\n",
    "        features.append(torch.std(image).item())\n",
    "        \n",
    "        return torch.tensor(features, device=device)\n",
    "    \n",
    "    def compute_glcm_gpu(self, image, distance=1, angle=0):\n",
    "        \"\"\"Compute GLCM\"\"\"\n",
    "        levels = 16\n",
    "        \n",
    "        # Quantize on GPU\n",
    "        image_quantized = (image / (256 / levels)).long()\n",
    "        image_quantized = torch.clamp(image_quantized, 0, levels - 1)\n",
    "        \n",
    "        # Transfer to CPU for co-occurrence computation\n",
    "        img_cpu = image_quantized.cpu().numpy()\n",
    "        glcm = np.zeros((levels, levels), dtype=np.float64)\n",
    "        \n",
    "        rows, cols = img_cpu.shape\n",
    "        \n",
    "        if angle == 0:\n",
    "            dx, dy = 0, distance\n",
    "        elif angle == 45:\n",
    "            dx, dy = distance, distance\n",
    "        elif angle == 90:\n",
    "            dx, dy = distance, 0\n",
    "        else:\n",
    "            dx, dy = distance, -distance\n",
    "        \n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                ni, nj = i + dx, j + dy\n",
    "                if 0 <= ni < rows and 0 <= nj < cols:\n",
    "                    glcm[img_cpu[i, j], img_cpu[ni, nj]] += 1\n",
    "        \n",
    "        glcm = glcm / (np.sum(glcm) + 1e-10)\n",
    "        \n",
    "        return torch.from_numpy(glcm).to(device)\n",
    "    \n",
    "    def extract_texture_features_gpu(self, image):\n",
    "        \"\"\"Extract texture features using GPU\"\"\"\n",
    "        glcm = self.compute_glcm_gpu(image, distance=1, angle=0)\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        # Contrast computation on GPU\n",
    "        i_idx = torch.arange(glcm.shape[0], device=device).view(-1, 1).float()\n",
    "        j_idx = torch.arange(glcm.shape[1], device=device).view(1, -1).float()\n",
    "        \n",
    "        contrast = torch.sum(glcm * (i_idx - j_idx) ** 2).item()\n",
    "        features.append(contrast)\n",
    "        \n",
    "        # Homogeneity computation on GPU\n",
    "        homogeneity = torch.sum(glcm / (1 + (i_idx - j_idx) ** 2)).item()\n",
    "        features.append(homogeneity)\n",
    "        \n",
    "        return torch.tensor(features, device=device)\n",
    "    \n",
    "    def gabor_kernel_gpu(self, ksize, sigma, theta, lambd, gamma, psi):\n",
    "        \"\"\"Create Gabor kernel on GPU\"\"\"\n",
    "        sigma_x = sigma\n",
    "        sigma_y = sigma / gamma\n",
    "        \n",
    "        xmax = ksize // 2\n",
    "        ymax = ksize // 2\n",
    "        \n",
    "        y = torch.arange(-ymax, ymax + 1, device=device).view(-1, 1).float()\n",
    "        x = torch.arange(-xmax, xmax + 1, device=device).view(1, -1).float()\n",
    "        \n",
    "        # Rotate coordinates\n",
    "        x_theta = x * torch.cos(torch.tensor(theta, device=device)) + y * torch.sin(torch.tensor(theta, device=device))\n",
    "        y_theta = -x * torch.sin(torch.tensor(theta, device=device)) + y * torch.cos(torch.tensor(theta, device=device))\n",
    "        \n",
    "        # Gaussian envelope\n",
    "        exp_part = torch.exp(-0.5 * (x_theta**2 / sigma_x**2 + y_theta**2 / sigma_y**2))\n",
    "        \n",
    "        # Sinusoidal carrier\n",
    "        cos_part = torch.cos(2 * np.pi * x_theta / lambd + psi)\n",
    "        \n",
    "        kernel = exp_part * cos_part\n",
    "        \n",
    "        return kernel\n",
    "    \n",
    "    def extract_filter_features_gpu(self, image):\n",
    "        \"\"\"Extract Gabor filter features on GPU\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        ksize = 21\n",
    "        sigma = 3\n",
    "        lambd = 10\n",
    "        gamma = 0.5\n",
    "        psi = 0\n",
    "        theta = 0\n",
    "        \n",
    "        # Create kernel on GPU\n",
    "        kernel = self.gabor_kernel_gpu(ksize, sigma, theta, lambd, gamma, psi)\n",
    "        \n",
    "        # Apply filter using conv2d\n",
    "        img_4d = image.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]\n",
    "        kernel_4d = kernel.unsqueeze(0).unsqueeze(0)  # [1, 1, K, K]\n",
    "        \n",
    "        filtered = torch.nn.functional.conv2d(img_4d, kernel_4d, padding=ksize//2)\n",
    "        filtered = filtered.squeeze()\n",
    "        \n",
    "        mean_response = torch.mean(torch.abs(filtered)).item()\n",
    "        features.append(mean_response)\n",
    "        \n",
    "        std_response = torch.std(filtered).item()\n",
    "        features.append(std_response)\n",
    "        \n",
    "        return torch.tensor(features, device=device)\n",
    "    \n",
    "    def extract_all_features(self, images):\n",
    "        \"\"\"Extract all features using GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"RADIOMIC FEATURE EXTRACTION (GPU-Accelerated)\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"Feature Categories:\")\n",
    "        print(\"  1. Statistical: Mean, Variance, Std\")\n",
    "        print(\"  2. Texture: GLCM Contrast, Homogeneity\")\n",
    "        print(\"  3. Filter-based: Gabor Mean Response, Gabor Std Response\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_features = []\n",
    "        n_images = len(images)\n",
    "        \n",
    "        for idx in range(n_images):\n",
    "            if idx % 100 == 0:\n",
    "                print(f\"Extracting features from image {idx}/{n_images}...\")\n",
    "            \n",
    "            img = images[idx]\n",
    "            \n",
    "            # Convert to uint8 range on GPU\n",
    "            img_min = torch.min(img)\n",
    "            img_max = torch.max(img)\n",
    "            img_uint8 = ((img - img_min) / (img_max - img_min + 1e-8) * 255)\n",
    "            \n",
    "            # Extract features (all on GPU)\n",
    "            stat_features = self.extract_statistical_features_gpu(img_uint8)\n",
    "            texture_features = self.extract_texture_features_gpu(img_uint8)\n",
    "            filter_features = self.extract_filter_features_gpu(img_uint8)\n",
    "            \n",
    "            # Concatenate on GPU\n",
    "            combined = torch.cat([stat_features, texture_features, filter_features])\n",
    "            all_features.append(combined)\n",
    "        \n",
    "        # Stack all features on GPU\n",
    "        all_features = torch.stack(all_features)\n",
    "        \n",
    "        print(f\"\\nTotal features extracted per image: {all_features.shape[1]}\")\n",
    "        print(f\"All features stored on: {all_features.device}\")\n",
    "        \n",
    "        return all_features\n",
    "# ============================================================================\n",
    "# 4. FEATURE FUSION AND SCALING (GPU)\n",
    "# ============================================================================\n",
    "class FeatureFusion:\n",
    "    \"\"\"GPU-accelerated feature fusion and scaling\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def scale_features(self, features, fit=True):\n",
    "        \"\"\"Z-score normalization on GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"FEATURE SCALING (GPU - Z-Score)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if fit:\n",
    "            self.mean = torch.mean(features, dim=0)\n",
    "            self.std = torch.std(features, dim=0)\n",
    "            print(\"Fitted scaling parameters on GPU\")\n",
    "        \n",
    "        self.std[self.std == 0] = 1\n",
    "        \n",
    "        scaled = (features - self.mean) / self.std\n",
    "        \n",
    "        print(f\"Scaled features shape: {scaled.shape}\")\n",
    "        print(f\"Mean: {torch.mean(scaled).item():.4f}\")\n",
    "        print(f\"Std: {torch.std(scaled).item():.4f}\")\n",
    "        \n",
    "        return scaled\n",
    "# ============================================================================\n",
    "# 5. DIMENSIONALITY REDUCTION (PCA on GPU)\n",
    "# ============================================================================\n",
    "class PCA:\n",
    "    \"\"\"GPU-accelerated PCA\"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=50):\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "        self.explained_variance = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit PCA on GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"DIMENSIONALITY REDUCTION (PCA on GPU - {self.n_components} components)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Center data on GPU\n",
    "        self.mean = torch.mean(X, dim=0)\n",
    "        X_centered = X - self.mean\n",
    "        \n",
    "        # Compute covariance matrix on GPU\n",
    "        cov_matrix = torch.mm(X_centered.T, X_centered) / (X.shape[0] - 1)\n",
    "        \n",
    "        # Compute eigenvalues and eigenvectors on GPU\n",
    "        eigenvalues, eigenvectors = torch.linalg.eigh(cov_matrix)\n",
    "        \n",
    "        # Sort in descending order\n",
    "        idx = torch.argsort(eigenvalues, descending=True)\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        \n",
    "        # Select top components\n",
    "        self.components = eigenvectors[:, :self.n_components]\n",
    "        self.explained_variance = eigenvalues[:self.n_components]\n",
    "        \n",
    "        # Calculate variance ratios\n",
    "        total_var = torch.sum(eigenvalues)\n",
    "        explained_var_ratio = self.explained_variance / total_var\n",
    "        cumulative_var = torch.cumsum(explained_var_ratio, dim=0)\n",
    "        \n",
    "        print(f\"Original dimension: {X.shape[1]}\")\n",
    "        print(f\"Reduced dimension: {self.n_components}\")\n",
    "        print(f\"Total variance explained: {cumulative_var[-1].item():.4f}\")\n",
    "        print(f\"Computation done on: GPU\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data on GPU\"\"\"\n",
    "        X_centered = X - self.mean\n",
    "        return torch.mm(X_centered, self.components)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit and transform on GPU\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "# ============================================================================\n",
    "# 6. DATA SPLITTING (GPU)\n",
    "# ============================================================================\n",
    "class DataSplitter:\n",
    "    \"\"\"GPU-based data splitting\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle_data(X, y, seed=42):\n",
    "        \"\"\"Shuffle data on GPU\"\"\"\n",
    "        torch.manual_seed(seed)\n",
    "        indices = torch.randperm(len(X), device=device)\n",
    "        return X[indices], y[indices]\n",
    "    \n",
    "    @staticmethod\n",
    "    def train_test_split(X, y, train_ratio=0.6, seed=42):\n",
    "        \"\"\"Split data on GPU\"\"\"\n",
    "        X_shuffled, y_shuffled = DataSplitter.shuffle_data(X, y, seed)\n",
    "        \n",
    "        n_samples = len(X)\n",
    "        n_train = int(n_samples * train_ratio)\n",
    "        \n",
    "        return X_shuffled[:n_train], X_shuffled[n_train:], y_shuffled[:n_train], y_shuffled[n_train:]\n",
    "# ============================================================================\n",
    "# 7. NAVE BAYES CLASSIFIER (Full GPU Implementation)\n",
    "# ============================================================================\n",
    "class NaiveBayes:\n",
    "    \"\"\"Full GPU-accelerated Gaussian Nave Bayes\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.class_priors = None\n",
    "        self.feature_means = None\n",
    "        self.feature_vars = None\n",
    "        self.training_history = []\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train Nave Bayes on GPU\"\"\"\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"TRAINING: Nave Bayes on GPU (Gaussian)\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        self.classes = torch.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        print(f\"Number of classes: {n_classes}\")\n",
    "        print(f\"Number of features: {n_features}\")\n",
    "        \n",
    "        # Initialize storage on GPU\n",
    "        self.class_priors = torch.zeros(n_classes, device=device)\n",
    "        self.feature_means = torch.zeros(n_classes, n_features, device=device)\n",
    "        self.feature_vars = torch.zeros(n_classes, n_features, device=device)\n",
    "        \n",
    "        # Calculate statistics for each class\n",
    "        for idx, class_label in enumerate(self.classes):\n",
    "            print(f\"\\nProcessing class {int(class_label.item())}...\")\n",
    "            \n",
    "            # Get samples for this class\n",
    "            class_mask = (y == class_label)\n",
    "            X_class = X[class_mask]\n",
    "            \n",
    "            # Calculate prior probability\n",
    "            self.class_priors[idx] = X_class.shape[0] / X.shape[0]\n",
    "            \n",
    "            # Calculate mean and variance for each feature\n",
    "            self.feature_means[idx] = torch.mean(X_class, dim=0)\n",
    "            self.feature_vars[idx] = torch.var(X_class, dim=0) + 1e-9  # Add small constant for numerical stability\n",
    "            \n",
    "            print(f\"  Samples: {X_class.shape[0]}\")\n",
    "            print(f\"  Prior probability: {self.class_priors[idx].item():.4f}\")\n",
    "            \n",
    "            # Store training info\n",
    "            self.training_history.append({\n",
    "                'class': int(class_label.item()),\n",
    "                'n_samples': int(X_class.shape[0]),\n",
    "                'prior': float(self.class_priors[idx].item())\n",
    "            })\n",
    "        \n",
    "        print(\"\\nTraining completed on GPU!\")\n",
    "        return self\n",
    "    \n",
    "    def _calculate_log_likelihood(self, X, class_idx):\n",
    "        \"\"\"Calculate log likelihood for a class on GPU\"\"\"\n",
    "        mean = self.feature_means[class_idx]\n",
    "        var = self.feature_vars[class_idx]\n",
    "        \n",
    "        # Log of Gaussian PDF: -0.5 * (log(2) + log(var) + ((x - mean)^2 / var))\n",
    "        log_likelihood = -0.5 * torch.sum(\n",
    "            torch.log(2 * torch.tensor(np.pi, device=device)) + \n",
    "            torch.log(var) + \n",
    "            ((X - mean) ** 2) / var,\n",
    "            dim=1\n",
    "        )\n",
    "        \n",
    "        return log_likelihood\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict probabilities on GPU\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        # Calculate log posterior for each class\n",
    "        log_posteriors = torch.zeros(n_samples, n_classes, device=device)\n",
    "        \n",
    "        for idx in range(n_classes):\n",
    "            log_prior = torch.log(self.class_priors[idx])\n",
    "            log_likelihood = self._calculate_log_likelihood(X, idx)\n",
    "            log_posteriors[:, idx] = log_prior + log_likelihood\n",
    "        \n",
    "        # Convert log posteriors to probabilities using softmax\n",
    "        # Subtract max for numerical stability\n",
    "        log_posteriors = log_posteriors - torch.max(log_posteriors, dim=1, keepdim=True)[0]\n",
    "        posteriors = torch.exp(log_posteriors)\n",
    "        probabilities = posteriors / torch.sum(posteriors, dim=1, keepdim=True)\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict labels on GPU\"\"\"\n",
    "        probabilities = self.predict_proba(X)\n",
    "        predictions = torch.argmax(probabilities, dim=1)\n",
    "        return self.classes[predictions]\n",
    "# ============================================================================\n",
    "# 8. MODEL EVALUATION\n",
    "# ============================================================================\n",
    "class ModelEvaluator:\n",
    "    \"\"\"GPU-accelerated model evaluation\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def confusion_matrix(y_true, y_pred, n_classes=3):\n",
    "        \"\"\"Compute confusion matrix\"\"\"\n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.cpu().numpy()\n",
    "        if isinstance(y_pred, torch.Tensor):\n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "        \n",
    "        cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "        for true, pred in zip(y_true, y_pred):\n",
    "            cm[int(true), int(pred)] += 1\n",
    "        return cm\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(y_true, y_pred):\n",
    "        \"\"\"Calculate accuracy\"\"\"\n",
    "        if isinstance(y_true, torch.Tensor) and isinstance(y_pred, torch.Tensor):\n",
    "            return (y_true == y_pred).float().mean().item()\n",
    "        return float(np.mean(y_true == y_pred))\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall_f1(y_true, y_pred, n_classes=3):\n",
    "        \"\"\"Calculate metrics\"\"\"\n",
    "        cm = ModelEvaluator.confusion_matrix(y_true, y_pred, n_classes)\n",
    "        \n",
    "        precision = np.zeros(n_classes)\n",
    "        recall = np.zeros(n_classes)\n",
    "        f1 = np.zeros(n_classes)\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            tp = cm[i, i]\n",
    "            fp = np.sum(cm[:, i]) - tp\n",
    "            fn = np.sum(cm[i, :]) - tp\n",
    "            \n",
    "            precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
    "        \n",
    "        return precision, recall, f1\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_confusion_matrix(cm, class_names, filename):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_roc_curve(y_true, y_proba, n_classes, class_names, filename):\n",
    "        \"\"\"Plot ROC curves\"\"\"\n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.cpu().numpy()\n",
    "        if isinstance(y_proba, torch.Tensor):\n",
    "            y_proba = y_proba.cpu().numpy()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            y_true_binary = (y_true == i).astype(int)\n",
    "            y_scores = y_proba[:, i]\n",
    "            \n",
    "            thresholds = np.linspace(0, 1, 100)\n",
    "            tpr_list = []\n",
    "            fpr_list = []\n",
    "            \n",
    "            for thresh in thresholds:\n",
    "                y_pred_binary = (y_scores >= thresh).astype(int)\n",
    "                \n",
    "                tp = np.sum((y_true_binary == 1) & (y_pred_binary == 1))\n",
    "                fp = np.sum((y_true_binary == 0) & (y_pred_binary == 1))\n",
    "                tn = np.sum((y_true_binary == 0) & (y_pred_binary == 0))\n",
    "                fn = np.sum((y_true_binary == 1) & (y_pred_binary == 0))\n",
    "                \n",
    "                tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "                \n",
    "                tpr_list.append(tpr)\n",
    "                fpr_list.append(fpr)\n",
    "            \n",
    "            fpr_array = np.array(fpr_list)\n",
    "            tpr_array = np.array(tpr_list)\n",
    "            \n",
    "            sorted_idx = np.argsort(fpr_array)\n",
    "            fpr_sorted = fpr_array[sorted_idx]\n",
    "            tpr_sorted = tpr_array[sorted_idx]\n",
    "            \n",
    "            auc = np.trapz(tpr_sorted, fpr_sorted)\n",
    "            \n",
    "            plt.plot(fpr_sorted, tpr_sorted, label=f'{class_names[i]} (AUC = {auc:.3f})', linewidth=2)\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves - Multiclass Classification')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_class_distribution(training_history, filename):\n",
    "        \"\"\"Plot class distribution from training\"\"\"\n",
    "        classes = [h['class'] for h in training_history]\n",
    "        n_samples = [h['n_samples'] for h in training_history]\n",
    "        priors = [h['prior'] for h in training_history]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Sample distribution\n",
    "        ax1.bar(classes, n_samples, color=['blue', 'orange', 'green'])\n",
    "        ax1.set_xlabel('Class')\n",
    "        ax1.set_ylabel('Number of Samples')\n",
    "        ax1.set_title('Training Samples per Class')\n",
    "        ax1.set_xticks(classes)\n",
    "        ax1.grid(alpha=0.3)\n",
    "        \n",
    "        # Prior probabilities\n",
    "        ax2.bar(classes, priors, color=['blue', 'orange', 'green'])\n",
    "        ax2.set_xlabel('Class')\n",
    "        ax2.set_ylabel('Prior Probability')\n",
    "        ax2.set_title('Class Prior Probabilities')\n",
    "        ax2.set_xticks(classes)\n",
    "        ax2.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "# ============================================================================\n",
    "# 9. MAIN PIPELINE (Full CUDA with PyTorch)\n",
    "# ============================================================================\n",
    "def main():\n",
    "    \"\"\"Main execution pipeline - Full GPU acceleration with PyTorch\"\"\"\n",
    "    output_dir = \"output_nb_cuda\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CUDA-ACCELERATED LUNG DISEASE CLASSIFICATION\")\n",
    "    print(\"PyTorch CUDA - All Processing on GPU\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Monitor GPU memory\n",
    "    if GPU_AVAILABLE:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\nInitial GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "        print(f\"Initial GPU Memory: {torch.cuda.memory_reserved() / 1e9:.2f} GB reserved\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: Load Dataset (Transfer to GPU)\n",
    "    # ========================================================================\n",
    "    dataset_path = \"chest_xray\"\n",
    "    loader = DatasetLoader(dataset_path)\n",
    "    images, labels = loader.load_dataset(target_size=(256, 256))\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory after loading: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2: Preprocessing (GPU)\n",
    "    # ========================================================================\n",
    "    preprocessor = DataPreprocessor()\n",
    "    \n",
    "    images_aug, labels_aug = preprocessor.augment_data(images, labels, augmentation_factor=2)\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory after augmentation: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    images_clean, labels_clean = preprocessor.remove_outliers_iqr(images_aug, labels_aug)\n",
    "    images_norm = preprocessor.normalize_images(images_clean)\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory after preprocessing: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 3: Feature Extraction (GPU)\n",
    "    # ========================================================================\n",
    "    feature_extractor = RadiomicFeatureExtractor()\n",
    "    features = feature_extractor.extract_all_features(images_norm)\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory after feature extraction: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 4: Feature Fusion (GPU)\n",
    "    # ========================================================================\n",
    "    fusion = FeatureFusion()\n",
    "    features_scaled = fusion.scale_features(features, fit=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 5: Dimensionality Reduction (GPU)\n",
    "    # ========================================================================\n",
    "    pca = PCA(n_components=min(7, features_scaled.shape[1]))\n",
    "    features_pca = pca.fit_transform(features_scaled)\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory after PCA: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 6: Train-Test Split and Model Training (GPU)\n",
    "    # ========================================================================\n",
    "    class_names = ['Normal', 'Bacterial Pneumonia', 'Viral Pneumonia']\n",
    "    train_ratio = 0.6\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"TRAINING WITH {int(train_ratio*100)}% TRAIN / {int((1-train_ratio)*100)}% TEST SPLIT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = DataSplitter.train_test_split(\n",
    "        features_pca, labels_clean, train_ratio=train_ratio\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTrain set: {len(X_train)} samples (GPU)\")\n",
    "    print(f\"Test set: {len(X_test)} samples (GPU)\")\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory before training: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Train Nave Bayes on GPU\n",
    "    # ====================================================================\n",
    "    start_time = time.time()\n",
    "    \n",
    "    nb_model = NaiveBayes()\n",
    "    nb_model.fit(X_train, y_train)\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"\\nGPU Memory after training: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # Predictions (on GPU)\n",
    "    y_pred = nb_model.predict(X_test)\n",
    "    y_proba = nb_model.predict_proba(X_test)\n",
    "    \n",
    "    # Evaluation\n",
    "    cm = ModelEvaluator.confusion_matrix(y_test, y_pred)\n",
    "    accuracy = ModelEvaluator.accuracy(y_test, y_pred)\n",
    "    precision, recall, f1 = ModelEvaluator.precision_recall_f1(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(\"RESULTS (CUDA-Accelerated with PyTorch)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Training Time: {train_time:.2f}s\")\n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"Processing: 100% on {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"\\n{class_name}:\")\n",
    "        print(f\"  Precision: {precision[i]:.4f}\")\n",
    "        print(f\"  Recall: {recall[i]:.4f}\")\n",
    "        print(f\"  F1-Score: {f1[i]:.4f}\")\n",
    "    \n",
    "    # Save visualizations\n",
    "    cm_filename = os.path.join(output_dir, f'confusion_matrix_NB_CUDA_{int(train_ratio*100)}.png')\n",
    "    ModelEvaluator.plot_confusion_matrix(cm, class_names, cm_filename)\n",
    "    \n",
    "    roc_filename = os.path.join(output_dir, f'roc_curve_NB_CUDA_{int(train_ratio*100)}.png')\n",
    "    ModelEvaluator.plot_roc_curve(y_test, y_proba, 3, class_names, roc_filename)\n",
    "    \n",
    "    class_dist_filename = os.path.join(output_dir, f'class_distribution_NB_CUDA_{int(train_ratio*100)}.png')\n",
    "    ModelEvaluator.plot_class_distribution(nb_model.training_history, class_dist_filename)\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        'model': 'Nave Bayes (PyTorch CUDA-Accelerated)',\n",
    "        'gpu': torch.cuda.get_device_name(0) if GPU_AVAILABLE else 'CPU',\n",
    "        'train_ratio': train_ratio,\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision': precision.tolist(),\n",
    "        'recall': recall.tolist(),\n",
    "        'f1_score': f1.tolist(),\n",
    "        'training_time': float(train_time),\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'class_priors': nb_model.class_priors.cpu().numpy().tolist() if GPU_AVAILABLE else nb_model.class_priors.tolist()\n",
    "    }\n",
    "    \n",
    "    results_file = os.path.join(output_dir, 'results_summary_nb_cuda.json')\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nResults saved to: {results_file}\")\n",
    "    print(f\"Visualizations saved to: {output_dir}/\")\n",
    "    \n",
    "    # Final GPU memory status\n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"\\nFinal GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "        print(f\"Peak GPU Memory: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CUDA-ACCELERATED PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 70)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036a4bb0-4a35-473c-9d7c-437f25c9bcf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
