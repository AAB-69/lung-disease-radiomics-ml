{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf9dc68-0756-4463-9a8e-a5ff0066cb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU (CuPy) not available. Using CPU (NumPy).\n",
      "\n",
      "======================================================================\n",
      "HYBRID RADIOMIC FEATURE FUSION FOR LUNG DISEASE CLASSIFICATION\n",
      "======================================================================\n",
      "======================================================================\n",
      "DATASET LOADING AND QUALITY CHECK\n",
      "======================================================================\n",
      "\n",
      "Processing Normal...\n",
      "\n",
      "Processing Pneumonia_bacterial...\n",
      "\n",
      "Processing Pneumonia_viral...\n",
      "\n",
      "======================================================================\n",
      "DATASET STATISTICS\n",
      "======================================================================\n",
      "Normal:\n",
      "  Total: 1583\n",
      "  Loaded: 1583\n",
      "  Rejected: 0\n",
      "Pneumonia_bacterial:\n",
      "  Total: 2780\n",
      "  Loaded: 2780\n",
      "  Rejected: 0\n",
      "Pneumonia_viral:\n",
      "  Total: 1493\n",
      "  Loaded: 1493\n",
      "  Rejected: 0\n",
      "\n",
      "Final Dataset Shape: (5856, 256, 256)\n",
      "Labels Shape: (5856,)\n",
      "\n",
      "======================================================================\n",
      "DATA AUGMENTATION\n",
      "======================================================================\n",
      "Augmenting image 0/5856...\n",
      "Augmenting image 100/5856...\n",
      "Augmenting image 200/5856...\n",
      "Augmenting image 300/5856...\n",
      "Augmenting image 400/5856...\n",
      "Augmenting image 500/5856...\n",
      "Augmenting image 600/5856...\n",
      "Augmenting image 700/5856...\n",
      "Augmenting image 800/5856...\n",
      "Augmenting image 900/5856...\n",
      "Augmenting image 1000/5856...\n",
      "Augmenting image 1100/5856...\n",
      "Augmenting image 1200/5856...\n",
      "Augmenting image 1300/5856...\n",
      "Augmenting image 1400/5856...\n",
      "Augmenting image 1500/5856...\n",
      "Augmenting image 1600/5856...\n",
      "Augmenting image 1700/5856...\n",
      "Augmenting image 1800/5856...\n",
      "Augmenting image 1900/5856...\n",
      "Augmenting image 2000/5856...\n",
      "Augmenting image 2100/5856...\n",
      "Augmenting image 2200/5856...\n",
      "Augmenting image 2300/5856...\n",
      "Augmenting image 2400/5856...\n",
      "Augmenting image 2500/5856...\n",
      "Augmenting image 2600/5856...\n",
      "Augmenting image 2700/5856...\n",
      "Augmenting image 2800/5856...\n",
      "Augmenting image 2900/5856...\n",
      "Augmenting image 3000/5856...\n",
      "Augmenting image 3100/5856...\n",
      "Augmenting image 3200/5856...\n",
      "Augmenting image 3300/5856...\n",
      "Augmenting image 3400/5856...\n",
      "Augmenting image 3500/5856...\n",
      "Augmenting image 3600/5856...\n",
      "Augmenting image 3700/5856...\n",
      "Augmenting image 3800/5856...\n",
      "Augmenting image 3900/5856...\n",
      "Augmenting image 4000/5856...\n",
      "Augmenting image 4100/5856...\n",
      "Augmenting image 4200/5856...\n",
      "Augmenting image 4300/5856...\n",
      "Augmenting image 4400/5856...\n",
      "Augmenting image 4500/5856...\n",
      "Augmenting image 4600/5856...\n",
      "Augmenting image 4700/5856...\n",
      "Augmenting image 4800/5856...\n",
      "Augmenting image 4900/5856...\n",
      "Augmenting image 5000/5856...\n",
      "Augmenting image 5100/5856...\n",
      "Augmenting image 5200/5856...\n",
      "Augmenting image 5300/5856...\n",
      "Augmenting image 5400/5856...\n",
      "Augmenting image 5500/5856...\n",
      "Augmenting image 5600/5856...\n",
      "Augmenting image 5700/5856...\n",
      "Augmenting image 5800/5856...\n",
      "\n",
      "Original dataset size: 5856\n",
      "Augmented dataset size: 17568\n",
      "\n",
      "======================================================================\n",
      "OUTLIER REMOVAL (IQR Method)\n",
      "======================================================================\n",
      "Original samples: 17568\n",
      "Outliers removed: 317\n",
      "Remaining samples: 17251\n",
      "\n",
      "======================================================================\n",
      "IMAGE NORMALIZATION (Z-Score)\n",
      "======================================================================\n",
      "Global Mean: 123.19\n",
      "Global Std: 63.41\n",
      "\n",
      "======================================================================\n",
      "RADIOMIC FEATURE EXTRACTION\n",
      "======================================================================\n",
      "Extracting features from image 0/17251...\n",
      "Extracting features from image 100/17251...\n",
      "Extracting features from image 200/17251...\n",
      "Extracting features from image 300/17251...\n",
      "Extracting features from image 400/17251...\n",
      "Extracting features from image 500/17251...\n",
      "Extracting features from image 600/17251...\n",
      "Extracting features from image 700/17251...\n",
      "Extracting features from image 800/17251...\n",
      "Extracting features from image 900/17251...\n",
      "Extracting features from image 1000/17251...\n",
      "Extracting features from image 1100/17251...\n",
      "Extracting features from image 1200/17251...\n",
      "Extracting features from image 1300/17251...\n",
      "Extracting features from image 1400/17251...\n",
      "Extracting features from image 1500/17251...\n",
      "Extracting features from image 1600/17251...\n",
      "Extracting features from image 1700/17251...\n",
      "Extracting features from image 1800/17251...\n",
      "Extracting features from image 1900/17251...\n",
      "Extracting features from image 2000/17251...\n",
      "Extracting features from image 2100/17251...\n",
      "Extracting features from image 2200/17251...\n",
      "Extracting features from image 2300/17251...\n",
      "Extracting features from image 2400/17251...\n",
      "Extracting features from image 2500/17251...\n",
      "Extracting features from image 2600/17251...\n",
      "Extracting features from image 2700/17251...\n",
      "Extracting features from image 2800/17251...\n",
      "Extracting features from image 2900/17251...\n",
      "Extracting features from image 3000/17251...\n",
      "Extracting features from image 3100/17251...\n",
      "Extracting features from image 3200/17251...\n",
      "Extracting features from image 3300/17251...\n",
      "Extracting features from image 3400/17251...\n",
      "Extracting features from image 3500/17251...\n",
      "Extracting features from image 3600/17251...\n",
      "Extracting features from image 3700/17251...\n",
      "Extracting features from image 3800/17251...\n",
      "Extracting features from image 3900/17251...\n",
      "Extracting features from image 4000/17251...\n",
      "Extracting features from image 4100/17251...\n",
      "Extracting features from image 4200/17251...\n",
      "Extracting features from image 4300/17251...\n",
      "Extracting features from image 4400/17251...\n",
      "Extracting features from image 4500/17251...\n",
      "Extracting features from image 4600/17251...\n",
      "Extracting features from image 4700/17251...\n",
      "Extracting features from image 4800/17251...\n",
      "Extracting features from image 4900/17251...\n",
      "Extracting features from image 5000/17251...\n",
      "Extracting features from image 5100/17251...\n",
      "Extracting features from image 5200/17251...\n",
      "Extracting features from image 5300/17251...\n",
      "Extracting features from image 5400/17251...\n",
      "Extracting features from image 5500/17251...\n",
      "Extracting features from image 5600/17251...\n",
      "Extracting features from image 5700/17251...\n",
      "Extracting features from image 5800/17251...\n",
      "Extracting features from image 5900/17251...\n",
      "Extracting features from image 6000/17251...\n",
      "Extracting features from image 6100/17251...\n",
      "Extracting features from image 6200/17251...\n",
      "Extracting features from image 6300/17251...\n",
      "Extracting features from image 6400/17251...\n",
      "Extracting features from image 6500/17251...\n",
      "Extracting features from image 6600/17251...\n",
      "Extracting features from image 6700/17251...\n",
      "Extracting features from image 6800/17251...\n",
      "Extracting features from image 6900/17251...\n",
      "Extracting features from image 7000/17251...\n",
      "Extracting features from image 7100/17251...\n",
      "Extracting features from image 7200/17251...\n",
      "Extracting features from image 7300/17251...\n",
      "Extracting features from image 7400/17251...\n",
      "Extracting features from image 7500/17251...\n",
      "Extracting features from image 7600/17251...\n",
      "Extracting features from image 7700/17251...\n",
      "Extracting features from image 7800/17251...\n",
      "Extracting features from image 7900/17251...\n",
      "Extracting features from image 8000/17251...\n",
      "Extracting features from image 8100/17251...\n",
      "Extracting features from image 8200/17251...\n",
      "Extracting features from image 8300/17251...\n",
      "Extracting features from image 8400/17251...\n",
      "Extracting features from image 8500/17251...\n",
      "Extracting features from image 8600/17251...\n",
      "Extracting features from image 8700/17251...\n",
      "Extracting features from image 8800/17251...\n",
      "Extracting features from image 8900/17251...\n",
      "Extracting features from image 9000/17251...\n",
      "Extracting features from image 9100/17251...\n",
      "Extracting features from image 9200/17251...\n",
      "Extracting features from image 9300/17251...\n",
      "Extracting features from image 9400/17251...\n",
      "Extracting features from image 9500/17251...\n",
      "Extracting features from image 9600/17251...\n",
      "Extracting features from image 9700/17251...\n",
      "Extracting features from image 9800/17251...\n",
      "Extracting features from image 9900/17251...\n",
      "Extracting features from image 10000/17251...\n",
      "Extracting features from image 10100/17251...\n",
      "Extracting features from image 10200/17251...\n",
      "Extracting features from image 10300/17251...\n",
      "Extracting features from image 10400/17251...\n",
      "Extracting features from image 10500/17251...\n",
      "Extracting features from image 10600/17251...\n",
      "Extracting features from image 10700/17251...\n",
      "Extracting features from image 10800/17251...\n",
      "Extracting features from image 10900/17251...\n",
      "Extracting features from image 11000/17251...\n",
      "Extracting features from image 11100/17251...\n",
      "Extracting features from image 11200/17251...\n",
      "Extracting features from image 11300/17251...\n",
      "Extracting features from image 11400/17251...\n",
      "Extracting features from image 11500/17251...\n",
      "Extracting features from image 11600/17251...\n",
      "Extracting features from image 11700/17251...\n",
      "Extracting features from image 11800/17251...\n",
      "Extracting features from image 11900/17251...\n",
      "Extracting features from image 12000/17251...\n",
      "Extracting features from image 12100/17251...\n",
      "Extracting features from image 12200/17251...\n",
      "Extracting features from image 12300/17251...\n",
      "Extracting features from image 12400/17251...\n",
      "Extracting features from image 12500/17251...\n",
      "Extracting features from image 12600/17251...\n",
      "Extracting features from image 12700/17251...\n",
      "Extracting features from image 12800/17251...\n",
      "Extracting features from image 12900/17251...\n",
      "Extracting features from image 13000/17251...\n",
      "Extracting features from image 13100/17251...\n",
      "Extracting features from image 13200/17251...\n",
      "Extracting features from image 13300/17251...\n",
      "Extracting features from image 13400/17251...\n",
      "Extracting features from image 13500/17251...\n",
      "Extracting features from image 13600/17251...\n",
      "Extracting features from image 13700/17251...\n",
      "Extracting features from image 13800/17251...\n",
      "Extracting features from image 13900/17251...\n",
      "Extracting features from image 14000/17251...\n",
      "Extracting features from image 14100/17251...\n",
      "Extracting features from image 14200/17251...\n",
      "Extracting features from image 14300/17251...\n",
      "Extracting features from image 14400/17251...\n",
      "Extracting features from image 14500/17251...\n",
      "Extracting features from image 14600/17251...\n",
      "Extracting features from image 14700/17251...\n",
      "Extracting features from image 14800/17251...\n",
      "Extracting features from image 14900/17251...\n",
      "Extracting features from image 15000/17251...\n",
      "Extracting features from image 15100/17251...\n",
      "Extracting features from image 15200/17251...\n",
      "Extracting features from image 15300/17251...\n",
      "Extracting features from image 15400/17251...\n",
      "Extracting features from image 15500/17251...\n",
      "Extracting features from image 15600/17251...\n",
      "Extracting features from image 15700/17251...\n",
      "Extracting features from image 15800/17251...\n",
      "Extracting features from image 15900/17251...\n",
      "Extracting features from image 16000/17251...\n",
      "Extracting features from image 16100/17251...\n",
      "Extracting features from image 16200/17251...\n",
      "Extracting features from image 16300/17251...\n",
      "Extracting features from image 16400/17251...\n",
      "Extracting features from image 16500/17251...\n",
      "Extracting features from image 16600/17251...\n",
      "Extracting features from image 16700/17251...\n",
      "Extracting features from image 16800/17251...\n",
      "Extracting features from image 16900/17251...\n",
      "Extracting features from image 17000/17251...\n",
      "Extracting features from image 17100/17251...\n",
      "Extracting features from image 17200/17251...\n",
      "\n",
      "Total features extracted per image: 156\n",
      "Feature breakdown:\n",
      "  - Statistical: 8\n",
      "  - Texture (GLCM): 20\n",
      "  - Gabor: 12\n",
      "  - HOG: 100\n",
      "  - Wavelet: 16\n",
      "\n",
      "======================================================================\n",
      "FEATURE SCALING (Z-Score Normalization)\n",
      "======================================================================\n",
      "Fitted scaling parameters\n",
      "Scaled features shape: (17251, 156)\n",
      "Mean of scaled features: 0.0000\n",
      "Std of scaled features: 1.0000\n",
      "\n",
      "======================================================================\n",
      "DIMENSIONALITY REDUCTION (PCA - 50 components)\n",
      "======================================================================\n",
      "Original feature dimension: 156\n",
      "Reduced feature dimension: 50\n",
      "Explained variance ratio: [0.25051415 0.10353698 0.05734164 0.03766788 0.03299413]\n",
      "Cumulative variance (first 5 components): [0.25051415 0.35405114 0.41139277 0.44906065 0.48205478]\n",
      "Total variance explained: 0.8638\n",
      "\n",
      "======================================================================\n",
      "TRAINING WITH 60% TRAIN / 40% TEST SPLIT\n",
      "======================================================================\n",
      "\n",
      "Train set: 10350 samples\n",
      "Test set: 6901 samples\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TRAINING: Logistic Regression\n",
      "----------------------------------------------------------------------\n",
      "Iteration 0, Loss: 1.1128, Accuracy: 0.3021\n",
      "Iteration 100, Loss: 0.7220, Accuracy: 0.7063\n",
      "Iteration 200, Loss: 0.7146, Accuracy: 0.7075\n",
      "Iteration 300, Loss: 0.7131, Accuracy: 0.7073\n",
      "Iteration 400, Loss: 0.7127, Accuracy: 0.7076\n",
      "\n",
      "Results:\n",
      "Accuracy: 0.7077\n",
      "Training Time: 1.15s\n",
      "\n",
      "Normal:\n",
      "  Precision: 0.7351\n",
      "  Recall: 0.8077\n",
      "  F1-Score: 0.7697\n",
      "\n",
      "Bacterial Pneumonia:\n",
      "  Precision: 0.7125\n",
      "  Recall: 0.7979\n",
      "  F1-Score: 0.7528\n",
      "\n",
      "Viral Pneumonia:\n",
      "  Precision: 0.6438\n",
      "  Recall: 0.4285\n",
      "  F1-Score: 0.5145\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "\n",
      "Results saved to: output_run2\\results_summary.json\n",
      "Visualizations saved to: output_run2/\n",
      "\n",
      "======================================================================\n",
      "PIPELINE COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU support\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"GPU (CuPy) detected and will be used for training!\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"GPU (CuPy) not available. Using CPU (NumPy).\")\n",
    "    cp = np  # Fallback to numpy\n",
    "\n",
    "# Select computation library\n",
    "xp = cp if GPU_AVAILABLE else np\n",
    "\n",
    "# ============================================================================\n",
    "# 1. DATASET PREPARATION AND LOADING\n",
    "# ============================================================================\n",
    "\n",
    "class DatasetLoader:\n",
    "    \"\"\"Handles dataset loading, quality checking, and initial preprocessing\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.categories = ['Normal', 'Pneumonia_bacterial', 'Pneumonia_viral']\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.label_map = {'Normal': 0, 'Pneumonia_bacterial': 1, 'Pneumonia_viral': 2}\n",
    "        \n",
    "    def check_image_quality(self, img_path):\n",
    "        \"\"\"Check if image is corrupted or low quality\"\"\"\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                return False, \"Corrupted\"\n",
    "            \n",
    "            # Check resolution (minimum 64x64)\n",
    "            if img.shape[0] < 64 or img.shape[1] < 64:\n",
    "                return False, \"Low resolution\"\n",
    "            \n",
    "            # Check if image is too dark or too bright\n",
    "            mean_intensity = np.mean(img)\n",
    "            if mean_intensity < 10 or mean_intensity > 245:\n",
    "                return False, \"Poor contrast\"\n",
    "            \n",
    "            return True, \"OK\"\n",
    "        except Exception as e:\n",
    "            return False, str(e)\n",
    "    \n",
    "    def load_dataset(self, target_size=(256, 256)):\n",
    "        \"\"\"Load and preprocess dataset\"\"\"\n",
    "        print(\"=\" * 70)\n",
    "        print(\"DATASET LOADING AND QUALITY CHECK\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        stats = {cat: {'total': 0, 'loaded': 0, 'rejected': 0} for cat in self.categories}\n",
    "        \n",
    "        for category in self.categories:\n",
    "            cat_path = os.path.join(self.dataset_path, category)\n",
    "            if not os.path.exists(cat_path):\n",
    "                print(f\"Warning: {category} folder not found!\")\n",
    "                continue\n",
    "            \n",
    "            files = [f for f in os.listdir(cat_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            stats[category]['total'] = len(files)\n",
    "            \n",
    "            print(f\"\\nProcessing {category}...\")\n",
    "            for filename in files:\n",
    "                img_path = os.path.join(cat_path, filename)\n",
    "                is_valid, reason = self.check_image_quality(img_path)\n",
    "                \n",
    "                if is_valid:\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img_resized = cv2.resize(img, target_size)\n",
    "                    self.images.append(img_resized)\n",
    "                    self.labels.append(self.label_map[category])\n",
    "                    stats[category]['loaded'] += 1\n",
    "                else:\n",
    "                    stats[category]['rejected'] += 1\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"DATASET STATISTICS\")\n",
    "        print(\"=\" * 70)\n",
    "        for cat in self.categories:\n",
    "            print(f\"{cat}:\")\n",
    "            print(f\"  Total: {stats[cat]['total']}\")\n",
    "            print(f\"  Loaded: {stats[cat]['loaded']}\")\n",
    "            print(f\"  Rejected: {stats[cat]['rejected']}\")\n",
    "        \n",
    "        self.images = np.array(self.images)\n",
    "        self.labels = np.array(self.labels)\n",
    "        \n",
    "        print(f\"\\nFinal Dataset Shape: {self.images.shape}\")\n",
    "        print(f\"Labels Shape: {self.labels.shape}\")\n",
    "        \n",
    "        return self.images, self.labels\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def apply_clahe(self, image):\n",
    "        \"\"\"Apply Contrast Limited Adaptive Histogram Equalization\"\"\"\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        return clahe.apply(image)\n",
    "    \n",
    "    def add_gaussian_noise(self, image, mean=0, sigma=10):\n",
    "        \"\"\"Add Gaussian noise for augmentation\"\"\"\n",
    "        noise = np.random.normal(mean, sigma, image.shape)\n",
    "        noisy_img = image + noise\n",
    "        return np.clip(noisy_img, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    def rotate_image(self, image, angle):\n",
    "        \"\"\"Rotate image by specified angle\"\"\"\n",
    "        h, w = image.shape\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        rotated = cv2.warpAffine(image, M, (w, h))\n",
    "        return rotated\n",
    "    \n",
    "    def flip_image(self, image, direction='horizontal'):\n",
    "        \"\"\"Flip image horizontally or vertically\"\"\"\n",
    "        if direction == 'horizontal':\n",
    "            return cv2.flip(image, 1)\n",
    "        else:\n",
    "            return cv2.flip(image, 0)\n",
    "    \n",
    "    def augment_data(self, images, labels, augmentation_factor=2):\n",
    "        \"\"\"Apply data augmentation techniques\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"DATA AUGMENTATION\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        augmented_images = list(images)\n",
    "        augmented_labels = list(labels)\n",
    "        \n",
    "        n_original = len(images)\n",
    "        \n",
    "        for i, (img, label) in enumerate(zip(images, labels)):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Augmenting image {i}/{n_original}...\")\n",
    "            \n",
    "            # Apply CLAHE\n",
    "            img_clahe = self.apply_clahe(img)\n",
    "            augmented_images.append(img_clahe)\n",
    "            augmented_labels.append(label)\n",
    "            \n",
    "            # Rotation\n",
    "            if augmentation_factor >= 2:\n",
    "                img_rot = self.rotate_image(img, 15)\n",
    "                augmented_images.append(img_rot)\n",
    "                augmented_labels.append(label)\n",
    "            \n",
    "            # Flipping\n",
    "            if augmentation_factor >= 3:\n",
    "                img_flip = self.flip_image(img, 'horizontal')\n",
    "                augmented_images.append(img_flip)\n",
    "                augmented_labels.append(label)\n",
    "            \n",
    "            # Noise addition\n",
    "            if augmentation_factor >= 4:\n",
    "                img_noise = self.add_gaussian_noise(img, sigma=5)\n",
    "                augmented_images.append(img_noise)\n",
    "                augmented_labels.append(label)\n",
    "        \n",
    "        print(f\"\\nOriginal dataset size: {n_original}\")\n",
    "        print(f\"Augmented dataset size: {len(augmented_images)}\")\n",
    "        \n",
    "        return np.array(augmented_images), np.array(augmented_labels)\n",
    "    \n",
    "    def remove_outliers_iqr(self, images, labels):\n",
    "        \"\"\"Remove outliers using IQR method based on image statistics\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"OUTLIER REMOVAL (IQR Method)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Calculate mean intensity for each image\n",
    "        mean_intensities = np.array([np.mean(img) for img in images])\n",
    "        \n",
    "        Q1 = np.percentile(mean_intensities, 25)\n",
    "        Q3 = np.percentile(mean_intensities, 75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Keep only non-outliers\n",
    "        mask = (mean_intensities >= lower_bound) & (mean_intensities <= upper_bound)\n",
    "        \n",
    "        print(f\"Original samples: {len(images)}\")\n",
    "        print(f\"Outliers removed: {np.sum(~mask)}\")\n",
    "        print(f\"Remaining samples: {np.sum(mask)}\")\n",
    "        \n",
    "        return images[mask], labels[mask]\n",
    "    \n",
    "    def normalize_images(self, images):\n",
    "        \"\"\"Z-score normalization\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"IMAGE NORMALIZATION (Z-Score)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Flatten all images for global statistics\n",
    "        all_pixels = images.reshape(-1)\n",
    "        self.mean = np.mean(all_pixels)\n",
    "        self.std = np.std(all_pixels)\n",
    "        \n",
    "        print(f\"Global Mean: {self.mean:.2f}\")\n",
    "        print(f\"Global Std: {self.std:.2f}\")\n",
    "        \n",
    "        # Normalize\n",
    "        normalized = (images - self.mean) / (self.std + 1e-8)\n",
    "        \n",
    "        return normalized\n",
    "\n",
    "# ============================================================================\n",
    "# 3. RADIOMIC FEATURE EXTRACTION\n",
    "# ============================================================================\n",
    "\n",
    "class RadiomicFeatureExtractor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # Statistical Features\n",
    "    def extract_statistical_features(self, image):\n",
    "        \"\"\"Extract first-order statistical features\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Mean\n",
    "        features.append(np.mean(image))\n",
    "        \n",
    "        # Variance\n",
    "        features.append(np.var(image))\n",
    "        \n",
    "        # Standard Deviation\n",
    "        features.append(np.std(image))\n",
    "        \n",
    "        # Entropy\n",
    "        hist, _ = np.histogram(image, bins=256, range=(0, 256), density=True)\n",
    "        hist = hist[hist > 0]  # Remove zero probabilities\n",
    "        entropy = -np.sum(hist * np.log2(hist))\n",
    "        features.append(entropy)\n",
    "        \n",
    "        # Skewness\n",
    "        mean = np.mean(image)\n",
    "        std = np.std(image)\n",
    "        skewness = np.mean(((image - mean) / std) ** 3)\n",
    "        features.append(skewness)\n",
    "        \n",
    "        # Kurtosis\n",
    "        kurtosis = np.mean(((image - mean) / std) ** 4) - 3\n",
    "        features.append(kurtosis)\n",
    "        \n",
    "        # Energy\n",
    "        features.append(np.sum(image ** 2))\n",
    "        \n",
    "        # RMS (Root Mean Square)\n",
    "        features.append(np.sqrt(np.mean(image ** 2)))\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    # GLCM Texture Features\n",
    "    def compute_glcm(self, image, distance=1, angle=0):\n",
    "        \"\"\"Compute Gray Level Co-occurrence Matrix\"\"\"\n",
    "        # Quantize image to reduce levels (0-31)\n",
    "        levels = 32\n",
    "        image_quantized = (image / (256 / levels)).astype(np.int32)\n",
    "        image_quantized = np.clip(image_quantized, 0, levels - 1)\n",
    "        \n",
    "        # Initialize GLCM\n",
    "        glcm = np.zeros((levels, levels), dtype=np.float64)\n",
    "        \n",
    "        rows, cols = image_quantized.shape\n",
    "        \n",
    "        # Compute offset based on angle\n",
    "        if angle == 0:\n",
    "            dx, dy = 0, distance\n",
    "        elif angle == 45:\n",
    "            dx, dy = distance, distance\n",
    "        elif angle == 90:\n",
    "            dx, dy = distance, 0\n",
    "        else:  # 135\n",
    "            dx, dy = distance, -distance\n",
    "        \n",
    "        # Build GLCM\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                ni, nj = i + dx, j + dy\n",
    "                if 0 <= ni < rows and 0 <= nj < cols:\n",
    "                    glcm[image_quantized[i, j], image_quantized[ni, nj]] += 1\n",
    "        \n",
    "        # Normalize\n",
    "        glcm = glcm / (np.sum(glcm) + 1e-10)\n",
    "        \n",
    "        return glcm\n",
    "    \n",
    "    def extract_glcm_features(self, glcm):\n",
    "        \"\"\"Extract Haralick texture features from GLCM\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Contrast\n",
    "        contrast = 0\n",
    "        for i in range(glcm.shape[0]):\n",
    "            for j in range(glcm.shape[1]):\n",
    "                contrast += glcm[i, j] * (i - j) ** 2\n",
    "        features.append(contrast)\n",
    "        \n",
    "        # Dissimilarity\n",
    "        dissimilarity = 0\n",
    "        for i in range(glcm.shape[0]):\n",
    "            for j in range(glcm.shape[1]):\n",
    "                dissimilarity += glcm[i, j] * abs(i - j)\n",
    "        features.append(dissimilarity)\n",
    "        \n",
    "        # Homogeneity\n",
    "        homogeneity = 0\n",
    "        for i in range(glcm.shape[0]):\n",
    "            for j in range(glcm.shape[1]):\n",
    "                homogeneity += glcm[i, j] / (1 + (i - j) ** 2)\n",
    "        features.append(homogeneity)\n",
    "        \n",
    "        # Energy (Angular Second Moment)\n",
    "        energy = np.sum(glcm ** 2)\n",
    "        features.append(energy)\n",
    "        \n",
    "        # Correlation\n",
    "        mu_i = np.sum(np.arange(glcm.shape[0]).reshape(-1, 1) * glcm)\n",
    "        mu_j = np.sum(np.arange(glcm.shape[1]).reshape(1, -1) * glcm)\n",
    "        sigma_i = np.sqrt(np.sum(((np.arange(glcm.shape[0]).reshape(-1, 1) - mu_i) ** 2) * glcm))\n",
    "        sigma_j = np.sqrt(np.sum(((np.arange(glcm.shape[1]).reshape(1, -1) - mu_j) ** 2) * glcm))\n",
    "        \n",
    "        correlation = 0\n",
    "        for i in range(glcm.shape[0]):\n",
    "            for j in range(glcm.shape[1]):\n",
    "                correlation += ((i - mu_i) * (j - mu_j) * glcm[i, j]) / (sigma_i * sigma_j + 1e-10)\n",
    "        features.append(correlation)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def extract_texture_features(self, image):\n",
    "        \"\"\"Extract GLCM features for multiple angles\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Compute GLCM for 4 angles (0, 45, 90, 135 degrees)\n",
    "        for angle in [0, 45, 90, 135]:\n",
    "            glcm = self.compute_glcm(image, distance=1, angle=angle)\n",
    "            glcm_features = self.extract_glcm_features(glcm)\n",
    "            features.extend(glcm_features)\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    # Gabor Filter Features\n",
    "    def gabor_kernel(self, ksize, sigma, theta, lambd, gamma, psi):\n",
    "        \"\"\"Create Gabor kernel\"\"\"\n",
    "        sigma_x = sigma\n",
    "        sigma_y = sigma / gamma\n",
    "        \n",
    "        xmax = ksize // 2\n",
    "        ymax = ksize // 2\n",
    "        xmin = -xmax\n",
    "        ymin = -ymax\n",
    "        \n",
    "        kernel = np.zeros((ksize, ksize))\n",
    "        \n",
    "        for y in range(ymin, ymax + 1):\n",
    "            for x in range(xmin, xmax + 1):\n",
    "                x_theta = x * np.cos(theta) + y * np.sin(theta)\n",
    "                y_theta = -x * np.sin(theta) + y * np.cos(theta)\n",
    "                \n",
    "                exp_part = np.exp(-0.5 * (x_theta**2 / sigma_x**2 + y_theta**2 / sigma_y**2))\n",
    "                cos_part = np.cos(2 * np.pi * x_theta / lambd + psi)\n",
    "                \n",
    "                kernel[y + ymax, x + xmax] = exp_part * cos_part\n",
    "        \n",
    "        return kernel\n",
    "    \n",
    "    def extract_gabor_features(self, image):\n",
    "        \"\"\"Extract Gabor filter features\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # Gabor parameters\n",
    "        ksize = 21\n",
    "        sigma = 3\n",
    "        lambd = 10\n",
    "        gamma = 0.5\n",
    "        psi = 0\n",
    "        \n",
    "        # Multiple orientations\n",
    "        for theta in [0, np.pi/4, np.pi/2, 3*np.pi/4]:\n",
    "            kernel = self.gabor_kernel(ksize, sigma, theta, lambd, gamma, psi)\n",
    "            filtered = cv2.filter2D(image.astype(np.float64), -1, kernel)\n",
    "            \n",
    "            # Extract statistics from filtered image\n",
    "            features.append(np.mean(filtered))\n",
    "            features.append(np.std(filtered))\n",
    "            features.append(np.max(filtered))\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    # HOG Features\n",
    "    def extract_hog_features(self, image, cell_size=16, bin_count=9):\n",
    "        \"\"\"Extract Histogram of Oriented Gradients features\"\"\"\n",
    "        # Compute gradients\n",
    "        gx = cv2.Sobel(image.astype(np.float64), cv2.CV_64F, 1, 0, ksize=3)\n",
    "        gy = cv2.Sobel(image.astype(np.float64), cv2.CV_64F, 0, 1, ksize=3)\n",
    "        \n",
    "        # Compute magnitude and angle\n",
    "        magnitude = np.sqrt(gx**2 + gy**2)\n",
    "        angle = np.arctan2(gy, gx) * (180 / np.pi) % 180\n",
    "        \n",
    "        # Divide image into cells\n",
    "        h, w = image.shape\n",
    "        cell_h = h // cell_size\n",
    "        cell_w = w // cell_size\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        for i in range(cell_h):\n",
    "            for j in range(cell_w):\n",
    "                cell_mag = magnitude[i*cell_size:(i+1)*cell_size, j*cell_size:(j+1)*cell_size]\n",
    "                cell_ang = angle[i*cell_size:(i+1)*cell_size, j*cell_size:(j+1)*cell_size]\n",
    "                \n",
    "                # Create histogram\n",
    "                hist, _ = np.histogram(cell_ang, bins=bin_count, range=(0, 180), weights=cell_mag)\n",
    "                features.extend(hist)\n",
    "        \n",
    "        return np.array(features[:100])  # Limit to 100 features\n",
    "    \n",
    "    # Wavelet Features\n",
    "    def dwt_2d(self, image):\n",
    "        \"\"\"Simple 2D Discrete Wavelet Transform (Haar)\"\"\"\n",
    "        h, w = image.shape\n",
    "        \n",
    "        # Ensure even dimensions\n",
    "        if h % 2 != 0:\n",
    "            image = image[:-1, :]\n",
    "            h -= 1\n",
    "        if w % 2 != 0:\n",
    "            image = image[:, :-1]\n",
    "            w -= 1\n",
    "        \n",
    "        # Low-pass and high-pass filters\n",
    "        low = np.array([1, 1]) / np.sqrt(2)\n",
    "        high = np.array([1, -1]) / np.sqrt(2)\n",
    "        \n",
    "        # Convolve rows\n",
    "        rows_low = np.zeros((h, w // 2))\n",
    "        rows_high = np.zeros((h, w // 2))\n",
    "        \n",
    "        for i in range(h):\n",
    "            for j in range(w // 2):\n",
    "                rows_low[i, j] = np.sum(image[i, 2*j:2*j+2] * low)\n",
    "                rows_high[i, j] = np.sum(image[i, 2*j:2*j+2] * high)\n",
    "        \n",
    "        # Convolve columns\n",
    "        LL = np.zeros((h // 2, w // 2))\n",
    "        LH = np.zeros((h // 2, w // 2))\n",
    "        HL = np.zeros((h // 2, w // 2))\n",
    "        HH = np.zeros((h // 2, w // 2))\n",
    "        \n",
    "        for j in range(w // 2):\n",
    "            for i in range(h // 2):\n",
    "                LL[i, j] = np.sum(rows_low[2*i:2*i+2, j] * low)\n",
    "                LH[i, j] = np.sum(rows_low[2*i:2*i+2, j] * high)\n",
    "                HL[i, j] = np.sum(rows_high[2*i:2*i+2, j] * low)\n",
    "                HH[i, j] = np.sum(rows_high[2*i:2*i+2, j] * high)\n",
    "        \n",
    "        return LL, LH, HL, HH\n",
    "    \n",
    "    def extract_wavelet_features(self, image):\n",
    "        \"\"\"Extract wavelet-based features\"\"\"\n",
    "        # Convert to uint8 if normalized\n",
    "        if image.dtype != np.uint8:\n",
    "            img_min = np.min(image)\n",
    "            img_max = np.max(image)\n",
    "            image = ((image - img_min) / (img_max - img_min + 1e-8) * 255).astype(np.uint8)\n",
    "        \n",
    "        LL, LH, HL, HH = self.dwt_2d(image.astype(np.float64))\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        # Extract statistics from each subband\n",
    "        for subband in [LL, LH, HL, HH]:\n",
    "            features.append(np.mean(subband))\n",
    "            features.append(np.std(subband))\n",
    "            features.append(np.max(subband))\n",
    "            features.append(np.min(subband))\n",
    "        \n",
    "        return np.array(features)\n",
    "    \n",
    "    def extract_all_features(self, images):\n",
    "        \"\"\"Extract all radiomic features from images\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"RADIOMIC FEATURE EXTRACTION\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_features = []\n",
    "        n_images = len(images)\n",
    "        \n",
    "        for idx, img in enumerate(images):\n",
    "            if idx % 100 == 0:\n",
    "                print(f\"Extracting features from image {idx}/{n_images}...\")\n",
    "            \n",
    "            # Convert to uint8 for some operations\n",
    "            if img.dtype != np.uint8:\n",
    "                img_min = np.min(img)\n",
    "                img_max = np.max(img)\n",
    "                img_uint8 = ((img - img_min) / (img_max - img_min + 1e-8) * 255).astype(np.uint8)\n",
    "            else:\n",
    "                img_uint8 = img\n",
    "            \n",
    "            # Extract different feature types\n",
    "            stat_features = self.extract_statistical_features(img_uint8)\n",
    "            texture_features = self.extract_texture_features(img_uint8)\n",
    "            gabor_features = self.extract_gabor_features(img_uint8)\n",
    "            hog_features = self.extract_hog_features(img_uint8)\n",
    "            wavelet_features = self.extract_wavelet_features(img)\n",
    "            \n",
    "            # Concatenate all features\n",
    "            combined = np.concatenate([\n",
    "                stat_features,\n",
    "                texture_features,\n",
    "                gabor_features,\n",
    "                hog_features,\n",
    "                wavelet_features\n",
    "            ])\n",
    "            \n",
    "            all_features.append(combined)\n",
    "        \n",
    "        all_features = np.array(all_features)\n",
    "        \n",
    "        print(f\"\\nTotal features extracted per image: {all_features.shape[1]}\")\n",
    "        print(f\"Feature breakdown:\")\n",
    "        print(f\"  - Statistical: {len(stat_features)}\")\n",
    "        print(f\"  - Texture (GLCM): {len(texture_features)}\")\n",
    "        print(f\"  - Gabor: {len(gabor_features)}\")\n",
    "        print(f\"  - HOG: {len(hog_features)}\")\n",
    "        print(f\"  - Wavelet: {len(wavelet_features)}\")\n",
    "        \n",
    "        return all_features\n",
    "\n",
    "# ============================================================================\n",
    "# 4. FEATURE FUSION AND SCALING\n",
    "# ============================================================================\n",
    "\n",
    "class FeatureFusion:\n",
    "    \"\"\"\n",
    "    Perform feature fusion and scaling\n",
    "    \n",
    "    Preferred Method: Z-score normalization after concatenation\n",
    "    \n",
    "    Justification:\n",
    "    - Combines complementary information from different feature types\n",
    "    - Z-score ensures all features contribute equally regardless of scale\n",
    "    - Prevents dominance by features with larger magnitudes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def scale_features(self, features, fit=True):\n",
    "        \"\"\"Apply Z-score normalization to features\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"FEATURE SCALING (Z-Score Normalization)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if fit:\n",
    "            self.mean = np.mean(features, axis=0)\n",
    "            self.std = np.std(features, axis=0)\n",
    "            print(\"Fitted scaling parameters\")\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        self.std[self.std == 0] = 1\n",
    "        \n",
    "        scaled = (features - self.mean) / self.std\n",
    "        \n",
    "        print(f\"Scaled features shape: {scaled.shape}\")\n",
    "        print(f\"Mean of scaled features: {np.mean(scaled):.4f}\")\n",
    "        print(f\"Std of scaled features: {np.std(scaled):.4f}\")\n",
    "        \n",
    "        return scaled\n",
    "\n",
    "# ============================================================================\n",
    "# 5. DIMENSIONALITY REDUCTION (PCA)\n",
    "# ============================================================================\n",
    "\n",
    "class PCA:\n",
    "    \"\"\"\n",
    "    Principal Component Analysis for dimensionality reduction\n",
    "    \n",
    "    Preferred Method: Manual PCA implementation\n",
    "    \n",
    "    Justification:\n",
    "    - Reduces computational complexity\n",
    "    - Removes redundant/correlated features\n",
    "    - Retains maximum variance in data\n",
    "    - Improves training time and prevents overfitting\n",
    "    \n",
    "    Reference: Jolliffe & Cadima, 2016\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=50):\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "        self.explained_variance = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit PCA on training data\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"DIMENSIONALITY REDUCTION (PCA - {self.n_components} components)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Center the data\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        X_centered = X - self.mean\n",
    "        \n",
    "        # Compute covariance matrix\n",
    "        cov_matrix = np.cov(X_centered.T)\n",
    "        \n",
    "        # Compute eigenvalues and eigenvectors\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "        \n",
    "        # Sort by eigenvalues\n",
    "        idx = eigenvalues.argsort()[::-1]\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        \n",
    "        # Select top n_components\n",
    "        self.components = eigenvectors[:, :self.n_components]\n",
    "        self.explained_variance = eigenvalues[:self.n_components]\n",
    "        \n",
    "        # Calculate explained variance ratio\n",
    "        total_var = np.sum(eigenvalues)\n",
    "        explained_var_ratio = self.explained_variance / total_var\n",
    "        cumulative_var = np.cumsum(explained_var_ratio)\n",
    "        \n",
    "        print(f\"Original feature dimension: {X.shape[1]}\")\n",
    "        print(f\"Reduced feature dimension: {self.n_components}\")\n",
    "        print(f\"Explained variance ratio: {explained_var_ratio[:5]}\")\n",
    "        print(f\"Cumulative variance (first 5 components): {cumulative_var[:5]}\")\n",
    "        print(f\"Total variance explained: {cumulative_var[-1]:.4f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data to PCA space\"\"\"\n",
    "        X_centered = X - self.mean\n",
    "        return np.dot(X_centered, self.components)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit and transform in one step\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "# ============================================================================\n",
    "# 6. DATA SPLITTING\n",
    "# ============================================================================\n",
    "\n",
    "class DataSplitter:\n",
    "    \"\"\"Manual train-test split implementation\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle_data(X, y, seed=42):\n",
    "        \"\"\"Shuffle data with a given seed\"\"\"\n",
    "        np.random.seed(seed)\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "        return X[indices], y[indices]\n",
    "    \n",
    "    @staticmethod\n",
    "    def train_test_split(X, y, train_ratio=0.6, seed=42):\n",
    "        \"\"\"Split data into train and test sets\"\"\"\n",
    "        X_shuffled, y_shuffled = DataSplitter.shuffle_data(X, y, seed)\n",
    "        \n",
    "        n_samples = len(X)\n",
    "        n_train = int(n_samples * train_ratio)\n",
    "        \n",
    "        X_train = X_shuffled[:n_train]\n",
    "        y_train = y_shuffled[:n_train]\n",
    "        X_test = X_shuffled[n_train:]\n",
    "        y_test = y_shuffled[n_train:]\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    @staticmethod\n",
    "    def k_fold_split(X, y, k=5):\n",
    "        \"\"\"Generate k-fold cross-validation splits\"\"\"\n",
    "        n_samples = len(X)\n",
    "        fold_size = n_samples // k\n",
    "        indices = np.arange(n_samples)\n",
    "        \n",
    "        folds = []\n",
    "        for i in range(k):\n",
    "            test_start = i * fold_size\n",
    "            test_end = (i + 1) * fold_size if i < k - 1 else n_samples\n",
    "            \n",
    "            test_indices = indices[test_start:test_end]\n",
    "            train_indices = np.concatenate([indices[:test_start], indices[test_end:]])\n",
    "            \n",
    "            folds.append((train_indices, test_indices))\n",
    "        \n",
    "        return folds\n",
    "\n",
    "# ============================================================================\n",
    "# 7. MACHINE LEARNING CLASSIFIERS\n",
    "# ============================================================================\n",
    "\n",
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    Manual Logistic Regression implementation using gradient descent with GPU support\n",
    "    \n",
    "    Reference: Hosmer, Lemeshow & Sturdivant, 2013\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000, regularization=0.01):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iter = n_iterations\n",
    "        self.reg = regularization\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.classes = None\n",
    "        self.loss_history = []\n",
    "        self.accuracy_history = []\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        \"\"\"Compute softmax function\"\"\"\n",
    "        exp_z = xp.exp(z - xp.max(z, axis=1, keepdims=True))\n",
    "        return exp_z / xp.sum(exp_z, axis=1, keepdims=True)\n",
    "    \n",
    "    def one_hot_encode(self, y):\n",
    "        \"\"\"Convert labels to one-hot encoding\"\"\"\n",
    "        n_classes = len(self.classes)\n",
    "        n_samples = len(y)\n",
    "        one_hot = xp.zeros((n_samples, n_classes))\n",
    "        for i, label in enumerate(y):\n",
    "            one_hot[i, xp.where(self.classes == label)[0][0]] = 1\n",
    "        return one_hot\n",
    "    \n",
    "    def compute_accuracy(self, X, y):\n",
    "        \"\"\"Compute accuracy on given data\"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        if GPU_AVAILABLE:\n",
    "            predictions = cp.asnumpy(predictions)\n",
    "            y_np = cp.asnumpy(y) if isinstance(y, cp.ndarray) else y\n",
    "        else:\n",
    "            y_np = y\n",
    "        return float(np.mean(predictions == y_np))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train logistic regression model\"\"\"\n",
    "        # Convert to GPU arrays if available\n",
    "        if GPU_AVAILABLE:\n",
    "            X = cp.asarray(X)\n",
    "            y = cp.asarray(y)\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        self.classes = xp.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.weights = xp.random.randn(n_features, n_classes) * 0.01\n",
    "        self.bias = xp.zeros(n_classes)\n",
    "        \n",
    "        # One-hot encode labels\n",
    "        y_encoded = self.one_hot_encode(y)\n",
    "        \n",
    "        # Gradient descent\n",
    "        for iteration in range(self.n_iter):\n",
    "            # Forward pass\n",
    "            z = xp.dot(X, self.weights) + self.bias\n",
    "            y_pred = self.softmax(z)\n",
    "            \n",
    "            # Compute loss (cross-entropy with L2 regularization)\n",
    "            loss = -xp.mean(xp.sum(y_encoded * xp.log(y_pred + 1e-8), axis=1))\n",
    "            loss += self.reg * xp.sum(self.weights ** 2)\n",
    "            \n",
    "            # Store loss\n",
    "            loss_val = float(cp.asnumpy(loss)) if GPU_AVAILABLE else float(loss)\n",
    "            self.loss_history.append(loss_val)\n",
    "            \n",
    "            # Compute accuracy every 10 iterations\n",
    "            if iteration % 10 == 0:\n",
    "                acc = self.compute_accuracy(X, y)\n",
    "                self.accuracy_history.append(acc)\n",
    "            \n",
    "            # Backward pass\n",
    "            error = y_pred - y_encoded\n",
    "            dw = xp.dot(X.T, error) / n_samples + 2 * self.reg * self.weights\n",
    "            db = xp.mean(error, axis=0)\n",
    "            \n",
    "            # Update weights\n",
    "            self.weights -= self.lr * dw\n",
    "            self.bias -= self.lr * db\n",
    "            \n",
    "            if iteration % 100 == 0:\n",
    "                print(f\"Iteration {iteration}, Loss: {loss_val:.4f}, Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict class probabilities\"\"\"\n",
    "        if GPU_AVAILABLE:\n",
    "            X = cp.asarray(X) if not isinstance(X, cp.ndarray) else X\n",
    "        z = xp.dot(X, self.weights) + self.bias\n",
    "        proba = self.softmax(z)\n",
    "        if GPU_AVAILABLE:\n",
    "            proba = cp.asnumpy(proba)\n",
    "        return proba\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        if GPU_AVAILABLE:\n",
    "            X = cp.asarray(X) if not isinstance(X, cp.ndarray) else X\n",
    "        proba = self.predict_proba(X)\n",
    "        predictions = np.argmax(proba, axis=1)\n",
    "        classes_np = cp.asnumpy(self.classes) if GPU_AVAILABLE else self.classes\n",
    "        return classes_np[predictions]\n",
    "\n",
    "# ============================================================================\n",
    "# 8. MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Comprehensive model evaluation with multiple metrics\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def confusion_matrix(y_true, y_pred, n_classes=3):\n",
    "        \"\"\"Compute confusion matrix\"\"\"\n",
    "        cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "        for true, pred in zip(y_true, y_pred):\n",
    "            cm[true, pred] += 1\n",
    "        return cm\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(y_true, y_pred):\n",
    "        \"\"\"Calculate accuracy\"\"\"\n",
    "        return np.mean(y_true == y_pred)\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall_f1(y_true, y_pred, n_classes=3):\n",
    "        \"\"\"Calculate precision, recall, and F1-score for each class\"\"\"\n",
    "        cm = ModelEvaluator.confusion_matrix(y_true, y_pred, n_classes)\n",
    "        \n",
    "        precision = np.zeros(n_classes)\n",
    "        recall = np.zeros(n_classes)\n",
    "        f1 = np.zeros(n_classes)\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            tp = cm[i, i]\n",
    "            fp = np.sum(cm[:, i]) - tp\n",
    "            fn = np.sum(cm[i, :]) - tp\n",
    "            \n",
    "            precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
    "        \n",
    "        return precision, recall, f1\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_confusion_matrix(cm, class_names, filename):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_roc_curve(y_true, y_proba, n_classes, class_names, filename):\n",
    "        \"\"\"Plot ROC curves for multiclass classification\"\"\"\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            # Binary classification for each class\n",
    "            y_true_binary = (y_true == i).astype(int)\n",
    "            y_scores = y_proba[:, i]\n",
    "            \n",
    "            # Compute ROC curve points\n",
    "            thresholds = np.linspace(0, 1, 100)\n",
    "            tpr_list = []\n",
    "            fpr_list = []\n",
    "            \n",
    "            for thresh in thresholds:\n",
    "                y_pred_binary = (y_scores >= thresh).astype(int)\n",
    "                \n",
    "                tp = np.sum((y_true_binary == 1) & (y_pred_binary == 1))\n",
    "                fp = np.sum((y_true_binary == 0) & (y_pred_binary == 1))\n",
    "                tn = np.sum((y_true_binary == 0) & (y_pred_binary == 0))\n",
    "                fn = np.sum((y_true_binary == 1) & (y_pred_binary == 0))\n",
    "                \n",
    "                tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "                \n",
    "                tpr_list.append(tpr)\n",
    "                fpr_list.append(fpr)\n",
    "            \n",
    "            # Compute AUC using trapezoidal rule\n",
    "            fpr_array = np.array(fpr_list)\n",
    "            tpr_array = np.array(tpr_list)\n",
    "            \n",
    "            sorted_idx = np.argsort(fpr_array)\n",
    "            fpr_sorted = fpr_array[sorted_idx]\n",
    "            tpr_sorted = tpr_array[sorted_idx]\n",
    "            \n",
    "            auc = np.trapz(tpr_sorted, fpr_sorted)\n",
    "            \n",
    "            plt.plot(fpr_sorted, tpr_sorted, label=f'{class_names[i]} (AUC = {auc:.3f})', linewidth=2)\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves - Multiclass Classification')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_training_curves(loss_history, accuracy_history, filename):\n",
    "        \"\"\"Plot training loss and accuracy curves\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Loss curve\n",
    "        ax1.plot(loss_history, linewidth=2, color='red')\n",
    "        ax1.set_xlabel('Iteration')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title('Training Loss over Iterations')\n",
    "        ax1.grid(alpha=0.3)\n",
    "        \n",
    "        # Accuracy curve (sampled every 10 iterations)\n",
    "        iterations = np.arange(0, len(loss_history), 10)[:len(accuracy_history)]\n",
    "        ax2.plot(iterations, accuracy_history, linewidth=2, color='blue')\n",
    "        ax2.set_xlabel('Iteration')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_title('Training Accuracy over Iterations')\n",
    "        ax2.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# 9. MAIN PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution pipeline\"\"\"\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = \"output_run2\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"HYBRID RADIOMIC FEATURE FUSION FOR LUNG DISEASE CLASSIFICATION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: Load Dataset\n",
    "    # ========================================================================\n",
    "    dataset_path = \"chest_xray\"\n",
    "    loader = DatasetLoader(dataset_path)\n",
    "    images, labels = loader.load_dataset(target_size=(256, 256))\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2: Preprocessing\n",
    "    # ========================================================================\n",
    "    preprocessor = DataPreprocessor()\n",
    "    \n",
    "    # Data augmentation\n",
    "    images_aug, labels_aug = preprocessor.augment_data(images, labels, augmentation_factor=2)\n",
    "    \n",
    "    # Remove outliers\n",
    "    images_clean, labels_clean = preprocessor.remove_outliers_iqr(images_aug, labels_aug)\n",
    "    \n",
    "    # Normalize\n",
    "    images_norm = preprocessor.normalize_images(images_clean)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 3: Feature Extraction\n",
    "    # ========================================================================\n",
    "    feature_extractor = RadiomicFeatureExtractor()\n",
    "    features = feature_extractor.extract_all_features(images_norm)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 4: Feature Fusion and Scaling\n",
    "    # ========================================================================\n",
    "    fusion = FeatureFusion()\n",
    "    features_scaled = fusion.scale_features(features, fit=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 5: Dimensionality Reduction\n",
    "    # ========================================================================\n",
    "    pca = PCA(n_components=50)\n",
    "    features_pca = pca.fit_transform(features_scaled)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 6: Data Splitting and Model Training\n",
    "    # ========================================================================\n",
    "    class_names = ['Normal', 'Bacterial Pneumonia', 'Viral Pneumonia']\n",
    "    train_ratios = [0.6]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for train_ratio in train_ratios:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"TRAINING WITH {int(train_ratio*100)}% TRAIN / {int((1-train_ratio)*100)}% TEST SPLIT\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = DataSplitter.train_test_split(\n",
    "            features_pca, labels_clean, train_ratio=train_ratio\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nTrain set: {len(X_train)} samples\")\n",
    "        print(f\"Test set: {len(X_test)} samples\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # Train Logistic Regression\n",
    "        # ====================================================================\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"TRAINING: Logistic Regression\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        lr_model = LogisticRegression(learning_rate=0.1, n_iterations=500, regularization=0.01)\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        \n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = lr_model.predict(X_test)\n",
    "        y_proba = lr_model.predict_proba(X_test)\n",
    "        \n",
    "        # Evaluation\n",
    "        cm = ModelEvaluator.confusion_matrix(y_test, y_pred)\n",
    "        accuracy = ModelEvaluator.accuracy(y_test, y_pred)\n",
    "        precision, recall, f1 = ModelEvaluator.precision_recall_f1(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nResults:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Training Time: {train_time:.2f}s\")\n",
    "        \n",
    "        for i, class_name in enumerate(class_names):\n",
    "            print(f\"\\n{class_name}:\")\n",
    "            print(f\"  Precision: {precision[i]:.4f}\")\n",
    "            print(f\"  Recall: {recall[i]:.4f}\")\n",
    "            print(f\"  F1-Score: {f1[i]:.4f}\")\n",
    "        \n",
    "        # Save confusion matrix\n",
    "        cm_filename = os.path.join(output_dir, f'confusion_matrix_LR_{int(train_ratio*100)}.png')\n",
    "        ModelEvaluator.plot_confusion_matrix(cm, class_names, cm_filename)\n",
    "        \n",
    "        # Save ROC curve\n",
    "        roc_filename = os.path.join(output_dir, f'roc_curve_LR_{int(train_ratio*100)}.png')\n",
    "        ModelEvaluator.plot_roc_curve(y_test, y_proba, 3, class_names, roc_filename)\n",
    "        \n",
    "        # Save training curves\n",
    "        training_curves_filename = os.path.join(output_dir, f'training_curves_LR_{int(train_ratio*100)}.png')\n",
    "        ModelEvaluator.plot_training_curves(lr_model.loss_history, lr_model.accuracy_history, training_curves_filename)\n",
    "        \n",
    "        # Store results (convert numpy arrays to lists for JSON serialization)\n",
    "        results.append({\n",
    "            'model': 'Logistic Regression',\n",
    "            'train_ratio': train_ratio,\n",
    "            'accuracy': float(accuracy),\n",
    "            'precision': precision.tolist(),\n",
    "            'recall': recall.tolist(),\n",
    "            'f1_score': f1.tolist(),\n",
    "            'training_time': float(train_time),\n",
    "            'confusion_matrix': cm.tolist(),\n",
    "            'final_loss': float(lr_model.loss_history[-1]) if lr_model.loss_history else 0.0,\n",
    "            'final_train_accuracy': float(lr_model.accuracy_history[-1]) if lr_model.accuracy_history else 0.0\n",
    "        })\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 7: Save Results Summary\n",
    "    # ========================================================================\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SAVING RESULTS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Save results to JSON\n",
    "    results_file = os.path.join(output_dir, 'results_summary.json')\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nResults saved to: {results_file}\")\n",
    "    print(f\"Visualizations saved to: {output_dir}/\")\n",
    "    \n",
    "    # Plot comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    models = [r['model'] for r in results]\n",
    "    accuracies = [r['accuracy'] for r in results]\n",
    "    \n",
    "    plt.bar(range(len(models)), accuracies, color='steelblue')\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Comparison - Accuracy')\n",
    "    plt.xticks(range(len(models)), models, rotation=45, ha='right')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, 'model_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21127ebc-1c41-4e1c-b70c-18b5fc6fa748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20c7bc41-7a82-4555-99aa-45de9b96b09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GPU INITIALIZATION\n",
      "======================================================================\n",
      "GPU Device: NVIDIA GeForce RTX 3060\n",
      "GPU Memory: 12.88 GB\n",
      "CUDA Version: 12.1\n",
      "CUDA enabled - All processing will run on GPU!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "CUDA-ACCELERATED LUNG DISEASE CLASSIFICATION\n",
      "PyTorch CUDA - All Processing on GPU - LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "\n",
      "Initial GPU Memory: 0.00 GB allocated\n",
      "Initial GPU Memory: 0.00 GB reserved\n",
      "======================================================================\n",
      "DATASET LOADING AND QUALITY CHECK\n",
      "======================================================================\n",
      "\n",
      "Processing Normal...\n",
      "\n",
      "Processing Pneumonia_bacterial...\n",
      "\n",
      "Processing Pneumonia_viral...\n",
      "\n",
      "======================================================================\n",
      "DATASET STATISTICS\n",
      "======================================================================\n",
      "Normal:\n",
      "  Total: 1583\n",
      "  Loaded: 1583\n",
      "  Rejected: 0\n",
      "Pneumonia_bacterial:\n",
      "  Total: 2780\n",
      "  Loaded: 2780\n",
      "  Rejected: 0\n",
      "Pneumonia_viral:\n",
      "  Total: 1493\n",
      "  Loaded: 1493\n",
      "  Rejected: 0\n",
      "\n",
      "Transferring data to GPU...\n",
      "Final Dataset Shape: torch.Size([5856, 256, 256])\n",
      "Labels Shape: torch.Size([5856])\n",
      "Data location: cuda:0\n",
      "GPU Memory after loading: 1.54 GB allocated\n",
      "\n",
      "======================================================================\n",
      "DATA AUGMENTATION (GPU-Accelerated)\n",
      "======================================================================\n",
      "Applying CLAHE enhancement...\n",
      " Processing 0/5856...\n",
      " Processing 500/5856...\n",
      " Processing 1000/5856...\n",
      " Processing 1500/5856...\n",
      " Processing 2000/5856...\n",
      " Processing 2500/5856...\n",
      " Processing 3000/5856...\n",
      " Processing 3500/5856...\n",
      " Processing 4000/5856...\n",
      " Processing 4500/5856...\n",
      " Processing 5000/5856...\n",
      " Processing 5500/5856...\n",
      "Applying rotation augmentation...\n",
      " Processing 0/5856...\n",
      " Processing 500/5856...\n",
      " Processing 1000/5856...\n",
      " Processing 1500/5856...\n",
      " Processing 2000/5856...\n",
      " Processing 2500/5856...\n",
      " Processing 3000/5856...\n",
      " Processing 3500/5856...\n",
      " Processing 4000/5856...\n",
      " Processing 4500/5856...\n",
      " Processing 5000/5856...\n",
      " Processing 5500/5856...\n",
      "\n",
      "Original dataset size: 5856\n",
      "Augmented dataset size: 17568\n",
      "Augmentation multiplier: 3.0x\n",
      "Data stored on: cuda:0\n",
      "GPU Memory after augmentation: 6.14 GB allocated\n",
      "\n",
      "======================================================================\n",
      "OUTLIER REMOVAL (IQR Method - GPU)\n",
      "======================================================================\n",
      "Original samples: 17568\n",
      "Outliers removed: 317\n",
      "Remaining samples: 17251\n",
      "\n",
      "======================================================================\n",
      "IMAGE NORMALIZATION (Z-Score - GPU)\n",
      "======================================================================\n",
      "Global Mean: 123.19\n",
      "Global Std: 63.41\n",
      "GPU Memory after preprocessing: 6.06 GB allocated\n",
      "\n",
      "======================================================================\n",
      "RADIOMIC FEATURE EXTRACTION (GPU-Accelerated)\n",
      "======================================================================\n",
      "Feature Categories:\n",
      " 1. Statistical: Mean, Variance, Std\n",
      " 2. Texture: GLCM Contrast, Homogeneity\n",
      " 3. Filter-based: Gabor Mean Response, Gabor Std Response\n",
      "======================================================================\n",
      "Extracting features from image 0/17251...\n",
      "Extracting features from image 500/17251...\n",
      "Extracting features from image 1000/17251...\n",
      "Extracting features from image 1500/17251...\n",
      "Extracting features from image 2000/17251...\n",
      "Extracting features from image 2500/17251...\n",
      "Extracting features from image 3000/17251...\n",
      "Extracting features from image 3500/17251...\n",
      "Extracting features from image 4000/17251...\n",
      "Extracting features from image 4500/17251...\n",
      "Extracting features from image 5000/17251...\n",
      "Extracting features from image 5500/17251...\n",
      "Extracting features from image 6000/17251...\n",
      "Extracting features from image 6500/17251...\n",
      "Extracting features from image 7000/17251...\n",
      "Extracting features from image 7500/17251...\n",
      "Extracting features from image 8000/17251...\n",
      "Extracting features from image 8500/17251...\n",
      "Extracting features from image 9000/17251...\n",
      "Extracting features from image 9500/17251...\n",
      "Extracting features from image 10000/17251...\n",
      "Extracting features from image 10500/17251...\n",
      "Extracting features from image 11000/17251...\n",
      "Extracting features from image 11500/17251...\n",
      "Extracting features from image 12000/17251...\n",
      "Extracting features from image 12500/17251...\n",
      "Extracting features from image 13000/17251...\n",
      "Extracting features from image 13500/17251...\n",
      "Extracting features from image 14000/17251...\n",
      "Extracting features from image 14500/17251...\n",
      "Extracting features from image 15000/17251...\n",
      "Extracting features from image 15500/17251...\n",
      "Extracting features from image 16000/17251...\n",
      "Extracting features from image 16500/17251...\n",
      "Extracting features from image 17000/17251...\n",
      "\n",
      "Total features extracted per image: 7\n",
      "All features stored on: cuda:0\n",
      "GPU Memory after feature extraction: 1.54 GB allocated\n",
      "\n",
      "======================================================================\n",
      "FEATURE SCALING (GPU - Z-Score)\n",
      "======================================================================\n",
      "Fitted scaling parameters on GPU\n",
      "Scaled features shape: torch.Size([17251, 7])\n",
      "Mean: 0.0000\n",
      "Std: 1.0000\n",
      "\n",
      "======================================================================\n",
      "DIMENSIONALITY REDUCTION (PCA on GPU - 7 components)\n",
      "======================================================================\n",
      "Original dimension: 7\n",
      "Reduced dimension: 7\n",
      "Total variance explained: 1.0000\n",
      "Computation done on: GPU\n",
      "GPU Memory after PCA: 1.54 GB allocated\n",
      "\n",
      "======================================================================\n",
      "TRAINING WITH 60% TRAIN / 40% TEST SPLIT\n",
      "======================================================================\n",
      "\n",
      "Train set: 10350 samples (GPU)\n",
      "Test set: 6901 samples (GPU)\n",
      "GPU Memory before training: 1.54 GB allocated\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TRAINING: Logistic Regression on GPU (Multiclass)\n",
      "----------------------------------------------------------------------\n",
      "  Iteration 0: Loss = 1.1002, Accuracy = 0.2664\n",
      "  Iteration 500: Loss = 0.9839, Accuracy = 0.5184\n",
      "  Iteration 1000: Loss = 0.9753, Accuracy = 0.5260\n",
      "  Iteration 1500: Loss = 0.9707, Accuracy = 0.5295\n",
      "Logistic Regression training completed on GPU!\n",
      "\n",
      "GPU Memory after training: 1.54 GB allocated\n",
      "\n",
      "======================================================================\n",
      "RESULTS (CUDA-Accelerated with PyTorch)\n",
      "======================================================================\n",
      "Accuracy: 0.5389\n",
      "Training Time: 0.91s\n",
      "Processing: 100% on NVIDIA GeForce RTX 3060\n",
      "\n",
      "Normal:\n",
      "  Precision: 0.5349\n",
      "  Recall: 0.4191\n",
      "  F1-Score: 0.4699\n",
      "\n",
      "Bacterial Pneumonia:\n",
      "  Precision: 0.5442\n",
      "  Recall: 0.8023\n",
      "  F1-Score: 0.6485\n",
      "\n",
      "Viral Pneumonia:\n",
      "  Precision: 0.5080\n",
      "  Recall: 0.1814\n",
      "  F1-Score: 0.2673\n",
      "\n",
      "Results saved to: output_lr_cuda\\results_summary_lr_cuda.json\n",
      "Visualizations saved to: output_lr_cuda/\n",
      "\n",
      "Final GPU Memory: 1.55 GB allocated\n",
      "Peak GPU Memory: 15.10 GB\n",
      "\n",
      "======================================================================\n",
      "CUDA-ACCELERATED PIPELINE COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch CUDA support\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        GPU_AVAILABLE = True\n",
    "        device = torch.device('cuda:0')\n",
    "        print(\"=\" * 70)\n",
    "        print(\"GPU INITIALIZATION\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "        print(\"CUDA enabled - All processing will run on GPU!\")\n",
    "        print(\"=\" * 70)\n",
    "    else:\n",
    "        GPU_AVAILABLE = False\n",
    "        device = torch.device('cpu')\n",
    "        print(\"WARNING: CUDA not available. Using CPU.\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    device = torch.device('cpu')\n",
    "    print(\"ERROR: PyTorch not available. Please install with: pip install torch torchvision\")\n",
    "    exit(1)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. DATASET PREPARATION AND LOADING\n",
    "# ============================================================================\n",
    "class DatasetLoader:\n",
    "    \"\"\"Handles dataset loading with GPU transfer\"\"\"\n",
    "  \n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.categories = ['Normal', 'Pneumonia_bacterial', 'Pneumonia_viral']\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.label_map = {'Normal': 0, 'Pneumonia_bacterial': 1, 'Pneumonia_viral': 2}\n",
    "      \n",
    "    def check_image_quality(self, img_path):\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                return False, \"Corrupted\"\n",
    "            if img.shape[0] < 64 or img.shape[1] < 64:\n",
    "                return False, \"Low resolution\"\n",
    "            mean_intensity = np.mean(img)\n",
    "            if mean_intensity < 10 or mean_intensity > 245:\n",
    "                return False, \"Poor contrast\"\n",
    "            return True, \"OK\"\n",
    "        except Exception as e:\n",
    "            return False, str(e)\n",
    "  \n",
    "    def load_dataset(self, target_size=(256, 256), max_samples_per_class=None):\n",
    "        print(\"=\" * 70)\n",
    "        print(\"DATASET LOADING AND QUALITY CHECK\")\n",
    "        print(\"=\" * 70)\n",
    "      \n",
    "        stats = {cat: {'total': 0, 'loaded': 0, 'rejected': 0} for cat in self.categories}\n",
    "      \n",
    "        for category in self.categories:\n",
    "            cat_path = os.path.join(self.dataset_path, category)\n",
    "            if not os.path.exists(cat_path):\n",
    "                print(f\"Warning: {category} folder not found!\")\n",
    "                continue\n",
    "          \n",
    "            files = [f for f in os.listdir(cat_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            stats[category]['total'] = len(files)\n",
    "           \n",
    "            if max_samples_per_class is not None:\n",
    "                files = files[:max_samples_per_class]\n",
    "          \n",
    "            print(f\"\\nProcessing {category}...\")\n",
    "            for filename in files:\n",
    "                img_path = os.path.join(cat_path, filename)\n",
    "                is_valid, reason = self.check_image_quality(img_path)\n",
    "              \n",
    "                if is_valid:\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img_resized = cv2.resize(img, target_size)\n",
    "                    self.images.append(img_resized)\n",
    "                    self.labels.append(self.label_map[category])\n",
    "                    stats[category]['loaded'] += 1\n",
    "                else:\n",
    "                    stats[category]['rejected'] += 1\n",
    "      \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"DATASET STATISTICS\")\n",
    "        print(\"=\" * 70)\n",
    "        for cat in self.categories:\n",
    "            print(f\"{cat}:\")\n",
    "            print(f\"  Total: {stats[cat]['total']}\")\n",
    "            print(f\"  Loaded: {stats[cat]['loaded']}\")\n",
    "            print(f\"  Rejected: {stats[cat]['rejected']}\")\n",
    "      \n",
    "        images_np = np.array(self.images, dtype=np.float32)\n",
    "        labels_np = np.array(self.labels, dtype=np.int64)\n",
    "      \n",
    "        print(f\"\\nTransferring data to GPU...\")\n",
    "        self.images = torch.from_numpy(images_np).to(device)\n",
    "        self.labels = torch.from_numpy(labels_np).to(device)\n",
    "      \n",
    "        print(f\"Final Dataset Shape: {self.images.shape}\")\n",
    "        print(f\"Labels Shape: {self.labels.shape}\")\n",
    "        print(f\"Data location: {self.images.device}\")\n",
    "      \n",
    "        return self.images, self.labels\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DATA PREPROCESSING (GPU-Optimized)\n",
    "# ============================================================================\n",
    "class DataPreprocessor:\n",
    "  \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "  \n",
    "    def apply_clahe_batch(self, images):\n",
    "        results = []\n",
    "        for i in range(len(images)):\n",
    "            img_cpu = images[i].cpu().numpy().astype(np.uint8)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            result = clahe.apply(img_cpu)\n",
    "            results.append(result)\n",
    "        return torch.from_numpy(np.stack(results)).to(device)\n",
    "  \n",
    "    def add_gaussian_noise_gpu(self, images, mean=0, sigma=10):\n",
    "        noise = torch.randn_like(images) * sigma + mean\n",
    "        noisy_img = images + noise\n",
    "        return torch.clamp(noisy_img, 0, 255)\n",
    "  \n",
    "    def rotate_image_batch(self, images, angle):\n",
    "        results = []\n",
    "        for i in range(len(images)):\n",
    "            img_cpu = images[i].cpu().numpy().astype(np.uint8)\n",
    "            h, w = img_cpu.shape\n",
    "            center = (w // 2, h // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            rotated = cv2.warpAffine(img_cpu, M, (w, h))\n",
    "            results.append(rotated)\n",
    "        return torch.from_numpy(np.stack(results)).to(device)\n",
    "  \n",
    "    def flip_image_gpu(self, images, direction='horizontal'):\n",
    "        if direction == 'horizontal':\n",
    "            return torch.flip(images, dims=[2])\n",
    "        else:\n",
    "            return torch.flip(images, dims=[1])\n",
    "  \n",
    "    def augment_data(self, images, labels, augmentation_factor=0):\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"DATA AUGMENTATION (GPU-Accelerated)\")\n",
    "        print(\"=\" * 70)\n",
    "      \n",
    "        n_original = len(images)\n",
    "       \n",
    "        if augmentation_factor == 0:\n",
    "            print(\"No augmentation applied - using original data only\")\n",
    "            return images, labels\n",
    "       \n",
    "        batch_size = 50\n",
    "      \n",
    "        final_images = images\n",
    "        final_labels = labels\n",
    "       \n",
    "        if augmentation_factor >= 1:\n",
    "            print(\"Applying CLAHE enhancement...\")\n",
    "            clahe_results = []\n",
    "            for i in range(0, n_original, batch_size):\n",
    "                if i % 500 == 0:\n",
    "                    print(f\" Processing {i}/{n_original}...\")\n",
    "                batch = images[i:i+batch_size]\n",
    "                clahe_batch = self.apply_clahe_batch(batch)\n",
    "                clahe_results.append(clahe_batch)\n",
    "                if GPU_AVAILABLE:\n",
    "                    torch.cuda.empty_cache()\n",
    "           \n",
    "            clahe_images = torch.cat(clahe_results, dim=0)\n",
    "            del clahe_results\n",
    "            if GPU_AVAILABLE:\n",
    "                torch.cuda.empty_cache()\n",
    "           \n",
    "            final_images = torch.cat([final_images, clahe_images], dim=0)\n",
    "            final_labels = torch.cat([final_labels, labels], dim=0)\n",
    "            del clahe_images\n",
    "            if GPU_AVAILABLE:\n",
    "                torch.cuda.empty_cache()\n",
    "      \n",
    "        if augmentation_factor >= 2:\n",
    "            print(\"Applying rotation augmentation...\")\n",
    "            rotation_results = []\n",
    "            for i in range(0, n_original, batch_size):\n",
    "                if i % 500 == 0:\n",
    "                    print(f\" Processing {i}/{n_original}...\")\n",
    "                batch = images[i:i+batch_size]\n",
    "                rot_batch = self.rotate_image_batch(batch, 15)\n",
    "                rotation_results.append(rot_batch)\n",
    "                if GPU_AVAILABLE:\n",
    "                    torch.cuda.empty_cache()\n",
    "           \n",
    "            rotation_images = torch.cat(rotation_results, dim=0)\n",
    "            del rotation_results\n",
    "            if GPU_AVAILABLE:\n",
    "                torch.cuda.empty_cache()\n",
    "               \n",
    "            final_images = torch.cat([final_images, rotation_images], dim=0)\n",
    "            final_labels = torch.cat([final_labels, labels], dim=0)\n",
    "            del rotation_images\n",
    "            if GPU_AVAILABLE:\n",
    "                torch.cuda.empty_cache()\n",
    "      \n",
    "        if augmentation_factor >= 3:\n",
    "            print(\"Applying flip augmentation...\")\n",
    "            flip_results = []\n",
    "            for i in range(0, n_original, batch_size):\n",
    "                if i % 500 == 0:\n",
    "                    print(f\" Processing {i}/{n_original}...\")\n",
    "                batch = images[i:i+batch_size]\n",
    "                batch_3d = batch.unsqueeze(1)\n",
    "                flipped = torch.flip(batch_3d, dims=[3]).squeeze(1)\n",
    "                flip_results.append(flipped)\n",
    "                if GPU_AVAILABLE:\n",
    "                    torch.cuda.empty_cache()\n",
    "           \n",
    "            flip_images = torch.cat(flip_results, dim=0)\n",
    "            del flip_results\n",
    "            if GPU_AVAILABLE:\n",
    "                torch.cuda.empty_cache()\n",
    "               \n",
    "            final_images = torch.cat([final_images, flip_images], dim=0)\n",
    "            final_labels = torch.cat([final_labels, labels], dim=0)\n",
    "            del flip_images\n",
    "            if GPU_AVAILABLE:\n",
    "                torch.cuda.empty_cache()\n",
    "      \n",
    "        if augmentation_factor >= 4:\n",
    "            print(\"Applying noise augmentation...\")\n",
    "            noise_results = []\n",
    "            for i in range(0, n_original, batch_size):\n",
    "                if i % 500 == 0:\n",
    "                    print(f\" Processing {i}/{n_original}...\")\n",
    "                batch = images[i:i+batch_size]\n",
    "                noisy = self.add_gaussian_noise_gpu(batch, sigma=5)\n",
    "                noise_results.append(noisy)\n",
    "                if GPU_AVAILABLE:\n",
    "                    torch.cuda.empty_cache()\n",
    "           \n",
    "            noise_images = torch.cat(noise_results, dim=0)\n",
    "            del noise_results\n",
    "            if GPU_AVAILABLE:\n",
    "                torch.cuda.empty_cache()\n",
    "               \n",
    "            final_images = torch.cat([final_images, noise_images], dim=0)\n",
    "            final_labels = torch.cat([final_labels, labels], dim=0)\n",
    "            del noise_images\n",
    "            if GPU_AVAILABLE:\n",
    "                torch.cuda.empty_cache()\n",
    "      \n",
    "        print(f\"\\nOriginal dataset size: {n_original}\")\n",
    "        print(f\"Augmented dataset size: {len(final_images)}\")\n",
    "        print(f\"Augmentation multiplier: {len(final_images) / n_original:.1f}x\")\n",
    "        print(f\"Data stored on: {final_images.device}\")\n",
    "      \n",
    "        return final_images, final_labels\n",
    "  \n",
    "    def remove_outliers_iqr(self, images, labels):\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"OUTLIER REMOVAL (IQR Method - GPU)\")\n",
    "        print(\"=\" * 70)\n",
    "      \n",
    "        batch_size = 100\n",
    "        mean_intensities_list = []\n",
    "       \n",
    "        for i in range(0, len(images), batch_size):\n",
    "            batch = images[i:i+batch_size]\n",
    "            batch_means = torch.mean(batch.view(len(batch), -1), dim=1)\n",
    "            mean_intensities_list.append(batch_means)\n",
    "            if GPU_AVAILABLE:\n",
    "                torch.cuda.empty_cache()\n",
    "       \n",
    "        mean_intensities = torch.cat(mean_intensities_list)\n",
    "        del mean_intensities_list\n",
    "        if GPU_AVAILABLE:\n",
    "            torch.cuda.empty_cache()\n",
    "      \n",
    "        Q1 = torch.quantile(mean_intensities, 0.25)\n",
    "        Q3 = torch.quantile(mean_intensities, 0.75)\n",
    "        IQR = Q3 - Q1\n",
    "      \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "      \n",
    "        mask = (mean_intensities >= lower_bound) & (mean_intensities <= upper_bound)\n",
    "       \n",
    "        indices = torch.where(mask)[0]\n",
    "       \n",
    "        print(f\"Original samples: {len(images)}\")\n",
    "        print(f\"Outliers removed: {(~mask).sum().item()}\")\n",
    "        print(f\"Remaining samples: {len(indices)}\")\n",
    "       \n",
    "        clean_images = torch.index_select(images, 0, indices)\n",
    "        clean_labels = torch.index_select(labels, 0, indices)\n",
    "       \n",
    "        del mask, indices, mean_intensities\n",
    "        if GPU_AVAILABLE:\n",
    "            torch.cuda.empty_cache()\n",
    "      \n",
    "        return clean_images, clean_labels\n",
    "  \n",
    "    def normalize_images(self, images):\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"IMAGE NORMALIZATION (Z-Score - GPU)\")\n",
    "        print(\"=\" * 70)\n",
    "      \n",
    "        self.mean = torch.mean(images)\n",
    "        self.std = torch.std(images)\n",
    "      \n",
    "        print(f\"Global Mean: {self.mean.item():.2f}\")\n",
    "        print(f\"Global Std: {self.std.item():.2f}\")\n",
    "      \n",
    "        normalized = (images - self.mean) / (self.std + 1e-8)\n",
    "      \n",
    "        return normalized\n",
    "\n",
    "# ============================================================================\n",
    "# 3. RADIOMIC FEATURE EXTRACTION (GPU-Optimized)\n",
    "# ============================================================================\n",
    "class RadiomicFeatureExtractor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "  \n",
    "    def extract_statistical_features_gpu(self, image):\n",
    "        features = []\n",
    "        features.append(torch.mean(image).item())\n",
    "        features.append(torch.var(image).item())\n",
    "        features.append(torch.std(image).item())\n",
    "        return torch.tensor(features, device=device)\n",
    "  \n",
    "    def compute_glcm_gpu(self, image, distance=1, angle=0):\n",
    "        levels = 16\n",
    "        image_quantized = (image / (256 / levels)).long()\n",
    "        image_quantized = torch.clamp(image_quantized, 0, levels - 1)\n",
    "        img_cpu = image_quantized.cpu().numpy()\n",
    "        glcm = np.zeros((levels, levels), dtype=np.float64)\n",
    "      \n",
    "        rows, cols = img_cpu.shape\n",
    "        if angle == 0:\n",
    "            dx, dy = 0, distance\n",
    "        elif angle == 45:\n",
    "            dx, dy = distance, distance\n",
    "        elif angle == 90:\n",
    "            dx, dy = distance, 0\n",
    "        else:\n",
    "            dx, dy = distance, -distance\n",
    "      \n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                ni, nj = i + dx, j + dy\n",
    "                if 0 <= ni < rows and 0 <= nj < cols:\n",
    "                    glcm[img_cpu[i, j], img_cpu[ni, nj]] += 1\n",
    "      \n",
    "        glcm = glcm / (np.sum(glcm) + 1e-10)\n",
    "        return torch.from_numpy(glcm).to(device)\n",
    "  \n",
    "    def extract_texture_features_gpu(self, image):\n",
    "        glcm = self.compute_glcm_gpu(image, distance=1, angle=0)\n",
    "        features = []\n",
    "        i_idx = torch.arange(glcm.shape[0], device=device).view(-1, 1).float()\n",
    "        j_idx = torch.arange(glcm.shape[1], device=device).view(1, -1).float()\n",
    "        contrast = torch.sum(glcm * (i_idx - j_idx) ** 2).item()\n",
    "        features.append(contrast)\n",
    "        homogeneity = torch.sum(glcm / (1 + (i_idx - j_idx) ** 2)).item()\n",
    "        features.append(homogeneity)\n",
    "        return torch.tensor(features, device=device)\n",
    "  \n",
    "    def gabor_kernel_gpu(self, ksize, sigma, theta, lambd, gamma, psi):\n",
    "        sigma_x = sigma\n",
    "        sigma_y = sigma / gamma\n",
    "        xmax = ksize // 2\n",
    "        ymax = ksize // 2\n",
    "        y = torch.arange(-ymax, ymax + 1, device=device).view(-1, 1).float()\n",
    "        x = torch.arange(-xmax, xmax + 1, device=device).view(1, -1).float()\n",
    "        x_theta = x * torch.cos(torch.tensor(theta, device=device)) + y * torch.sin(torch.tensor(theta, device=device))\n",
    "        y_theta = -x * torch.sin(torch.tensor(theta, device=device)) + y * torch.cos(torch.tensor(theta, device=device))\n",
    "        exp_part = torch.exp(-0.5 * (x_theta**2 / sigma_x**2 + y_theta**2 / sigma_y**2))\n",
    "        cos_part = torch.cos(2 * np.pi * x_theta / lambd + psi)\n",
    "        kernel = exp_part * cos_part\n",
    "        return kernel\n",
    "  \n",
    "    def extract_filter_features_gpu(self, image):\n",
    "        features = []\n",
    "        ksize = 21\n",
    "        sigma = 3\n",
    "        lambd = 10\n",
    "        gamma = 0.5\n",
    "        psi = 0\n",
    "        theta = 0\n",
    "        kernel = self.gabor_kernel_gpu(ksize, sigma, theta, lambd, gamma, psi)\n",
    "        img_4d = image.unsqueeze(0).unsqueeze(0)\n",
    "        kernel_4d = kernel.unsqueeze(0).unsqueeze(0)\n",
    "        filtered = torch.nn.functional.conv2d(img_4d, kernel_4d, padding=ksize//2)\n",
    "        filtered = filtered.squeeze()\n",
    "        mean_response = torch.mean(torch.abs(filtered)).item()\n",
    "        features.append(mean_response)\n",
    "        std_response = torch.std(filtered).item()\n",
    "        features.append(std_response)\n",
    "        return torch.tensor(features, device=device)\n",
    "  \n",
    "    def extract_all_features(self, images):\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"RADIOMIC FEATURE EXTRACTION (GPU-Accelerated)\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"Feature Categories:\")\n",
    "        print(\" 1. Statistical: Mean, Variance, Std\")\n",
    "        print(\" 2. Texture: GLCM Contrast, Homogeneity\")\n",
    "        print(\" 3. Filter-based: Gabor Mean Response, Gabor Std Response\")\n",
    "        print(\"=\" * 70)\n",
    "      \n",
    "        all_features = []\n",
    "        n_images = len(images)\n",
    "        batch_size = 50\n",
    "      \n",
    "        for start_idx in range(0, n_images, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, n_images)\n",
    "            if start_idx % 500 == 0:\n",
    "                print(f\"Extracting features from image {start_idx}/{n_images}...\")\n",
    "           \n",
    "            batch_features = []\n",
    "            for idx in range(start_idx, end_idx):\n",
    "                img = images[idx]\n",
    "                img_min = torch.min(img)\n",
    "                img_max = torch.max(img)\n",
    "                img_uint8 = ((img - img_min) / (img_max - img_min + 1e-8) * 255)\n",
    "              \n",
    "                stat_features = self.extract_statistical_features_gpu(img_uint8)\n",
    "                texture_features = self.extract_texture_features_gpu(img_uint8)\n",
    "                filter_features = self.extract_filter_features_gpu(img_uint8)\n",
    "              \n",
    "                combined = torch.cat([stat_features, texture_features, filter_features])\n",
    "                batch_features.append(combined)\n",
    "           \n",
    "            all_features.append(torch.stack(batch_features))\n",
    "            if GPU_AVAILABLE:\n",
    "                torch.cuda.empty_cache()\n",
    "      \n",
    "        all_features = torch.cat(all_features, dim=0)\n",
    "      \n",
    "        print(f\"\\nTotal features extracted per image: {all_features.shape[1]}\")\n",
    "        print(f\"All features stored on: {all_features.device}\")\n",
    "      \n",
    "        return all_features\n",
    "\n",
    "# ============================================================================\n",
    "# 4. FEATURE FUSION AND SCALING (GPU)\n",
    "# ============================================================================\n",
    "class FeatureFusion:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "  \n",
    "    def scale_features(self, features, fit=True):\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"FEATURE SCALING (GPU - Z-Score)\")\n",
    "        print(\"=\" * 70)\n",
    "      \n",
    "        if fit:\n",
    "            self.mean = torch.mean(features, dim=0)\n",
    "            self.std = torch.std(features, dim=0)\n",
    "            print(\"Fitted scaling parameters on GPU\")\n",
    "      \n",
    "        self.std[self.std == 0] = 1\n",
    "        scaled = (features - self.mean) / self.std\n",
    "      \n",
    "        print(f\"Scaled features shape: {scaled.shape}\")\n",
    "        print(f\"Mean: {torch.mean(scaled).item():.4f}\")\n",
    "        print(f\"Std: {torch.std(scaled).item():.4f}\")\n",
    "      \n",
    "        return scaled\n",
    "\n",
    "# ============================================================================\n",
    "# 5. DIMENSIONALITY REDUCTION (PCA on GPU)\n",
    "# ============================================================================\n",
    "class PCA:\n",
    "    def __init__(self, n_components=50):\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "        self.explained_variance = None\n",
    "  \n",
    "    def fit(self, X):\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"DIMENSIONALITY REDUCTION (PCA on GPU - {self.n_components} components)\")\n",
    "        print(\"=\" * 70)\n",
    "      \n",
    "        self.mean = torch.mean(X, dim=0)\n",
    "        X_centered = X - self.mean\n",
    "        cov_matrix = torch.mm(X_centered.T, X_centered) / (X.shape[0] - 1)\n",
    "        eigenvalues, eigenvectors = torch.linalg.eigh(cov_matrix)\n",
    "        idx = torch.argsort(eigenvalues, descending=True)\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        self.components = eigenvectors[:, :self.n_components]\n",
    "        self.explained_variance = eigenvalues[:self.n_components]\n",
    "        total_var = torch.sum(eigenvalues)\n",
    "        explained_var_ratio = self.explained_variance / total_var\n",
    "        cumulative_var = torch.cumsum(explained_var_ratio, dim=0)\n",
    "      \n",
    "        print(f\"Original dimension: {X.shape[1]}\")\n",
    "        print(f\"Reduced dimension: {self.n_components}\")\n",
    "        print(f\"Total variance explained: {cumulative_var[-1].item():.4f}\")\n",
    "        print(f\"Computation done on: GPU\")\n",
    "      \n",
    "        return self\n",
    "  \n",
    "    def transform(self, X):\n",
    "        X_centered = X - self.mean\n",
    "        return torch.mm(X_centered, self.components)\n",
    "  \n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "# ============================================================================\n",
    "# 6. DATA SPLITTING (GPU)\n",
    "# ============================================================================\n",
    "class DataSplitter:\n",
    "    @staticmethod\n",
    "    def shuffle_data(X, y, seed=42):\n",
    "        torch.manual_seed(seed)\n",
    "        indices = torch.randperm(len(X), device=device)\n",
    "        return X[indices], y[indices]\n",
    "  \n",
    "    @staticmethod\n",
    "    def train_test_split(X, y, train_ratio=0.6, seed=42):\n",
    "        X_shuffled, y_shuffled = DataSplitter.shuffle_data(X, y, seed)\n",
    "        n_samples = len(X)\n",
    "        n_train = int(n_samples * train_ratio)\n",
    "        return X_shuffled[:n_train], X_shuffled[n_train:], y_shuffled[:n_train], y_shuffled[n_train:]\n",
    "\n",
    "# ============================================================================\n",
    "# 7. LOGISTIC REGRESSION CLASSIFIER (Full GPU Implementation) - FIXED\n",
    "# ============================================================================\n",
    "class LogisticRegressionGPU:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=2000, regularization=0.01):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iterations\n",
    "        self.l2 = regularization\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.n_classes = None\n",
    "        self.training_history = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"TRAINING: Logistic Regression on GPU (Multiclass)\")\n",
    "        print(\"-\" * 70)\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "        self.n_classes = len(torch.unique(y))\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.weights = torch.randn(n_features, self.n_classes, device=device) * 0.01\n",
    "        self.bias = torch.zeros(self.n_classes, device=device)\n",
    "\n",
    "        # One-hot encode labels\n",
    "        y_onehot = torch.zeros(n_samples, self.n_classes, device=device)\n",
    "        y_onehot[torch.arange(n_samples), y] = 1\n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "            linear = torch.mm(X, self.weights) + self.bias\n",
    "            y_pred = torch.softmax(linear, dim=1)\n",
    "\n",
    "            # Cross-entropy loss + L2\n",
    "            loss = -torch.mean(torch.sum(y_onehot * torch.log(y_pred + 1e-8), dim=1))\n",
    "            loss += self.l2 * torch.sum(self.weights ** 2)\n",
    "\n",
    "            # Gradients\n",
    "            grad_w = (1/n_samples) * torch.mm(X.t(), (y_pred - y_onehot)) + 2 * self.l2 * self.weights\n",
    "            grad_b = (1/n_samples) * torch.sum(y_pred - y_onehot, dim=0)\n",
    "\n",
    "            # Update\n",
    "            self.weights -= self.lr * grad_w\n",
    "            self.bias -= self.lr * grad_b\n",
    "\n",
    "            if i % 500 == 0:\n",
    "                acc = (torch.argmax(y_pred, dim=1) == y).float().mean().item()\n",
    "                print(f\"  Iteration {i}: Loss = {loss.item():.4f}, Accuracy = {acc:.4f}\")\n",
    "\n",
    "        # Store class distribution\n",
    "        for c in range(self.n_classes):\n",
    "            count = (y == c).sum().item()\n",
    "            self.training_history.append({'class': int(c), 'n_samples': count, 'prior': count / n_samples})\n",
    "\n",
    "        print(\"Logistic Regression training completed on GPU!\")\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        linear = torch.mm(X, self.weights) + self.bias\n",
    "        return torch.softmax(linear, dim=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return torch.argmax(self.predict_proba(X), dim=1)\n",
    "\n",
    "# ============================================================================\n",
    "# 8. MODEL EVALUATION\n",
    "# ============================================================================\n",
    "class ModelEvaluator:\n",
    "    @staticmethod\n",
    "    def confusion_matrix(y_true, y_pred, n_classes=3):\n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.cpu().numpy()\n",
    "        if isinstance(y_pred, torch.Tensor):\n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "        cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "        for true, pred in zip(y_true, y_pred):\n",
    "            cm[int(true), int(pred)] += 1\n",
    "        return cm\n",
    "  \n",
    "    @staticmethod\n",
    "    def accuracy(y_true, y_pred):\n",
    "        if isinstance(y_true, torch.Tensor) and isinstance(y_pred, torch.Tensor):\n",
    "            return (y_true == y_pred).float().mean().item()\n",
    "        return float(np.mean(y_true == y_pred))\n",
    "  \n",
    "    @staticmethod\n",
    "    def precision_recall_f1(y_true, y_pred, n_classes=3):\n",
    "        cm = ModelEvaluator.confusion_matrix(y_true, y_pred, n_classes)\n",
    "        precision = np.zeros(n_classes)\n",
    "        recall = np.zeros(n_classes)\n",
    "        f1 = np.zeros(n_classes)\n",
    "        for i in range(n_classes):\n",
    "            tp = cm[i, i]\n",
    "            fp = np.sum(cm[:, i]) - tp\n",
    "            fn = np.sum(cm[i, :]) - tp\n",
    "            precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
    "        return precision, recall, f1\n",
    "  \n",
    "    @staticmethod\n",
    "    def plot_confusion_matrix(cm, class_names, filename):\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                   xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "  \n",
    "    @staticmethod\n",
    "    def plot_roc_curve(y_true, y_proba, n_classes, class_names, filename):\n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.cpu().numpy()\n",
    "        if isinstance(y_proba, torch.Tensor):\n",
    "            y_proba = y_proba.cpu().numpy()\n",
    "      \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        for i in range(n_classes):\n",
    "            y_true_binary = (y_true == i).astype(int)\n",
    "            y_scores = y_proba[:, i]\n",
    "            thresholds = np.linspace(0, 1, 100)\n",
    "            tpr_list = []\n",
    "            fpr_list = []\n",
    "            for thresh in thresholds:\n",
    "                y_pred_binary = (y_scores >= thresh).astype(int)\n",
    "                tp = np.sum((y_true_binary == 1) & (y_pred_binary == 1))\n",
    "                fp = np.sum((y_true_binary == 0) & (y_pred_binary == 1))\n",
    "                tn = np.sum((y_true_binary == 0) & (y_pred_binary == 0))\n",
    "                fn = np.sum((y_true_binary == 1) & (y_pred_binary == 0))\n",
    "                tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "                tpr_list.append(tpr)\n",
    "                fpr_list.append(fpr)\n",
    "           \n",
    "            fpr_array = np.array(fpr_list)\n",
    "            tpr_array = np.array(tpr_list)\n",
    "            sorted_idx = np.argsort(fpr_array)\n",
    "            fpr_sorted = fpr_array[sorted_idx]\n",
    "            tpr_sorted = tpr_array[sorted_idx]\n",
    "            auc = np.trapz(tpr_sorted, fpr_sorted)\n",
    "            plt.plot(fpr_sorted, tpr_sorted, label=f'{class_names[i]} (AUC = {auc:.3f})', linewidth=2)\n",
    "      \n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves - Multiclass Classification')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "  \n",
    "    @staticmethod\n",
    "    def plot_class_distribution(training_history, filename):\n",
    "        classes = [h['class'] for h in training_history]\n",
    "        n_samples = [h['n_samples'] for h in training_history]\n",
    "        priors = [h['prior'] for h in training_history]\n",
    "      \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        ax1.bar(classes, n_samples, color=['blue', 'orange', 'green'])\n",
    "        ax1.set_xlabel('Class')\n",
    "        ax1.set_ylabel('Number of Samples')\n",
    "        ax1.set_title('Training Samples per Class')\n",
    "        ax1.set_xticks(classes)\n",
    "        ax1.grid(alpha=0.3)\n",
    "      \n",
    "        ax2.bar(classes, priors, color=['blue', 'orange', 'green'])\n",
    "        ax2.set_xlabel('Class')\n",
    "        ax2.set_ylabel('Prior Probability')\n",
    "        ax2.set_title('Class Prior Probabilities')\n",
    "        ax2.set_xticks(classes)\n",
    "        ax2.grid(alpha=0.3)\n",
    "      \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# 9. MAIN PIPELINE (Full CUDA with PyTorch)\n",
    "# ============================================================================\n",
    "def main():\n",
    "    output_dir = \"output_lr_cuda\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "  \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CUDA-ACCELERATED LUNG DISEASE CLASSIFICATION\")\n",
    "    print(\"PyTorch CUDA - All Processing on GPU - LOGISTIC REGRESSION\")\n",
    "    print(\"=\" * 70)\n",
    "  \n",
    "    if GPU_AVAILABLE:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\nInitial GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "        print(f\"Initial GPU Memory: {torch.cuda.memory_reserved() / 1e9:.2f} GB reserved\")\n",
    "  \n",
    "    dataset_path = r'C:\\Users\\Wolf\\PAGANI\\chest_xray'\n",
    "    loader = DatasetLoader(dataset_path)\n",
    "    images, labels = loader.load_dataset(target_size=(256, 256), max_samples_per_class=None)\n",
    "  \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory after loading: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "  \n",
    "    preprocessor = DataPreprocessor()\n",
    "\n",
    "    # CHANGED: augmentation_factor=2\n",
    "    images_aug, labels_aug = preprocessor.augment_data(images, labels, augmentation_factor=2)\n",
    "  \n",
    "    del images, labels\n",
    "    if GPU_AVAILABLE:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"GPU Memory after augmentation: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "  \n",
    "    images_clean, labels_clean = preprocessor.remove_outliers_iqr(images_aug, labels_aug)\n",
    "    del images_aug, labels_aug\n",
    "    if GPU_AVAILABLE:\n",
    "        torch.cuda.empty_cache()\n",
    "   \n",
    "    images_norm = preprocessor.normalize_images(images_clean)\n",
    "    del images_clean\n",
    "    if GPU_AVAILABLE:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"GPU Memory after preprocessing: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "  \n",
    "    feature_extractor = RadiomicFeatureExtractor()\n",
    "    features = feature_extractor.extract_all_features(images_norm)\n",
    "    del images_norm\n",
    "    if GPU_AVAILABLE:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"GPU Memory after feature extraction: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "  \n",
    "    fusion = FeatureFusion()\n",
    "    features_scaled = fusion.scale_features(features, fit=True)\n",
    "    del features\n",
    "    if GPU_AVAILABLE:\n",
    "        torch.cuda.empty_cache()\n",
    "  \n",
    "    pca = PCA(n_components=min(7, features_scaled.shape[1]))\n",
    "    features_pca = pca.fit_transform(features_scaled)\n",
    "    del features_scaled\n",
    "    if GPU_AVAILABLE:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"GPU Memory after PCA: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "  \n",
    "    class_names = ['Normal', 'Bacterial Pneumonia', 'Viral Pneumonia']\n",
    "    train_ratio = 0.6\n",
    "  \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"TRAINING WITH {int(train_ratio*100)}% TRAIN / {int((1-train_ratio)*100)}% TEST SPLIT\")\n",
    "    print(\"=\" * 70)\n",
    "  \n",
    "    X_train, X_test, y_train, y_test = DataSplitter.train_test_split(\n",
    "        features_pca, labels_clean, train_ratio=train_ratio\n",
    "    )\n",
    "  \n",
    "    print(f\"\\nTrain set: {len(X_train)} samples (GPU)\")\n",
    "    print(f\"Test set: {len(X_test)} samples (GPU)\")\n",
    "  \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory before training: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "  \n",
    "    start_time = time.time()\n",
    "  \n",
    "    # Now using proper Logistic Regression\n",
    "    lr_model = LogisticRegressionGPU(learning_rate=0.01, n_iterations=2000, regularization=0.01)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "  \n",
    "    train_time = time.time() - start_time\n",
    "  \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"\\nGPU Memory after training: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "  \n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    y_proba = lr_model.predict_proba(X_test)\n",
    "  \n",
    "    cm = ModelEvaluator.confusion_matrix(y_test, y_pred)\n",
    "    accuracy = ModelEvaluator.accuracy(y_test, y_pred)\n",
    "    precision, recall, f1 = ModelEvaluator.precision_recall_f1(y_test, y_pred)\n",
    "  \n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(\"RESULTS (CUDA-Accelerated with PyTorch)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Training Time: {train_time:.2f}s\")\n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"Processing: 100% on {torch.cuda.get_device_name(0)}\")\n",
    "  \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"\\n{class_name}:\")\n",
    "        print(f\"  Precision: {precision[i]:.4f}\")\n",
    "        print(f\"  Recall: {recall[i]:.4f}\")\n",
    "        print(f\"  F1-Score: {f1[i]:.4f}\")\n",
    "  \n",
    "    cm_filename = os.path.join(output_dir, f'confusion_matrix_LR_CUDA_{int(train_ratio*100)}.png')\n",
    "    ModelEvaluator.plot_confusion_matrix(cm, class_names, cm_filename)\n",
    "  \n",
    "    roc_filename = os.path.join(output_dir, f'roc_curve_LR_CUDA_{int(train_ratio*100)}.png')\n",
    "    ModelEvaluator.plot_roc_curve(y_test, y_proba, 3, class_names, roc_filename)\n",
    "  \n",
    "    class_dist_filename = os.path.join(output_dir, f'class_distribution_LR_CUDA_{int(train_ratio*100)}.png')\n",
    "    ModelEvaluator.plot_class_distribution(lr_model.training_history, class_dist_filename)\n",
    "  \n",
    "    results = {\n",
    "        'model': 'Logistic Regression (PyTorch CUDA-Accelerated)',\n",
    "        'gpu': torch.cuda.get_device_name(0) if GPU_AVAILABLE else 'CPU',\n",
    "        'train_ratio': train_ratio,\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision': precision.tolist(),\n",
    "        'recall': recall.tolist(),\n",
    "        'f1_score': f1.tolist(),\n",
    "        'training_time': float(train_time),\n",
    "        'confusion_matrix': cm.tolist()\n",
    "    }\n",
    "  \n",
    "    results_file = os.path.join(output_dir, 'results_summary_lr_cuda.json')\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "  \n",
    "    print(f\"\\nResults saved to: {results_file}\")\n",
    "    print(f\"Visualizations saved to: {output_dir}/\")\n",
    "  \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"\\nFinal GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "        print(f\"Peak GPU Memory: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "  \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CUDA-ACCELERATED PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21795f-a4cb-43e9-ba91-71718ae24896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
