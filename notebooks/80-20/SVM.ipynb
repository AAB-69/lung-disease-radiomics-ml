{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4c51b4-84ed-4c5f-ad42-3133b2136784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GPU INITIALIZATION\n",
      "======================================================================\n",
      "GPU Device: NVIDIA GeForce RTX 3060\n",
      "GPU Memory: 12.88 GB\n",
      "CUDA Version: 12.1\n",
      "CUDA enabled - All processing will run on GPU!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "CUDA-ACCELERATED LUNG DISEASE CLASSIFICATION\n",
      "PyTorch CUDA - All Processing on GPU\n",
      "======================================================================\n",
      "\n",
      "Initial GPU Memory: 0.00 GB allocated\n",
      "Initial GPU Memory: 0.00 GB reserved\n",
      "======================================================================\n",
      "DATASET LOADING AND QUALITY CHECK\n",
      "======================================================================\n",
      "\n",
      "Processing Normal...\n",
      "\n",
      "Processing Pneumonia_bacterial...\n",
      "\n",
      "Processing Pneumonia_viral...\n",
      "\n",
      "======================================================================\n",
      "DATASET STATISTICS\n",
      "======================================================================\n",
      "Normal:\n",
      "  Total: 1583\n",
      "  Loaded: 1583\n",
      "  Rejected: 0\n",
      "Pneumonia_bacterial:\n",
      "  Total: 2780\n",
      "  Loaded: 2780\n",
      "  Rejected: 0\n",
      "Pneumonia_viral:\n",
      "  Total: 1493\n",
      "  Loaded: 1493\n",
      "  Rejected: 0\n",
      "\n",
      "Transferring data to GPU...\n",
      "Final Dataset Shape: torch.Size([5856, 256, 256])\n",
      "Labels Shape: torch.Size([5856])\n",
      "Data location: cuda:0\n",
      "GPU Memory after loading: 1.54 GB allocated\n",
      "\n",
      "======================================================================\n",
      "DATA AUGMENTATION (GPU-Accelerated)\n",
      "======================================================================\n",
      "Applying CLAHE enhancement...\n",
      "  Processing 0/5856...\n",
      "  Processing 500/5856...\n",
      "  Processing 1000/5856...\n",
      "  Processing 1500/5856...\n",
      "  Processing 2000/5856...\n",
      "  Processing 2500/5856...\n",
      "  Processing 3000/5856...\n",
      "  Processing 3500/5856...\n",
      "  Processing 4000/5856...\n",
      "  Processing 4500/5856...\n",
      "  Processing 5000/5856...\n",
      "  Processing 5500/5856...\n",
      "Applying rotation augmentation...\n",
      "  Processing 0/5856...\n",
      "  Processing 500/5856...\n",
      "  Processing 1000/5856...\n",
      "  Processing 1500/5856...\n",
      "  Processing 2000/5856...\n",
      "  Processing 2500/5856...\n",
      "  Processing 3000/5856...\n",
      "  Processing 3500/5856...\n",
      "  Processing 4000/5856...\n",
      "  Processing 4500/5856...\n",
      "  Processing 5000/5856...\n",
      "  Processing 5500/5856...\n",
      "\n",
      "Original dataset size: 5856\n",
      "Augmented dataset size: 17568\n",
      "Data stored on: cuda:0\n",
      "GPU Memory after augmentation: 6.14 GB allocated\n",
      "\n",
      "======================================================================\n",
      "OUTLIER REMOVAL (IQR Method - GPU)\n",
      "======================================================================\n",
      "Original samples: 17568\n",
      "Outliers removed: 317\n",
      "Remaining samples: 17251\n",
      "\n",
      "======================================================================\n",
      "IMAGE NORMALIZATION (Z-Score - GPU)\n",
      "======================================================================\n",
      "Global Mean: 123.19\n",
      "Global Std: 63.41\n",
      "GPU Memory after preprocessing: 15.19 GB allocated\n",
      "\n",
      "======================================================================\n",
      "RADIOMIC FEATURE EXTRACTION (GPU-Accelerated)\n",
      "======================================================================\n",
      "Feature Categories:\n",
      "  1. Statistical: Mean, Variance, Std\n",
      "  2. Texture: GLCM Contrast, Homogeneity\n",
      "  3. Filter-based: Gabor Mean Response, Gabor Std Response\n",
      "======================================================================\n",
      "Extracting features from image 0/17251...\n",
      "Extracting features from image 100/17251...\n",
      "Extracting features from image 200/17251...\n",
      "Extracting features from image 300/17251...\n",
      "Extracting features from image 400/17251...\n",
      "Extracting features from image 500/17251...\n",
      "Extracting features from image 600/17251...\n",
      "Extracting features from image 700/17251...\n",
      "Extracting features from image 800/17251...\n",
      "Extracting features from image 900/17251...\n",
      "Extracting features from image 1000/17251...\n",
      "Extracting features from image 1100/17251...\n",
      "Extracting features from image 1200/17251...\n",
      "Extracting features from image 1300/17251...\n",
      "Extracting features from image 1400/17251...\n",
      "Extracting features from image 1500/17251...\n",
      "Extracting features from image 1600/17251...\n",
      "Extracting features from image 1700/17251...\n",
      "Extracting features from image 1800/17251...\n",
      "Extracting features from image 1900/17251...\n",
      "Extracting features from image 2000/17251...\n",
      "Extracting features from image 2100/17251...\n",
      "Extracting features from image 2200/17251...\n",
      "Extracting features from image 2300/17251...\n",
      "Extracting features from image 2400/17251...\n",
      "Extracting features from image 2500/17251...\n",
      "Extracting features from image 2600/17251...\n",
      "Extracting features from image 2700/17251...\n",
      "Extracting features from image 2800/17251...\n",
      "Extracting features from image 2900/17251...\n",
      "Extracting features from image 3000/17251...\n",
      "Extracting features from image 3100/17251...\n",
      "Extracting features from image 3200/17251...\n",
      "Extracting features from image 3300/17251...\n",
      "Extracting features from image 3400/17251...\n",
      "Extracting features from image 3500/17251...\n",
      "Extracting features from image 3600/17251...\n",
      "Extracting features from image 3700/17251...\n",
      "Extracting features from image 3800/17251...\n",
      "Extracting features from image 3900/17251...\n",
      "Extracting features from image 4000/17251...\n",
      "Extracting features from image 4100/17251...\n",
      "Extracting features from image 4200/17251...\n",
      "Extracting features from image 4300/17251...\n",
      "Extracting features from image 4400/17251...\n",
      "Extracting features from image 4500/17251...\n",
      "Extracting features from image 4600/17251...\n",
      "Extracting features from image 4700/17251...\n",
      "Extracting features from image 4800/17251...\n",
      "Extracting features from image 4900/17251...\n",
      "Extracting features from image 5000/17251...\n",
      "Extracting features from image 5100/17251...\n",
      "Extracting features from image 5200/17251...\n",
      "Extracting features from image 5300/17251...\n",
      "Extracting features from image 5400/17251...\n",
      "Extracting features from image 5500/17251...\n",
      "Extracting features from image 5600/17251...\n",
      "Extracting features from image 5700/17251...\n",
      "Extracting features from image 5800/17251...\n",
      "Extracting features from image 5900/17251...\n",
      "Extracting features from image 6000/17251...\n",
      "Extracting features from image 6100/17251...\n",
      "Extracting features from image 6200/17251...\n",
      "Extracting features from image 6300/17251...\n",
      "Extracting features from image 6400/17251...\n",
      "Extracting features from image 6500/17251...\n",
      "Extracting features from image 6600/17251...\n",
      "Extracting features from image 6700/17251...\n",
      "Extracting features from image 6800/17251...\n",
      "Extracting features from image 6900/17251...\n",
      "Extracting features from image 7000/17251...\n",
      "Extracting features from image 7100/17251...\n",
      "Extracting features from image 7200/17251...\n",
      "Extracting features from image 7300/17251...\n",
      "Extracting features from image 7400/17251...\n",
      "Extracting features from image 7500/17251...\n",
      "Extracting features from image 7600/17251...\n",
      "Extracting features from image 7700/17251...\n",
      "Extracting features from image 7800/17251...\n",
      "Extracting features from image 7900/17251...\n",
      "Extracting features from image 8000/17251...\n",
      "Extracting features from image 8100/17251...\n",
      "Extracting features from image 8200/17251...\n",
      "Extracting features from image 8300/17251...\n",
      "Extracting features from image 8400/17251...\n",
      "Extracting features from image 8500/17251...\n",
      "Extracting features from image 8600/17251...\n",
      "Extracting features from image 8700/17251...\n",
      "Extracting features from image 8800/17251...\n",
      "Extracting features from image 8900/17251...\n",
      "Extracting features from image 9000/17251...\n",
      "Extracting features from image 9100/17251...\n",
      "Extracting features from image 9200/17251...\n",
      "Extracting features from image 9300/17251...\n",
      "Extracting features from image 9400/17251...\n",
      "Extracting features from image 9500/17251...\n",
      "Extracting features from image 9600/17251...\n",
      "Extracting features from image 9700/17251...\n",
      "Extracting features from image 9800/17251...\n",
      "Extracting features from image 9900/17251...\n",
      "Extracting features from image 10000/17251...\n",
      "Extracting features from image 10100/17251...\n",
      "Extracting features from image 10200/17251...\n",
      "Extracting features from image 10300/17251...\n",
      "Extracting features from image 10400/17251...\n",
      "Extracting features from image 10500/17251...\n",
      "Extracting features from image 10600/17251...\n",
      "Extracting features from image 10700/17251...\n",
      "Extracting features from image 10800/17251...\n",
      "Extracting features from image 10900/17251...\n",
      "Extracting features from image 11000/17251...\n",
      "Extracting features from image 11100/17251...\n",
      "Extracting features from image 11200/17251...\n",
      "Extracting features from image 11300/17251...\n",
      "Extracting features from image 11400/17251...\n",
      "Extracting features from image 11500/17251...\n",
      "Extracting features from image 11600/17251...\n",
      "Extracting features from image 11700/17251...\n",
      "Extracting features from image 11800/17251...\n",
      "Extracting features from image 11900/17251...\n",
      "Extracting features from image 12000/17251...\n",
      "Extracting features from image 12100/17251...\n",
      "Extracting features from image 12200/17251...\n",
      "Extracting features from image 12300/17251...\n",
      "Extracting features from image 12400/17251...\n",
      "Extracting features from image 12500/17251...\n",
      "Extracting features from image 12600/17251...\n",
      "Extracting features from image 12700/17251...\n",
      "Extracting features from image 12800/17251...\n",
      "Extracting features from image 12900/17251...\n",
      "Extracting features from image 13000/17251...\n",
      "Extracting features from image 13100/17251...\n",
      "Extracting features from image 13200/17251...\n",
      "Extracting features from image 13300/17251...\n",
      "Extracting features from image 13400/17251...\n",
      "Extracting features from image 13500/17251...\n",
      "Extracting features from image 13600/17251...\n",
      "Extracting features from image 13700/17251...\n",
      "Extracting features from image 13800/17251...\n",
      "Extracting features from image 13900/17251...\n",
      "Extracting features from image 14000/17251...\n",
      "Extracting features from image 14100/17251...\n",
      "Extracting features from image 14200/17251...\n",
      "Extracting features from image 14300/17251...\n",
      "Extracting features from image 14400/17251...\n",
      "Extracting features from image 14500/17251...\n",
      "Extracting features from image 14600/17251...\n",
      "Extracting features from image 14700/17251...\n",
      "Extracting features from image 14800/17251...\n",
      "Extracting features from image 14900/17251...\n",
      "Extracting features from image 15000/17251...\n",
      "Extracting features from image 15100/17251...\n",
      "Extracting features from image 15200/17251...\n",
      "Extracting features from image 15300/17251...\n",
      "Extracting features from image 15400/17251...\n",
      "Extracting features from image 15500/17251...\n",
      "Extracting features from image 15600/17251...\n",
      "Extracting features from image 15700/17251...\n",
      "Extracting features from image 15800/17251...\n",
      "Extracting features from image 15900/17251...\n",
      "Extracting features from image 16000/17251...\n",
      "Extracting features from image 16100/17251...\n",
      "Extracting features from image 16200/17251...\n",
      "Extracting features from image 16300/17251...\n",
      "Extracting features from image 16400/17251...\n",
      "Extracting features from image 16500/17251...\n",
      "Extracting features from image 16600/17251...\n",
      "Extracting features from image 16700/17251...\n",
      "Extracting features from image 16800/17251...\n",
      "Extracting features from image 16900/17251...\n",
      "Extracting features from image 17000/17251...\n",
      "Extracting features from image 17100/17251...\n",
      "Extracting features from image 17200/17251...\n",
      "\n",
      "Total features extracted per image: 7\n",
      "All features stored on: cuda:0\n",
      "GPU Memory after feature extraction: 15.19 GB allocated\n",
      "\n",
      "======================================================================\n",
      "FEATURE SCALING (GPU - Z-Score)\n",
      "======================================================================\n",
      "Fitted scaling parameters on GPU\n",
      "Scaled features shape: torch.Size([17251, 7])\n",
      "Mean: 0.0000\n",
      "Std: 1.0000\n",
      "\n",
      "======================================================================\n",
      "DIMENSIONALITY REDUCTION (PCA on GPU - 7 components)\n",
      "======================================================================\n",
      "Original dimension: 7\n",
      "Reduced dimension: 7\n",
      "Total variance explained: 1.0000\n",
      "Computation done on: GPU\n",
      "GPU Memory after PCA: 15.20 GB allocated\n",
      "\n",
      "======================================================================\n",
      "TRAINING WITH 80% TRAIN / 19% TEST SPLIT\n",
      "======================================================================\n",
      "\n",
      "Train set: 13800 samples (GPU)\n",
      "Test set: 3451 samples (GPU)\n",
      "GPU Memory before training: 15.20 GB allocated\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TRAINING: SVM on GPU (One-vs-Rest)\n",
      "----------------------------------------------------------------------\n",
      "Training 3 binary classifiers on GPU...\n",
      "\n",
      "Training classifier for class 0...\n",
      "  Iteration 0, Loss: 0.9954, Accuracy: 0.6072\n",
      "  Iteration 100, Loss: 0.9659, Accuracy: 0.6988\n",
      "  Iteration 200, Loss: 0.9393, Accuracy: 0.7143\n",
      "  Iteration 300, Loss: 0.9148, Accuracy: 0.7207\n",
      "  Iteration 400, Loss: 0.8916, Accuracy: 0.7236\n",
      "\n",
      "Training classifier for class 1...\n",
      "  Iteration 0, Loss: 1.0044, Accuracy: 0.4075\n",
      "  Iteration 100, Loss: 0.9870, Accuracy: 0.6336\n",
      "  Iteration 200, Loss: 0.9753, Accuracy: 0.6298\n",
      "  Iteration 300, Loss: 0.9673, Accuracy: 0.6288\n",
      "  Iteration 400, Loss: 0.9618, Accuracy: 0.6295\n",
      "\n",
      "Training classifier for class 2...\n",
      "  Iteration 0, Loss: 1.0001, Accuracy: 0.4967\n",
      "  Iteration 100, Loss: 0.9683, Accuracy: 0.7195\n",
      "  Iteration 200, Loss: 0.9390, Accuracy: 0.7223\n",
      "  Iteration 300, Loss: 0.9114, Accuracy: 0.7235\n",
      "  Iteration 400, Loss: 0.8850, Accuracy: 0.7273\n",
      "\n",
      "GPU Memory after training: 15.20 GB allocated\n",
      "\n",
      "======================================================================\n",
      "RESULTS (CUDA-Accelerated with PyTorch)\n",
      "======================================================================\n",
      "Accuracy: 0.5109\n",
      "Training Time: 1.52s\n",
      "Processing: 100% on NVIDIA GeForce RTX 3060\n",
      "\n",
      "Normal:\n",
      "  Precision: 0.5072\n",
      "  Recall: 0.3640\n",
      "  F1-Score: 0.4238\n",
      "\n",
      "Bacterial Pneumonia:\n",
      "  Precision: 0.5345\n",
      "  Recall: 0.7064\n",
      "  F1-Score: 0.6086\n",
      "\n",
      "Viral Pneumonia:\n",
      "  Precision: 0.4368\n",
      "  Recall: 0.3171\n",
      "  F1-Score: 0.3675\n",
      "\n",
      "Results saved to: output_svm_cuda\\results_summary_cuda.json\n",
      "Visualizations saved to: output_svm_cuda/\n",
      "\n",
      "Final GPU Memory: 15.20 GB allocated\n",
      "Peak GPU Memory: 19.71 GB\n",
      "\n",
      "======================================================================\n",
      "CUDA-ACCELERATED PIPELINE COMPLETED SUCCESSFULLY!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch CUDA support\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        GPU_AVAILABLE = True\n",
    "        device = torch.device('cuda:0')\n",
    "        print(\"=\" * 70)\n",
    "        print(\"GPU INITIALIZATION\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "        print(\"CUDA enabled - All processing will run on GPU!\")\n",
    "        print(\"=\" * 70)\n",
    "    else:\n",
    "        GPU_AVAILABLE = False\n",
    "        device = torch.device('cpu')\n",
    "        print(\"WARNING: CUDA not available. Using CPU.\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    device = torch.device('cpu')\n",
    "    print(\"ERROR: PyTorch not available. Please install with: pip install torch torchvision\")\n",
    "    exit(1)\n",
    "\n",
    "# ============================================================================\n",
    "# 1. DATASET PREPARATION AND LOADING\n",
    "# ============================================================================\n",
    "\n",
    "class DatasetLoader:\n",
    "    \"\"\"Handles dataset loading with GPU transfer\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.categories = ['Normal', 'Pneumonia_bacterial', 'Pneumonia_viral']\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.label_map = {'Normal': 0, 'Pneumonia_bacterial': 1, 'Pneumonia_viral': 2}\n",
    "        \n",
    "    def check_image_quality(self, img_path):\n",
    "        \"\"\"Check if image is corrupted or low quality\"\"\"\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                return False, \"Corrupted\"\n",
    "            \n",
    "            if img.shape[0] < 64 or img.shape[1] < 64:\n",
    "                return False, \"Low resolution\"\n",
    "            \n",
    "            mean_intensity = np.mean(img)\n",
    "            if mean_intensity < 10 or mean_intensity > 245:\n",
    "                return False, \"Poor contrast\"\n",
    "            \n",
    "            return True, \"OK\"\n",
    "        except Exception as e:\n",
    "            return False, str(e)\n",
    "    \n",
    "    def load_dataset(self, target_size=(256, 256)):\n",
    "        \"\"\"Load and preprocess dataset, then transfer to GPU\"\"\"\n",
    "        print(\"=\" * 70)\n",
    "        print(\"DATASET LOADING AND QUALITY CHECK\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        stats = {cat: {'total': 0, 'loaded': 0, 'rejected': 0} for cat in self.categories}\n",
    "        \n",
    "        for category in self.categories:\n",
    "            cat_path = os.path.join(self.dataset_path, category)\n",
    "            if not os.path.exists(cat_path):\n",
    "                print(f\"Warning: {category} folder not found!\")\n",
    "                continue\n",
    "            \n",
    "            files = [f for f in os.listdir(cat_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            stats[category]['total'] = len(files)\n",
    "            \n",
    "            print(f\"\\nProcessing {category}...\")\n",
    "            for filename in files:\n",
    "                img_path = os.path.join(cat_path, filename)\n",
    "                is_valid, reason = self.check_image_quality(img_path)\n",
    "                \n",
    "                if is_valid:\n",
    "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    img_resized = cv2.resize(img, target_size)\n",
    "                    self.images.append(img_resized)\n",
    "                    self.labels.append(self.label_map[category])\n",
    "                    stats[category]['loaded'] += 1\n",
    "                else:\n",
    "                    stats[category]['rejected'] += 1\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"DATASET STATISTICS\")\n",
    "        print(\"=\" * 70)\n",
    "        for cat in self.categories:\n",
    "            print(f\"{cat}:\")\n",
    "            print(f\"  Total: {stats[cat]['total']}\")\n",
    "            print(f\"  Loaded: {stats[cat]['loaded']}\")\n",
    "            print(f\"  Rejected: {stats[cat]['rejected']}\")\n",
    "        \n",
    "        # Convert to numpy first, then transfer to GPU\n",
    "        images_np = np.array(self.images, dtype=np.float32)\n",
    "        labels_np = np.array(self.labels, dtype=np.int64)\n",
    "        \n",
    "        print(f\"\\nTransferring data to GPU...\")\n",
    "        self.images = torch.from_numpy(images_np).to(device)\n",
    "        self.labels = torch.from_numpy(labels_np).to(device)\n",
    "        \n",
    "        print(f\"Final Dataset Shape: {self.images.shape}\")\n",
    "        print(f\"Labels Shape: {self.labels.shape}\")\n",
    "        print(f\"Data location: {self.images.device}\")\n",
    "        \n",
    "        return self.images, self.labels\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DATA PREPROCESSING (GPU-Optimized)\n",
    "# ============================================================================\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def apply_clahe_batch(self, images):\n",
    "        \"\"\"Apply CLAHE to batch of images\"\"\"\n",
    "        results = []\n",
    "        for i in range(len(images)):\n",
    "            img_cpu = images[i].cpu().numpy().astype(np.uint8)\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            result = clahe.apply(img_cpu)\n",
    "            results.append(result)\n",
    "        return torch.from_numpy(np.stack(results)).to(device)\n",
    "    \n",
    "    def add_gaussian_noise_gpu(self, images, mean=0, sigma=10):\n",
    "        \"\"\"Add Gaussian noise using GPU\"\"\"\n",
    "        noise = torch.randn_like(images) * sigma + mean\n",
    "        noisy_img = images + noise\n",
    "        return torch.clamp(noisy_img, 0, 255)\n",
    "    \n",
    "    def rotate_image_batch(self, images, angle):\n",
    "        \"\"\"Rotate batch of images\"\"\"\n",
    "        results = []\n",
    "        for i in range(len(images)):\n",
    "            img_cpu = images[i].cpu().numpy().astype(np.uint8)\n",
    "            h, w = img_cpu.shape\n",
    "            center = (w // 2, h // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            rotated = cv2.warpAffine(img_cpu, M, (w, h))\n",
    "            results.append(rotated)\n",
    "        return torch.from_numpy(np.stack(results)).to(device)\n",
    "    \n",
    "    def flip_image_gpu(self, images, direction='horizontal'):\n",
    "        \"\"\"Flip images on GPU\"\"\"\n",
    "        if direction == 'horizontal':\n",
    "            return torch.flip(images, dims=[2])\n",
    "        else:\n",
    "            return torch.flip(images, dims=[1])\n",
    "    \n",
    "    def augment_data(self, images, labels, augmentation_factor=2):\n",
    "        \"\"\"Apply data augmentation on GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"DATA AUGMENTATION (GPU-Accelerated)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        augmented_images = [images]\n",
    "        augmented_labels = [labels]\n",
    "        \n",
    "        n_original = len(images)\n",
    "        \n",
    "        # CLAHE enhancement\n",
    "        print(\"Applying CLAHE enhancement...\")\n",
    "        batch_size = 100\n",
    "        clahe_results = []\n",
    "        for i in range(0, n_original, batch_size):\n",
    "            if i % 500 == 0:\n",
    "                print(f\"  Processing {i}/{n_original}...\")\n",
    "            batch = images[i:i+batch_size]\n",
    "            clahe_batch = self.apply_clahe_batch(batch)\n",
    "            clahe_results.append(clahe_batch)\n",
    "        augmented_images.append(torch.cat(clahe_results, dim=0))\n",
    "        augmented_labels.append(labels)\n",
    "        \n",
    "        if augmentation_factor >= 2:\n",
    "            print(\"Applying rotation augmentation...\")\n",
    "            rotation_results = []\n",
    "            for i in range(0, n_original, batch_size):\n",
    "                if i % 500 == 0:\n",
    "                    print(f\"  Processing {i}/{n_original}...\")\n",
    "                batch = images[i:i+batch_size]\n",
    "                rot_batch = self.rotate_image_batch(batch, 15)\n",
    "                rotation_results.append(rot_batch)\n",
    "            augmented_images.append(torch.cat(rotation_results, dim=0))\n",
    "            augmented_labels.append(labels)\n",
    "        \n",
    "        if augmentation_factor >= 3:\n",
    "            print(\"Applying flip augmentation...\")\n",
    "            # Reshape for flip operation\n",
    "            images_3d = images.unsqueeze(1)  # Add channel dimension\n",
    "            flipped = torch.flip(images_3d, dims=[3]).squeeze(1)\n",
    "            augmented_images.append(flipped)\n",
    "            augmented_labels.append(labels)\n",
    "        \n",
    "        if augmentation_factor >= 4:\n",
    "            print(\"Applying noise augmentation...\")\n",
    "            noisy = self.add_gaussian_noise_gpu(images, sigma=5)\n",
    "            augmented_images.append(noisy)\n",
    "            augmented_labels.append(labels)\n",
    "        \n",
    "        # Concatenate all augmented data on GPU\n",
    "        final_images = torch.cat(augmented_images, dim=0)\n",
    "        final_labels = torch.cat(augmented_labels, dim=0)\n",
    "        \n",
    "        print(f\"\\nOriginal dataset size: {n_original}\")\n",
    "        print(f\"Augmented dataset size: {len(final_images)}\")\n",
    "        print(f\"Data stored on: {final_images.device}\")\n",
    "        \n",
    "        return final_images, final_labels\n",
    "    \n",
    "    def remove_outliers_iqr(self, images, labels):\n",
    "        \"\"\"Remove outliers using IQR method on GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"OUTLIER REMOVAL (IQR Method - GPU)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Calculate mean intensity for each image on GPU\n",
    "        mean_intensities = torch.mean(images.view(len(images), -1), dim=1)\n",
    "        \n",
    "        Q1 = torch.quantile(mean_intensities, 0.25)\n",
    "        Q3 = torch.quantile(mean_intensities, 0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        mask = (mean_intensities >= lower_bound) & (mean_intensities <= upper_bound)\n",
    "        \n",
    "        print(f\"Original samples: {len(images)}\")\n",
    "        print(f\"Outliers removed: {(~mask).sum().item()}\")\n",
    "        print(f\"Remaining samples: {mask.sum().item()}\")\n",
    "        \n",
    "        return images[mask], labels[mask]\n",
    "    \n",
    "    def normalize_images(self, images):\n",
    "        \"\"\"Z-score normalization on GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"IMAGE NORMALIZATION (Z-Score - GPU)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Global statistics on GPU\n",
    "        self.mean = torch.mean(images)\n",
    "        self.std = torch.std(images)\n",
    "        \n",
    "        print(f\"Global Mean: {self.mean.item():.2f}\")\n",
    "        print(f\"Global Std: {self.std.item():.2f}\")\n",
    "        \n",
    "        # Normalize on GPU\n",
    "        normalized = (images - self.mean) / (self.std + 1e-8)\n",
    "        \n",
    "        return normalized\n",
    "\n",
    "# ============================================================================\n",
    "# 3. RADIOMIC FEATURE EXTRACTION (GPU-Optimized)\n",
    "# ============================================================================\n",
    "\n",
    "class RadiomicFeatureExtractor:\n",
    "    \"\"\"GPU-accelerated radiomic feature extraction\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def extract_statistical_features_gpu(self, image):\n",
    "        \"\"\"Extract statistical features on GPU\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        features.append(torch.mean(image).item())\n",
    "        features.append(torch.var(image).item())\n",
    "        features.append(torch.std(image).item())\n",
    "        \n",
    "        return torch.tensor(features, device=device)\n",
    "    \n",
    "    def compute_glcm_gpu(self, image, distance=1, angle=0):\n",
    "        \"\"\"Compute GLCM\"\"\"\n",
    "        levels = 16\n",
    "        \n",
    "        # Quantize on GPU\n",
    "        image_quantized = (image / (256 / levels)).long()\n",
    "        image_quantized = torch.clamp(image_quantized, 0, levels - 1)\n",
    "        \n",
    "        # Transfer to CPU for co-occurrence computation\n",
    "        img_cpu = image_quantized.cpu().numpy()\n",
    "        glcm = np.zeros((levels, levels), dtype=np.float64)\n",
    "        \n",
    "        rows, cols = img_cpu.shape\n",
    "        \n",
    "        if angle == 0:\n",
    "            dx, dy = 0, distance\n",
    "        elif angle == 45:\n",
    "            dx, dy = distance, distance\n",
    "        elif angle == 90:\n",
    "            dx, dy = distance, 0\n",
    "        else:\n",
    "            dx, dy = distance, -distance\n",
    "        \n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                ni, nj = i + dx, j + dy\n",
    "                if 0 <= ni < rows and 0 <= nj < cols:\n",
    "                    glcm[img_cpu[i, j], img_cpu[ni, nj]] += 1\n",
    "        \n",
    "        glcm = glcm / (np.sum(glcm) + 1e-10)\n",
    "        \n",
    "        return torch.from_numpy(glcm).to(device)\n",
    "    \n",
    "    def extract_texture_features_gpu(self, image):\n",
    "        \"\"\"Extract texture features using GPU\"\"\"\n",
    "        glcm = self.compute_glcm_gpu(image, distance=1, angle=0)\n",
    "        \n",
    "        features = []\n",
    "        \n",
    "        # Contrast computation on GPU\n",
    "        i_idx = torch.arange(glcm.shape[0], device=device).view(-1, 1).float()\n",
    "        j_idx = torch.arange(glcm.shape[1], device=device).view(1, -1).float()\n",
    "        \n",
    "        contrast = torch.sum(glcm * (i_idx - j_idx) ** 2).item()\n",
    "        features.append(contrast)\n",
    "        \n",
    "        # Homogeneity computation on GPU\n",
    "        homogeneity = torch.sum(glcm / (1 + (i_idx - j_idx) ** 2)).item()\n",
    "        features.append(homogeneity)\n",
    "        \n",
    "        return torch.tensor(features, device=device)\n",
    "    \n",
    "    def gabor_kernel_gpu(self, ksize, sigma, theta, lambd, gamma, psi):\n",
    "        \"\"\"Create Gabor kernel on GPU\"\"\"\n",
    "        sigma_x = sigma\n",
    "        sigma_y = sigma / gamma\n",
    "        \n",
    "        xmax = ksize // 2\n",
    "        ymax = ksize // 2\n",
    "        \n",
    "        y = torch.arange(-ymax, ymax + 1, device=device).view(-1, 1).float()\n",
    "        x = torch.arange(-xmax, xmax + 1, device=device).view(1, -1).float()\n",
    "        \n",
    "        # Rotate coordinates\n",
    "        x_theta = x * torch.cos(torch.tensor(theta, device=device)) + y * torch.sin(torch.tensor(theta, device=device))\n",
    "        y_theta = -x * torch.sin(torch.tensor(theta, device=device)) + y * torch.cos(torch.tensor(theta, device=device))\n",
    "        \n",
    "        # Gaussian envelope\n",
    "        exp_part = torch.exp(-0.5 * (x_theta**2 / sigma_x**2 + y_theta**2 / sigma_y**2))\n",
    "        \n",
    "        # Sinusoidal carrier\n",
    "        cos_part = torch.cos(2 * np.pi * x_theta / lambd + psi)\n",
    "        \n",
    "        kernel = exp_part * cos_part\n",
    "        \n",
    "        return kernel\n",
    "    \n",
    "    def extract_filter_features_gpu(self, image):\n",
    "        \"\"\"Extract Gabor filter features on GPU\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        ksize = 21\n",
    "        sigma = 3\n",
    "        lambd = 10\n",
    "        gamma = 0.5\n",
    "        psi = 0\n",
    "        theta = 0\n",
    "        \n",
    "        # Create kernel on GPU\n",
    "        kernel = self.gabor_kernel_gpu(ksize, sigma, theta, lambd, gamma, psi)\n",
    "        \n",
    "        # Apply filter using conv2d\n",
    "        img_4d = image.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]\n",
    "        kernel_4d = kernel.unsqueeze(0).unsqueeze(0)  # [1, 1, K, K]\n",
    "        \n",
    "        filtered = torch.nn.functional.conv2d(img_4d, kernel_4d, padding=ksize//2)\n",
    "        filtered = filtered.squeeze()\n",
    "        \n",
    "        mean_response = torch.mean(torch.abs(filtered)).item()\n",
    "        features.append(mean_response)\n",
    "        \n",
    "        std_response = torch.std(filtered).item()\n",
    "        features.append(std_response)\n",
    "        \n",
    "        return torch.tensor(features, device=device)\n",
    "    \n",
    "    def extract_all_features(self, images):\n",
    "        \"\"\"Extract all features using GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"RADIOMIC FEATURE EXTRACTION (GPU-Accelerated)\")\n",
    "        print(\"=\" * 70)\n",
    "        print(\"Feature Categories:\")\n",
    "        print(\"  1. Statistical: Mean, Variance, Std\")\n",
    "        print(\"  2. Texture: GLCM Contrast, Homogeneity\")\n",
    "        print(\"  3. Filter-based: Gabor Mean Response, Gabor Std Response\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        all_features = []\n",
    "        n_images = len(images)\n",
    "        \n",
    "        for idx in range(n_images):\n",
    "            if idx % 100 == 0:\n",
    "                print(f\"Extracting features from image {idx}/{n_images}...\")\n",
    "            \n",
    "            img = images[idx]\n",
    "            \n",
    "            # Convert to uint8 range on GPU\n",
    "            img_min = torch.min(img)\n",
    "            img_max = torch.max(img)\n",
    "            img_uint8 = ((img - img_min) / (img_max - img_min + 1e-8) * 255)\n",
    "            \n",
    "            # Extract features (all on GPU)\n",
    "            stat_features = self.extract_statistical_features_gpu(img_uint8)\n",
    "            texture_features = self.extract_texture_features_gpu(img_uint8)\n",
    "            filter_features = self.extract_filter_features_gpu(img_uint8)\n",
    "            \n",
    "            # Concatenate on GPU\n",
    "            combined = torch.cat([stat_features, texture_features, filter_features])\n",
    "            all_features.append(combined)\n",
    "        \n",
    "        # Stack all features on GPU\n",
    "        all_features = torch.stack(all_features)\n",
    "        \n",
    "        print(f\"\\nTotal features extracted per image: {all_features.shape[1]}\")\n",
    "        print(f\"All features stored on: {all_features.device}\")\n",
    "        \n",
    "        return all_features\n",
    "\n",
    "# ============================================================================\n",
    "# 4. FEATURE FUSION AND SCALING (GPU)\n",
    "# ============================================================================\n",
    "\n",
    "class FeatureFusion:\n",
    "    \"\"\"GPU-accelerated feature fusion and scaling\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def scale_features(self, features, fit=True):\n",
    "        \"\"\"Z-score normalization on GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"FEATURE SCALING (GPU - Z-Score)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if fit:\n",
    "            self.mean = torch.mean(features, dim=0)\n",
    "            self.std = torch.std(features, dim=0)\n",
    "            print(\"Fitted scaling parameters on GPU\")\n",
    "        \n",
    "        self.std[self.std == 0] = 1\n",
    "        \n",
    "        scaled = (features - self.mean) / self.std\n",
    "        \n",
    "        print(f\"Scaled features shape: {scaled.shape}\")\n",
    "        print(f\"Mean: {torch.mean(scaled).item():.4f}\")\n",
    "        print(f\"Std: {torch.std(scaled).item():.4f}\")\n",
    "        \n",
    "        return scaled\n",
    "\n",
    "# ============================================================================\n",
    "# 5. DIMENSIONALITY REDUCTION (PCA on GPU)\n",
    "# ============================================================================\n",
    "\n",
    "class PCA:\n",
    "    \"\"\"GPU-accelerated PCA\"\"\"\n",
    "    \n",
    "    def __init__(self, n_components=50):\n",
    "        self.n_components = n_components\n",
    "        self.components = None\n",
    "        self.mean = None\n",
    "        self.explained_variance = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"Fit PCA on GPU\"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"DIMENSIONALITY REDUCTION (PCA on GPU - {self.n_components} components)\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Center data on GPU\n",
    "        self.mean = torch.mean(X, dim=0)\n",
    "        X_centered = X - self.mean\n",
    "        \n",
    "        # Compute covariance matrix on GPU\n",
    "        cov_matrix = torch.mm(X_centered.T, X_centered) / (X.shape[0] - 1)\n",
    "        \n",
    "        # Compute eigenvalues and eigenvectors on GPU\n",
    "        eigenvalues, eigenvectors = torch.linalg.eigh(cov_matrix)\n",
    "        \n",
    "        # Sort in descending order\n",
    "        idx = torch.argsort(eigenvalues, descending=True)\n",
    "        eigenvalues = eigenvalues[idx]\n",
    "        eigenvectors = eigenvectors[:, idx]\n",
    "        \n",
    "        # Select top components\n",
    "        self.components = eigenvectors[:, :self.n_components]\n",
    "        self.explained_variance = eigenvalues[:self.n_components]\n",
    "        \n",
    "        # Calculate variance ratios\n",
    "        total_var = torch.sum(eigenvalues)\n",
    "        explained_var_ratio = self.explained_variance / total_var\n",
    "        cumulative_var = torch.cumsum(explained_var_ratio, dim=0)\n",
    "        \n",
    "        print(f\"Original dimension: {X.shape[1]}\")\n",
    "        print(f\"Reduced dimension: {self.n_components}\")\n",
    "        print(f\"Total variance explained: {cumulative_var[-1].item():.4f}\")\n",
    "        print(f\"Computation done on: GPU\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data on GPU\"\"\"\n",
    "        X_centered = X - self.mean\n",
    "        return torch.mm(X_centered, self.components)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit and transform on GPU\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n",
    "\n",
    "# ============================================================================\n",
    "# 6. DATA SPLITTING (GPU)\n",
    "# ============================================================================\n",
    "\n",
    "class DataSplitter:\n",
    "    \"\"\"GPU-based data splitting\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def shuffle_data(X, y, seed=42):\n",
    "        \"\"\"Shuffle data on GPU\"\"\"\n",
    "        torch.manual_seed(seed)\n",
    "        indices = torch.randperm(len(X), device=device)\n",
    "        return X[indices], y[indices]\n",
    "    \n",
    "    @staticmethod\n",
    "    def train_test_split(X, y, train_ratio=0.8, seed=42):\n",
    "        \"\"\"Split data on GPU\"\"\"\n",
    "        X_shuffled, y_shuffled = DataSplitter.shuffle_data(X, y, seed)\n",
    "        \n",
    "        n_samples = len(X)\n",
    "        n_train = int(n_samples * train_ratio)\n",
    "        \n",
    "        return X_shuffled[:n_train], X_shuffled[n_train:], y_shuffled[:n_train], y_shuffled[n_train:]\n",
    "\n",
    "# ============================================================================\n",
    "# 7. SVM CLASSIFIER (Full GPU Implementation)\n",
    "# ============================================================================\n",
    "\n",
    "class SVM:\n",
    "    \"\"\"Full GPU-accelerated SVM\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.001, n_iterations=1000, C=1.0):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iter = n_iterations\n",
    "        self.C = C\n",
    "        self.lambda_param = 1.0 / C\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.classes = None\n",
    "        self.loss_history = []\n",
    "        self.accuracy_history = []\n",
    "    \n",
    "    def compute_hinge_loss(self, X, y, w, b):\n",
    "        \"\"\"Compute hinge loss on GPU\"\"\"\n",
    "        decision = torch.mm(X, w.unsqueeze(1)).squeeze() + b\n",
    "        hinge_loss = torch.clamp(1 - y * decision, min=0)\n",
    "        return torch.mean(hinge_loss) + self.lambda_param * torch.sum(w ** 2)\n",
    "    \n",
    "    def compute_accuracy_binary(self, X, y, w, b):\n",
    "        \"\"\"Compute accuracy on GPU\"\"\"\n",
    "        decision = torch.mm(X, w.unsqueeze(1)).squeeze() + b\n",
    "        predictions = torch.sign(decision)\n",
    "        predictions[predictions == 0] = 1\n",
    "        return (predictions == y).float().mean().item()\n",
    "    \n",
    "    def fit_binary(self, X, y):\n",
    "        \"\"\"Train binary SVM on GPU\"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Initialize on GPU\n",
    "        w = torch.randn(n_features, device=device) * 0.01\n",
    "        b = torch.tensor(0.0, device=device)\n",
    "        \n",
    "        for iteration in range(self.n_iter):\n",
    "            decision = torch.mm(X, w.unsqueeze(1)).squeeze() + b\n",
    "            margin_violations = (y * decision < 1)\n",
    "            \n",
    "            # Gradient computation on GPU\n",
    "            dw = 2 * self.lambda_param * w\n",
    "            db = torch.tensor(0.0, device=device)\n",
    "            \n",
    "            if margin_violations.sum() > 0:\n",
    "                dw -= torch.mm(X[margin_violations].T, y[margin_violations].unsqueeze(1)).squeeze() / n_samples\n",
    "                db -= y[margin_violations].sum() / n_samples\n",
    "            \n",
    "            # Update on GPU\n",
    "            w -= self.lr * dw\n",
    "            b -= self.lr * db\n",
    "            \n",
    "            if iteration % 10 == 0:\n",
    "                loss = self.compute_hinge_loss(X, y, w, b).item()\n",
    "                acc = self.compute_accuracy_binary(X, y, w, b)\n",
    "                self.loss_history.append(loss)\n",
    "                self.accuracy_history.append(acc)\n",
    "                \n",
    "                if iteration % 100 == 0:\n",
    "                    print(f\"  Iteration {iteration}, Loss: {loss:.4f}, Accuracy: {acc:.4f}\")\n",
    "        \n",
    "        return w, b\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train multiclass SVM on GPU\"\"\"\n",
    "        print(\"\\n\" + \"-\" * 70)\n",
    "        print(\"TRAINING: SVM on GPU (One-vs-Rest)\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        self.classes = torch.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        print(f\"Training {n_classes} binary classifiers on GPU...\")\n",
    "        \n",
    "        for i, class_label in enumerate(self.classes):\n",
    "            print(f\"\\nTraining classifier for class {int(class_label.item())}...\")\n",
    "            y_binary = torch.where(y == class_label, \n",
    "                                  torch.tensor(1.0, device=device), \n",
    "                                  torch.tensor(-1.0, device=device))\n",
    "            w, b = self.fit_binary(X, y_binary)\n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict probabilities on GPU\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        decision_values = torch.zeros((n_samples, n_classes), device=device)\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            decision_values[:, i] = torch.mm(X, self.weights[i].unsqueeze(1)).squeeze() + self.biases[i]\n",
    "        \n",
    "        # Softmax on GPU\n",
    "        exp_values = torch.exp(decision_values - torch.max(decision_values, dim=1, keepdim=True)[0])\n",
    "        probabilities = exp_values / torch.sum(exp_values, dim=1, keepdim=True)\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict labels on GPU\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        decision_values = torch.zeros((n_samples, n_classes), device=device)\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            decision_values[:, i] = torch.mm(X, self.weights[i].unsqueeze(1)).squeeze() + self.biases[i]\n",
    "        \n",
    "        predictions = torch.argmax(decision_values, dim=1)\n",
    "        return self.classes[predictions]\n",
    "\n",
    "# ============================================================================\n",
    "# 8. MODEL EVALUATION\n",
    "# ============================================================================\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"GPU-accelerated model evaluation\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def confusion_matrix(y_true, y_pred, n_classes=3):\n",
    "        \"\"\"Compute confusion matrix\"\"\"\n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.cpu().numpy()\n",
    "        if isinstance(y_pred, torch.Tensor):\n",
    "            y_pred = y_pred.cpu().numpy()\n",
    "        \n",
    "        cm = np.zeros((n_classes, n_classes), dtype=int)\n",
    "        for true, pred in zip(y_true, y_pred):\n",
    "            cm[int(true), int(pred)] += 1\n",
    "        return cm\n",
    "    \n",
    "    @staticmethod\n",
    "    def accuracy(y_true, y_pred):\n",
    "        \"\"\"Calculate accuracy\"\"\"\n",
    "        if isinstance(y_true, torch.Tensor) and isinstance(y_pred, torch.Tensor):\n",
    "            return (y_true == y_pred).float().mean().item()\n",
    "        return float(np.mean(y_true == y_pred))\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_recall_f1(y_true, y_pred, n_classes=3):\n",
    "        \"\"\"Calculate metrics\"\"\"\n",
    "        cm = ModelEvaluator.confusion_matrix(y_true, y_pred, n_classes)\n",
    "        \n",
    "        precision = np.zeros(n_classes)\n",
    "        recall = np.zeros(n_classes)\n",
    "        f1 = np.zeros(n_classes)\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            tp = cm[i, i]\n",
    "            fp = np.sum(cm[:, i]) - tp\n",
    "            fn = np.sum(cm[i, :]) - tp\n",
    "            \n",
    "            precision[i] = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "            recall[i] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "            f1[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) > 0 else 0\n",
    "        \n",
    "        return precision, recall, f1\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_confusion_matrix(cm, class_names, filename):\n",
    "        \"\"\"Plot confusion matrix\"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_roc_curve(y_true, y_proba, n_classes, class_names, filename):\n",
    "        \"\"\"Plot ROC curves\"\"\"\n",
    "        if isinstance(y_true, torch.Tensor):\n",
    "            y_true = y_true.cpu().numpy()\n",
    "        if isinstance(y_proba, torch.Tensor):\n",
    "            y_proba = y_proba.cpu().numpy()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        for i in range(n_classes):\n",
    "            y_true_binary = (y_true == i).astype(int)\n",
    "            y_scores = y_proba[:, i]\n",
    "            \n",
    "            thresholds = np.linspace(0, 1, 100)\n",
    "            tpr_list = []\n",
    "            fpr_list = []\n",
    "            \n",
    "            for thresh in thresholds:\n",
    "                y_pred_binary = (y_scores >= thresh).astype(int)\n",
    "                \n",
    "                tp = np.sum((y_true_binary == 1) & (y_pred_binary == 1))\n",
    "                fp = np.sum((y_true_binary == 0) & (y_pred_binary == 1))\n",
    "                tn = np.sum((y_true_binary == 0) & (y_pred_binary == 0))\n",
    "                fn = np.sum((y_true_binary == 1) & (y_pred_binary == 0))\n",
    "                \n",
    "                tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "                fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "                \n",
    "                tpr_list.append(tpr)\n",
    "                fpr_list.append(fpr)\n",
    "            \n",
    "            fpr_array = np.array(fpr_list)\n",
    "            tpr_array = np.array(tpr_list)\n",
    "            \n",
    "            sorted_idx = np.argsort(fpr_array)\n",
    "            fpr_sorted = fpr_array[sorted_idx]\n",
    "            tpr_sorted = tpr_array[sorted_idx]\n",
    "            \n",
    "            auc = np.trapz(tpr_sorted, fpr_sorted)\n",
    "            \n",
    "            plt.plot(fpr_sorted, tpr_sorted, label=f'{class_names[i]} (AUC = {auc:.3f})', linewidth=2)\n",
    "        \n",
    "        plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curves - Multiclass Classification')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_training_curves(loss_history, accuracy_history, filename):\n",
    "        \"\"\"Plot training curves\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        ax1.plot(loss_history, linewidth=2, color='red')\n",
    "        ax1.set_xlabel('Iteration (x10)')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title('Training Loss over Iterations')\n",
    "        ax1.grid(alpha=0.3)\n",
    "        \n",
    "        ax2.plot(accuracy_history, linewidth=2, color='blue')\n",
    "        ax2.set_xlabel('Iteration (x10)')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_title('Training Accuracy over Iterations')\n",
    "        ax2.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "# 9. MAIN PIPELINE (Full CUDA with PyTorch)\n",
    "# ============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution pipeline - Full GPU acceleration with PyTorch\"\"\"\n",
    "    output_dir = \"output_svm_cuda\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CUDA-ACCELERATED LUNG DISEASE CLASSIFICATION\")\n",
    "    print(\"PyTorch CUDA - All Processing on GPU\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Monitor GPU memory\n",
    "    if GPU_AVAILABLE:\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\nInitial GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "        print(f\"Initial GPU Memory: {torch.cuda.memory_reserved() / 1e9:.2f} GB reserved\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 1: Load Dataset (Transfer to GPU)\n",
    "    # ========================================================================\n",
    "    dataset_path = r'C:\\Users\\Wolf\\PAGANI\\chest_xray'\n",
    "    loader = DatasetLoader(dataset_path)\n",
    "    images, labels = loader.load_dataset(target_size=(256, 256))\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory after loading: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2: Preprocessing (GPU)\n",
    "    # ========================================================================\n",
    "    preprocessor = DataPreprocessor()\n",
    "    \n",
    "    images_aug, labels_aug = preprocessor.augment_data(images, labels, augmentation_factor=2)\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory after augmentation: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    images_clean, labels_clean = preprocessor.remove_outliers_iqr(images_aug, labels_aug)\n",
    "    images_norm = preprocessor.normalize_images(images_clean)\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory after preprocessing: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 3: Feature Extraction (GPU)\n",
    "    # ========================================================================\n",
    "    feature_extractor = RadiomicFeatureExtractor()\n",
    "    features = feature_extractor.extract_all_features(images_norm)\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory after feature extraction: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 4: Feature Fusion (GPU)\n",
    "    # ========================================================================\n",
    "    fusion = FeatureFusion()\n",
    "    features_scaled = fusion.scale_features(features, fit=True)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 5: Dimensionality Reduction (GPU)\n",
    "    # ========================================================================\n",
    "    pca = PCA(n_components=min(7, features_scaled.shape[1]))\n",
    "    features_pca = pca.fit_transform(features_scaled)\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory after PCA: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 6: Train-Test Split and Model Training (GPU)\n",
    "    # ========================================================================\n",
    "    class_names = ['Normal', 'Bacterial Pneumonia', 'Viral Pneumonia']\n",
    "    train_ratio = 0.8\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"TRAINING WITH {int(train_ratio*100)}% TRAIN / {int((1-train_ratio)*100)}% TEST SPLIT\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = DataSplitter.train_test_split(\n",
    "        features_pca, labels_clean, train_ratio=train_ratio\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTrain set: {len(X_train)} samples (GPU)\")\n",
    "    print(f\"Test set: {len(X_test)} samples (GPU)\")\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"GPU Memory before training: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # ====================================================================\n",
    "    # Train SVM on GPU\n",
    "    # ====================================================================\n",
    "    start_time = time.time()\n",
    "    \n",
    "    svm_model = SVM(learning_rate=0.001, n_iterations=500, C=1.0)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"\\nGPU Memory after training: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "    \n",
    "    # Predictions (on GPU)\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    y_proba = svm_model.predict_proba(X_test)\n",
    "    \n",
    "    # Evaluation\n",
    "    cm = ModelEvaluator.confusion_matrix(y_test, y_pred)\n",
    "    accuracy = ModelEvaluator.accuracy(y_test, y_pred)\n",
    "    precision, recall, f1 = ModelEvaluator.precision_recall_f1(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 70)\n",
    "    print(\"RESULTS (CUDA-Accelerated with PyTorch)\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Training Time: {train_time:.2f}s\")\n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"Processing: 100% on {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    for i, class_name in enumerate(class_names):\n",
    "        print(f\"\\n{class_name}:\")\n",
    "        print(f\"  Precision: {precision[i]:.4f}\")\n",
    "        print(f\"  Recall: {recall[i]:.4f}\")\n",
    "        print(f\"  F1-Score: {f1[i]:.4f}\")\n",
    "    \n",
    "    # Save visualizations\n",
    "    cm_filename = os.path.join(output_dir, f'confusion_matrix_CUDA_{int(train_ratio*100)}.png')\n",
    "    ModelEvaluator.plot_confusion_matrix(cm, class_names, cm_filename)\n",
    "    \n",
    "    roc_filename = os.path.join(output_dir, f'roc_curve_CUDA_{int(train_ratio*100)}.png')\n",
    "    ModelEvaluator.plot_roc_curve(y_test, y_proba, 3, class_names, roc_filename)\n",
    "    \n",
    "    training_curves_filename = os.path.join(output_dir, f'training_curves_CUDA_{int(train_ratio*100)}.png')\n",
    "    ModelEvaluator.plot_training_curves(svm_model.loss_history, svm_model.accuracy_history, training_curves_filename)\n",
    "    \n",
    "    # Save results\n",
    "    results = {\n",
    "        'model': 'SVM (PyTorch CUDA-Accelerated)',\n",
    "        'gpu': torch.cuda.get_device_name(0) if GPU_AVAILABLE else 'CPU',\n",
    "        'train_ratio': train_ratio,\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision': precision.tolist(),\n",
    "        'recall': recall.tolist(),\n",
    "        'f1_score': f1.tolist(),\n",
    "        'training_time': float(train_time),\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'final_loss': float(svm_model.loss_history[-1]) if svm_model.loss_history else 0.0,\n",
    "        'final_train_accuracy': float(svm_model.accuracy_history[-1]) if svm_model.accuracy_history else 0.0\n",
    "    }\n",
    "    \n",
    "    results_file = os.path.join(output_dir, 'results_summary_cuda.json')\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    \n",
    "    print(f\"\\nResults saved to: {results_file}\")\n",
    "    print(f\"Visualizations saved to: {output_dir}/\")\n",
    "    \n",
    "    # Final GPU memory status\n",
    "    if GPU_AVAILABLE:\n",
    "        print(f\"\\nFinal GPU Memory: {torch.cuda.memory_allocated() / 1e9:.2f} GB allocated\")\n",
    "        print(f\"Peak GPU Memory: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"CUDA-ACCELERATED PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45ef60-17a9-4f63-b966-3b20f06d6e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
